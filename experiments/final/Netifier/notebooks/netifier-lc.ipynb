{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5449be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:25.560216Z",
     "iopub.status.busy": "2024-12-17T12:55:25.559817Z",
     "iopub.status.idle": "2024-12-17T12:55:46.293433Z",
     "shell.execute_reply": "2024-12-17T12:55:46.292475Z"
    },
    "papermill": {
     "duration": 20.742036,
     "end_time": "2024-12-17T12:55:46.295549",
     "exception": false,
     "start_time": "2024-12-17T12:55:25.553513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification, BertPreTrainedModel, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from kaggle_secrets import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2419007a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:46.305669Z",
     "iopub.status.busy": "2024-12-17T12:55:46.305092Z",
     "iopub.status.idle": "2024-12-17T12:55:46.879812Z",
     "shell.execute_reply": "2024-12-17T12:55:46.878921Z"
    },
    "papermill": {
     "duration": 0.581664,
     "end_time": "2024-12-17T12:55:46.881646",
     "exception": false,
     "start_time": "2024-12-17T12:55:46.299982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_key\")\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69a94ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:46.891737Z",
     "iopub.status.busy": "2024-12-17T12:55:46.891412Z",
     "iopub.status.idle": "2024-12-17T12:55:46.895667Z",
     "shell.execute_reply": "2024-12-17T12:55:46.894920Z"
    },
    "papermill": {
     "duration": 0.011422,
     "end_time": "2024-12-17T12:55:46.897788",
     "exception": false,
     "start_time": "2024-12-17T12:55:46.886366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78ccde4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:46.909017Z",
     "iopub.status.busy": "2024-12-17T12:55:46.908439Z",
     "iopub.status.idle": "2024-12-17T12:55:47.064331Z",
     "shell.execute_reply": "2024-12-17T12:55:47.063445Z"
    },
    "papermill": {
     "duration": 0.162479,
     "end_time": "2024-12-17T12:55:47.066027",
     "exception": false,
     "start_time": "2024-12-17T12:55:46.903548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/netifier/processed_train.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/netifier/processed_test.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a78f5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.075885Z",
     "iopub.status.busy": "2024-12-17T12:55:47.075603Z",
     "iopub.status.idle": "2024-12-17T12:55:47.091801Z",
     "shell.execute_reply": "2024-12-17T12:55:47.090855Z"
    },
    "papermill": {
     "duration": 0.02313,
     "end_time": "2024-12-17T12:55:47.093534",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.070404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>jabar memang provinsi barokah boleh juga dan n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@verosvante kita2 aja nitizen yang pada kepo,t...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kita saja nitizen yang pada penasaran toh kelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"#SidangAhok smg sipenista agama n ateknya mat...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sidangahok semoga sipenista agama dan ateknya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@bolususulembang.jkt barusan baca undang2 ini....</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jakarta barusan baca undang ini tetap dibedaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bikin anak mulu lu nof \\nkaga mikir apa kasian...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>buat anak melulu kamu nof nkaga mikir apa kasi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text     source  pornografi  \\\n",
       "0  [QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...     kaskus           0   \n",
       "1  @verosvante kita2 aja nitizen yang pada kepo,t...  instagram           0   \n",
       "2  \"#SidangAhok smg sipenista agama n ateknya mat...    twitter           0   \n",
       "3  @bolususulembang.jkt barusan baca undang2 ini....  instagram           0   \n",
       "4  bikin anak mulu lu nof \\nkaga mikir apa kasian...     kaskus           0   \n",
       "\n",
       "   sara  radikalisme  pencemaran_nama_baik  \\\n",
       "0     0            0                     1   \n",
       "1     0            0                     0   \n",
       "2     1            1                     1   \n",
       "3     0            0                     0   \n",
       "4     0            0                     0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  jabar memang provinsi barokah boleh juga dan n...  \n",
       "1  kita saja nitizen yang pada penasaran toh kelu...  \n",
       "2  sidangahok semoga sipenista agama dan ateknya ...  \n",
       "3  jakarta barusan baca undang ini tetap dibedaka...  \n",
       "4  buat anak melulu kamu nof nkaga mikir apa kasi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a530f639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.103400Z",
     "iopub.status.busy": "2024-12-17T12:55:47.103135Z",
     "iopub.status.idle": "2024-12-17T12:55:47.112346Z",
     "shell.execute_reply": "2024-12-17T12:55:47.111601Z"
    },
    "papermill": {
     "duration": 0.016379,
     "end_time": "2024-12-17T12:55:47.114197",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.097818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e512d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.125216Z",
     "iopub.status.busy": "2024-12-17T12:55:47.124935Z",
     "iopub.status.idle": "2024-12-17T12:55:47.134595Z",
     "shell.execute_reply": "2024-12-17T12:55:47.133627Z"
    },
    "papermill": {
     "duration": 0.016956,
     "end_time": "2024-12-17T12:55:47.136366",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.119410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6218,) (6218, 4)\n",
      "(1555,) (1555, 4)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[2:6]\n",
    "val_labels = val_data.columns[2:6]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['processed_text'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['processed_text'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b08775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.147306Z",
     "iopub.status.busy": "2024-12-17T12:55:47.147036Z",
     "iopub.status.idle": "2024-12-17T12:55:47.911368Z",
     "shell.execute_reply": "2024-12-17T12:55:47.910623Z"
    },
    "papermill": {
     "duration": 0.772156,
     "end_time": "2024-12-17T12:55:47.913480",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.141324",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36be185ae6e74bf0b047d4af839be9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7751aa99ea214141ac8a913524f60ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7280ba19054d06a26edc099c9069f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c8638ce72b4a0da315906aea8e02a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define custom Dataset class\n",
    "class NetifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae1f7d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.925374Z",
     "iopub.status.busy": "2024-12-17T12:55:47.925084Z",
     "iopub.status.idle": "2024-12-17T12:55:47.930230Z",
     "shell.execute_reply": "2024-12-17T12:55:47.929413Z"
    },
    "papermill": {
     "duration": 0.01312,
     "end_time": "2024-12-17T12:55:47.931769",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.918649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    a, b, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31310235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.942576Z",
     "iopub.status.busy": "2024-12-17T12:55:47.942286Z",
     "iopub.status.idle": "2024-12-17T12:55:47.947661Z",
     "shell.execute_reply": "2024-12-17T12:55:47.946792Z"
    },
    "papermill": {
     "duration": 0.013075,
     "end_time": "2024-12-17T12:55:47.949831",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.936756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics_eval(p):\n",
    "    result = compute_metrics(p)\n",
    "    \n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['pornografi', 'sara', 'radikalisme', 'pencemaran_nama_baik'],\n",
    "        zero_division=0\n",
    "    )    \n",
    "    return {\n",
    "        'accuracy': result['accuracy'],\n",
    "        'precision': result['precision'],\n",
    "        'recall': result['recall'],\n",
    "        'f1_micro': result['f1_micro'],\n",
    "        'f1_macro': result['f1_macro'],\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0186c",
   "metadata": {
    "papermill": {
     "duration": 0.004486,
     "end_time": "2024-12-17T12:55:47.959462",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.954976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ACTIVE LEARNING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bd0fafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.970024Z",
     "iopub.status.busy": "2024-12-17T12:55:47.969748Z",
     "iopub.status.idle": "2024-12-17T12:55:47.973665Z",
     "shell.execute_reply": "2024-12-17T12:55:47.972940Z"
    },
    "papermill": {
     "duration": 0.011157,
     "end_time": "2024-12-17T12:55:47.975381",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.964224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_micros = []\n",
    "f1_macros = []\n",
    "sampling_dur = []\n",
    "data_used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98707140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:47.986697Z",
     "iopub.status.busy": "2024-12-17T12:55:47.986030Z",
     "iopub.status.idle": "2024-12-17T12:55:47.990611Z",
     "shell.execute_reply": "2024-12-17T12:55:47.989840Z"
    },
    "papermill": {
     "duration": 0.012128,
     "end_time": "2024-12-17T12:55:47.992250",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.980122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'netifier-lc'\n",
    "epochs = 10\n",
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bade3359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:48.003524Z",
     "iopub.status.busy": "2024-12-17T12:55:48.003266Z",
     "iopub.status.idle": "2024-12-17T12:55:48.014599Z",
     "shell.execute_reply": "2024-12-17T12:55:48.013775Z"
    },
    "papermill": {
     "duration": 0.019164,
     "end_time": "2024-12-17T12:55:48.016348",
     "exception": false,
     "start_time": "2024-12-17T12:55:47.997184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(model, X_pool, train_indices, remaining_indices, trials, n_samples=min_increment):\n",
    "    start_time = time.time()\n",
    "    current_train_size = len(train_indices)\n",
    "        \n",
    "    dataset = NetifierDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=128)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    for data in dataloader:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        for output in outputs:\n",
    "            probs = torch.sigmoid(output).cpu().numpy()\n",
    "            uncertainty = np.absolute(1 - np.max(probs))\n",
    "            uncertainties.append(uncertainty)\n",
    "\n",
    "    uncertainties = np.array(uncertainties)\n",
    "    sorted = np.argsort(uncertainties)\n",
    "    sorted = sorted[::-1]\n",
    "\n",
    "    threshold = np.percentile(uncertainties, 90)\n",
    "    items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "    num_of_candidates = len(items_greater_than_average)\n",
    "\n",
    "    # Check nearest checkpoint\n",
    "    nearest_cp = 0\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "            \n",
    "    if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "        least_confident_indices = sorted[:n_samples]\n",
    "    elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "         least_confident_indices = sorted[:num_of_candidates]\n",
    "    else:\n",
    "        least_confident_indices = sorted[:nearest_cp - current_train_size]\n",
    "\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend(least_confident_indices)\n",
    "        \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'pornografi': [y_train[i][0] for i in temp],\n",
    "            'sara': [y_train[i][1] for i in temp],\n",
    "            'radikalisme': [y_train[i][2] for i in temp],\n",
    "            'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "    end_time = time.time()  # Record the end time\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print(\"Samples above threshold:\", num_of_candidates)\n",
    "    print(\"Acquired samples:\", len(least_confident_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")  # Print or return the runtime if needed\n",
    "    \n",
    "    sampling_dur.append(duration)\n",
    "    \n",
    "    return [remaining_indices[i] for i in least_confident_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71d8dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:48.027817Z",
     "iopub.status.busy": "2024-12-17T12:55:48.027577Z",
     "iopub.status.idle": "2024-12-17T12:55:48.036527Z",
     "shell.execute_reply": "2024-12-17T12:55:48.035802Z"
    },
    "papermill": {
     "duration": 0.016555,
     "end_time": "2024-12-17T12:55:48.038062",
     "exception": false,
     "start_time": "2024-12-17T12:55:48.021507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, trials, seed):\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        # Specify the layers you want to freeze (e.g., first 6 layers)\n",
    "        if \"encoder.layer\" in name:\n",
    "            # Extract the layer number safely\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                # Freeze only the first 6 layers\n",
    "                if int(layer_num) < 9:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                # Skip any parameter names that donâ€™t follow the expected format\n",
    "                continue\n",
    "    \n",
    "    # Create Dataset with current training data\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_dataset = NetifierDataset(current_X_train, current_y_train, tokenizer, max_length=128)\n",
    "    val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=128)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/{filename}-{trials+1}',\n",
    "        eval_strategy=\"epoch\",                    # Evaluate after every epoch\n",
    "        save_strategy=\"epoch\",                    # Save model after every epoch\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_micro',\n",
    "        save_total_limit=1,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate after training\n",
    "    trainer.compute_metrics = compute_metrics_eval\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Iteration {current_train_size}: Accuracy: {eval_results['eval_accuracy']}, F1 Micro: {eval_results['eval_f1_micro']}, F1 Macro: {eval_results['eval_f1_macro']}\")\n",
    "    print(eval_results['eval_report'])\n",
    "\n",
    "    torch.save(model.state_dict(), f'{filename}-{trials+1}-model.pth')\n",
    "    model.config.to_json_file(f'{filename}-{trials+1}-config.json')\n",
    "\n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(eval_results['eval_accuracy'])\n",
    "    f1_micros.append(eval_results['eval_f1_micro'])\n",
    "    f1_macros.append(eval_results['eval_f1_macro'])\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa207bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:48.049741Z",
     "iopub.status.busy": "2024-12-17T12:55:48.049264Z",
     "iopub.status.idle": "2024-12-17T12:55:48.055643Z",
     "shell.execute_reply": "2024-12-17T12:55:48.054810Z"
    },
    "papermill": {
     "duration": 0.014077,
     "end_time": "2024-12-17T12:55:48.057378",
     "exception": false,
     "start_time": "2024-12-17T12:55:48.043301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcb5cff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:48.069077Z",
     "iopub.status.busy": "2024-12-17T12:55:48.068601Z",
     "iopub.status.idle": "2024-12-17T12:55:48.076704Z",
     "shell.execute_reply": "2024-12-17T12:55:48.075944Z"
    },
    "papermill": {
     "duration": 0.015934,
     "end_time": "2024-12-17T12:55:48.078439",
     "exception": false,
     "start_time": "2024-12-17T12:55:48.062505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies.clear()\n",
    "    f1_micros.clear()\n",
    "    f1_macros.clear()\n",
    "    sampling_dur.clear()\n",
    "    data_used.clear()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = least_confidence_sampling(\n",
    "            model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices,\n",
    "            remaining_indices,\n",
    "            trials=i, \n",
    "        )\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    sampling_dur.insert(0, 0)\n",
    "    \n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    \n",
    "    results.to_csv(f'{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfc8cbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:48.089562Z",
     "iopub.status.busy": "2024-12-17T12:55:48.089333Z",
     "iopub.status.idle": "2024-12-17T12:55:48.092839Z",
     "shell.execute_reply": "2024-12-17T12:55:48.092100Z"
    },
    "papermill": {
     "duration": 0.011013,
     "end_time": "2024-12-17T12:55:48.094513",
     "exception": false,
     "start_time": "2024-12-17T12:55:48.083500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b10937",
   "metadata": {
    "papermill": {
     "duration": 0.004833,
     "end_time": "2024-12-17T12:55:48.104463",
     "exception": false,
     "start_time": "2024-12-17T12:55:48.099630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c790e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T12:55:48.115433Z",
     "iopub.status.busy": "2024-12-17T12:55:48.115214Z",
     "iopub.status.idle": "2024-12-17T16:10:54.961692Z",
     "shell.execute_reply": "2024-12-17T16:10:54.960647Z"
    },
    "papermill": {
     "duration": 11706.854129,
     "end_time": "2024-12-17T16:10:54.963629",
     "exception": false,
     "start_time": "2024-12-17T12:55:48.109500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d46d937c8ab46f6a954852b8a35b37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicost918\u001b[0m (\u001b[33mnicost918-petra-christian-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241217_125552-8vim52ye\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-lc-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/8vim52ye\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471070</td>\n",
       "      <td>0.441801</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.016121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408955</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.181750</td>\n",
       "      <td>0.304485</td>\n",
       "      <td>0.212706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.760807</td>\n",
       "      <td>0.398190</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.458811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.333005</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.745169</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>0.572888</td>\n",
       "      <td>0.519570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.599357</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.596443</td>\n",
       "      <td>0.562729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>0.602572</td>\n",
       "      <td>0.734064</td>\n",
       "      <td>0.555807</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.600391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322708</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602180</td>\n",
       "      <td>0.576849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310757</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.728030</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>0.632917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310798</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.650754</td>\n",
       "      <td>0.631457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310642</td>\n",
       "      <td>0.616077</td>\n",
       "      <td>0.733840</td>\n",
       "      <td>0.582202</td>\n",
       "      <td>0.649285</td>\n",
       "      <td>0.630442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6180064308681672, F1 Micro: 0.653926049023681, F1 Macro: 0.6329171582051338\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8939410455524921\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 20.06878662109375 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.430060</td>\n",
       "      <td>0.547267</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.296015</td>\n",
       "      <td>0.212407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339294</td>\n",
       "      <td>0.571704</td>\n",
       "      <td>0.735065</td>\n",
       "      <td>0.426848</td>\n",
       "      <td>0.540076</td>\n",
       "      <td>0.509811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.320608</td>\n",
       "      <td>0.597428</td>\n",
       "      <td>0.751387</td>\n",
       "      <td>0.510558</td>\n",
       "      <td>0.607993</td>\n",
       "      <td>0.576728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303444</td>\n",
       "      <td>0.611576</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.625943</td>\n",
       "      <td>0.665064</td>\n",
       "      <td>0.657531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302950</td>\n",
       "      <td>0.618650</td>\n",
       "      <td>0.718127</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.668011</td>\n",
       "      <td>0.661997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299793</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.723001</td>\n",
       "      <td>0.661388</td>\n",
       "      <td>0.690823</td>\n",
       "      <td>0.675127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302168</td>\n",
       "      <td>0.631511</td>\n",
       "      <td>0.734144</td>\n",
       "      <td>0.637255</td>\n",
       "      <td>0.682277</td>\n",
       "      <td>0.672745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305015</td>\n",
       "      <td>0.637299</td>\n",
       "      <td>0.726073</td>\n",
       "      <td>0.663650</td>\n",
       "      <td>0.693459</td>\n",
       "      <td>0.684938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.308608</td>\n",
       "      <td>0.632154</td>\n",
       "      <td>0.729958</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.688969</td>\n",
       "      <td>0.678106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.308172</td>\n",
       "      <td>0.629582</td>\n",
       "      <td>0.715773</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.694369</td>\n",
       "      <td>0.685902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.84      0.87       362\n",
      "                sara       0.64      0.51      0.57       237\n",
      "         radikalisme       0.65      0.70      0.67       235\n",
      "pencemaran_nama_baik       0.65      0.62      0.63       492\n",
      "\n",
      "           micro avg       0.72      0.67      0.69      1326\n",
      "           macro avg       0.71      0.67      0.69      1326\n",
      "        weighted avg       0.72      0.67      0.69      1326\n",
      "         samples avg       0.38      0.38      0.37      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6295819935691318, F1 Micro: 0.6943689320388349, F1 Macro: 0.6859024981598474\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.84      0.87       362\n",
      "                sara       0.64      0.51      0.57       237\n",
      "         radikalisme       0.65      0.70      0.67       235\n",
      "pencemaran_nama_baik       0.65      0.62      0.63       492\n",
      "\n",
      "           micro avg       0.72      0.67      0.69      1326\n",
      "           macro avg       0.71      0.67      0.69      1326\n",
      "        weighted avg       0.72      0.67      0.69      1326\n",
      "         samples avg       0.38      0.38      0.37      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9412037670612335\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.11165428161621 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444531</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>0.175716</td>\n",
       "      <td>0.296626</td>\n",
       "      <td>0.209635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.588424</td>\n",
       "      <td>0.725971</td>\n",
       "      <td>0.535445</td>\n",
       "      <td>0.616319</td>\n",
       "      <td>0.591499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.298519</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.714534</td>\n",
       "      <td>0.619155</td>\n",
       "      <td>0.663434</td>\n",
       "      <td>0.646247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288986</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.709285</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.706061</td>\n",
       "      <td>0.689479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300154</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.675265</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.719521</td>\n",
       "      <td>0.713264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.310835</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.681546</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.723735</td>\n",
       "      <td>0.716161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.317864</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.691881</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.720636</td>\n",
       "      <td>0.714370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.317229</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>0.710273</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.717432</td>\n",
       "      <td>0.708992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.327822</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.696949</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.726156</td>\n",
       "      <td>0.720694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.326194</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.699858</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.720351</td>\n",
       "      <td>0.713864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.87      0.87       362\n",
      "                sara       0.61      0.62      0.61       237\n",
      "         radikalisme       0.64      0.81      0.72       235\n",
      "pencemaran_nama_baik       0.65      0.72      0.68       492\n",
      "\n",
      "           micro avg       0.70      0.76      0.73      1326\n",
      "           macro avg       0.69      0.75      0.72      1326\n",
      "        weighted avg       0.70      0.76      0.73      1326\n",
      "         samples avg       0.41      0.43      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6540192926045016, F1 Micro: 0.7261560693641619, F1 Macro: 0.7206935807694668\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.87      0.87       362\n",
      "                sara       0.61      0.62      0.61       237\n",
      "         radikalisme       0.64      0.81      0.72       235\n",
      "pencemaran_nama_baik       0.65      0.72      0.68       492\n",
      "\n",
      "           micro avg       0.70      0.76      0.73      1326\n",
      "           macro avg       0.69      0.75      0.72      1326\n",
      "        weighted avg       0.70      0.76      0.73      1326\n",
      "         samples avg       0.41      0.43      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9351345762610437\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.414743423461914 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.556913</td>\n",
       "      <td>0.922794</td>\n",
       "      <td>0.189291</td>\n",
       "      <td>0.314143</td>\n",
       "      <td>0.231689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306682</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.580694</td>\n",
       "      <td>0.646516</td>\n",
       "      <td>0.644855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291905</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.745975</td>\n",
       "      <td>0.628959</td>\n",
       "      <td>0.682488</td>\n",
       "      <td>0.679743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283922</td>\n",
       "      <td>0.642444</td>\n",
       "      <td>0.711242</td>\n",
       "      <td>0.730015</td>\n",
       "      <td>0.720506</td>\n",
       "      <td>0.707808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.294481</td>\n",
       "      <td>0.642444</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.729369</td>\n",
       "      <td>0.718950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.297530</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.722182</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.735283</td>\n",
       "      <td>0.729003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.330426</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.673125</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.736159</td>\n",
       "      <td>0.732548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.321816</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.693083</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.733215</td>\n",
       "      <td>0.725230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.320501</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.738406</td>\n",
       "      <td>0.731188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.325742</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.706454</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.735815</td>\n",
       "      <td>0.728271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.85      0.87       362\n",
      "                sara       0.62      0.63      0.63       237\n",
      "         radikalisme       0.64      0.81      0.72       235\n",
      "pencemaran_nama_baik       0.67      0.76      0.71       492\n",
      "\n",
      "           micro avg       0.71      0.77      0.74      1326\n",
      "           macro avg       0.71      0.76      0.73      1326\n",
      "        weighted avg       0.72      0.77      0.74      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6655948553054662, F1 Micro: 0.7384057971014492, F1 Macro: 0.731187924629885\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.85      0.87       362\n",
      "                sara       0.62      0.63      0.63       237\n",
      "         radikalisme       0.64      0.81      0.72       235\n",
      "pencemaran_nama_baik       0.67      0.76      0.71       492\n",
      "\n",
      "           micro avg       0.71      0.77      0.74      1326\n",
      "           macro avg       0.71      0.76      0.73      1326\n",
      "        weighted avg       0.72      0.77      0.74      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8450943350791932\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.789022207260132 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.368044</td>\n",
       "      <td>0.560129</td>\n",
       "      <td>0.917492</td>\n",
       "      <td>0.209653</td>\n",
       "      <td>0.341314</td>\n",
       "      <td>0.269892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297894</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.730245</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.662546</td>\n",
       "      <td>0.657983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278159</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.691205</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.741699</td>\n",
       "      <td>0.732980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.273960</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.696393</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.745002</td>\n",
       "      <td>0.741277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.287126</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.705961</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.747783</td>\n",
       "      <td>0.733351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.289985</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.723496</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.742101</td>\n",
       "      <td>0.728466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.304783</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.714383</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.752143</td>\n",
       "      <td>0.744499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.323116</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.692898</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.749740</td>\n",
       "      <td>0.746410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.328052</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.694087</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.749480</td>\n",
       "      <td>0.743533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.322744</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.705999</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.753429</td>\n",
       "      <td>0.747798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.64      0.85      0.73       235\n",
      "pencemaran_nama_baik       0.67      0.79      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.81      0.75      1326\n",
      "           macro avg       0.70      0.80      0.75      1326\n",
      "        weighted avg       0.71      0.81      0.76      1326\n",
      "         samples avg       0.43      0.46      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6720257234726688, F1 Micro: 0.7534294759057334, F1 Macro: 0.7477977564913787\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.64      0.85      0.73       235\n",
      "pencemaran_nama_baik       0.67      0.79      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.81      0.75      1326\n",
      "           macro avg       0.70      0.80      0.75      1326\n",
      "        weighted avg       0.71      0.81      0.76      1326\n",
      "         samples avg       0.43      0.46      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.4966639518737797\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.292513608932495 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361897</td>\n",
       "      <td>0.567846</td>\n",
       "      <td>0.934028</td>\n",
       "      <td>0.202866</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.231644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.282932</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.724741</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.705381</td>\n",
       "      <td>0.703441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.261633</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.728190</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.744563</td>\n",
       "      <td>0.735141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.291983</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.677914</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.747632</td>\n",
       "      <td>0.741765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.283353</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.739354</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.749256</td>\n",
       "      <td>0.747094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.295674</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.723361</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.754831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.327558</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.688085</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.753158</td>\n",
       "      <td>0.751207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.322236</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.755524</td>\n",
       "      <td>0.750439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.324897</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.708936</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.757725</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.324732</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.712583</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.758815</td>\n",
       "      <td>0.754950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.89       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.70      0.82      0.75       235\n",
      "pencemaran_nama_baik       0.68      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.72      0.80      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.73      0.80      0.76      1326\n",
      "         samples avg       0.43      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6816720257234726, F1 Micro: 0.7591397849462367, F1 Macro: 0.7548309896426588\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.89       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.70      0.82      0.75       235\n",
      "pencemaran_nama_baik       0.68      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.72      0.80      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.73      0.80      0.76      1326\n",
      "         samples avg       0.43      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.31896644830703735\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.005959033966064 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353038</td>\n",
       "      <td>0.564630</td>\n",
       "      <td>0.927052</td>\n",
       "      <td>0.230015</td>\n",
       "      <td>0.368580</td>\n",
       "      <td>0.296615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.705640</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.738129</td>\n",
       "      <td>0.731974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.271617</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.714096</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.750063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.265727</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.734397</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.765173</td>\n",
       "      <td>0.758403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.274007</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.733562</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.762147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.349216</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.662864</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.754791</td>\n",
       "      <td>0.753547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.312733</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.714941</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.765077</td>\n",
       "      <td>0.759186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.314725</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.765791</td>\n",
       "      <td>0.760945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.336217</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.708974</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.766459</td>\n",
       "      <td>0.762287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.340945</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.707851</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.759355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.61      0.67      0.64       237\n",
      "         radikalisme       0.69      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7022508038585209, F1 Micro: 0.7688442211055275, F1 Macro: 0.762147159996968\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.61      0.67      0.64       237\n",
      "         radikalisme       0.69      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.1815493404865265\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.889323472976685 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.311680</td>\n",
       "      <td>0.614148</td>\n",
       "      <td>0.806536</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>0.590148</td>\n",
       "      <td>0.531331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265001</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.732046</td>\n",
       "      <td>0.721027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.263493</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.746404</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.744994</td>\n",
       "      <td>0.728994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.267242</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.728268</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.763545</td>\n",
       "      <td>0.758431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.275202</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.730559</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.767192</td>\n",
       "      <td>0.763385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.322318</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.694360</td>\n",
       "      <td>0.863499</td>\n",
       "      <td>0.769748</td>\n",
       "      <td>0.770128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.306942</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.715036</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.764479</td>\n",
       "      <td>0.760345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.312815</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.718915</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.766032</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.312694</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.741620</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.770123</td>\n",
       "      <td>0.763547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.331212</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.723179</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.770099</td>\n",
       "      <td>0.764885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.78      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7035369774919614, F1 Micro: 0.770123277737491, F1 Macro: 0.763546903169527\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.71      0.84      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.78      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.79      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.04258209466934204\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.874484539031982 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302163</td>\n",
       "      <td>0.618650</td>\n",
       "      <td>0.754774</td>\n",
       "      <td>0.566365</td>\n",
       "      <td>0.647135</td>\n",
       "      <td>0.636297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259614</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.727528</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.753455</td>\n",
       "      <td>0.751089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.248928</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.783034</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.752351</td>\n",
       "      <td>0.732038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.263900</td>\n",
       "      <td>0.282179</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.705323</td>\n",
       "      <td>0.839367</td>\n",
       "      <td>0.766529</td>\n",
       "      <td>0.762097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.271534</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.728486</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.773097</td>\n",
       "      <td>0.769285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.157700</td>\n",
       "      <td>0.284491</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.759610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.303813</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.729514</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.774673</td>\n",
       "      <td>0.767822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.318518</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.727513</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.770804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.320574</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.723572</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.773605</td>\n",
       "      <td>0.770642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.315618</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.734007</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.775525</td>\n",
       "      <td>0.771632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.61      0.71      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.78      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.6996784565916399, F1 Micro: 0.775524724297403, F1 Macro: 0.7716322548725598\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.61      0.71      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.78      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.020580208301544195\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 8.973403453826904 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284924</td>\n",
       "      <td>0.641801</td>\n",
       "      <td>0.747871</td>\n",
       "      <td>0.662142</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.693386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255493</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.733475</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.755214</td>\n",
       "      <td>0.747518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.263090</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.759459</td>\n",
       "      <td>0.757594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.267779</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.718301</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.769608</td>\n",
       "      <td>0.764152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.279678</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.736044</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.759496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.285163</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.740896</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.768337</td>\n",
       "      <td>0.761148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.321830</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.715120</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.768748</td>\n",
       "      <td>0.765593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.322276</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.722623</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.773062</td>\n",
       "      <td>0.769385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.326271</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.727092</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.773305</td>\n",
       "      <td>0.768243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.327422</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.726547</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.772004</td>\n",
       "      <td>0.767835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.91      0.90       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.77      1326\n",
      "           macro avg       0.72      0.82      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.6971061093247588, F1 Micro: 0.7733050847457626, F1 Macro: 0.768243030341341\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.91      0.90       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.77      1326\n",
      "           macro avg       0.72      0.82      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.013772147893905639\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.316777229309082 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277304</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.788826</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.699412</td>\n",
       "      <td>0.696834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>0.244901</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.760212</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.759063</td>\n",
       "      <td>0.750879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>0.244080</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.763457</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.761437</td>\n",
       "      <td>0.751108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.256684</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.736510</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.763531</td>\n",
       "      <td>0.759044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.269360</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.742715</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.764727</td>\n",
       "      <td>0.759271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.309880</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.711613</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.767038</td>\n",
       "      <td>0.762925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.313230</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.722661</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.771449</td>\n",
       "      <td>0.769272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.309231</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.771190</td>\n",
       "      <td>0.764831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.312934</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.745896</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.766410</td>\n",
       "      <td>0.759581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.324508</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.731241</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.767908</td>\n",
       "      <td>0.762340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.69      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.83      0.77      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.6919614147909968, F1 Micro: 0.7714486638537271, F1 Macro: 0.7692721011509679\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.62      0.73      0.67       237\n",
      "         radikalisme       0.69      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.73       492\n",
      "\n",
      "           micro avg       0.72      0.83      0.77      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.010799241065979005\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.514275074005127 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284154</td>\n",
       "      <td>0.639228</td>\n",
       "      <td>0.834577</td>\n",
       "      <td>0.506033</td>\n",
       "      <td>0.630047</td>\n",
       "      <td>0.629777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.245633</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.741661</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.764168</td>\n",
       "      <td>0.756294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.247473</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.743785</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.776496</td>\n",
       "      <td>0.767355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.247310</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.740638</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.771676</td>\n",
       "      <td>0.768258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.273816</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.732203</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.771153</td>\n",
       "      <td>0.763920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>0.300011</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.771329</td>\n",
       "      <td>0.767341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.752680</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.772844</td>\n",
       "      <td>0.767870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.301104</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.768011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.311729</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.741869</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.773728</td>\n",
       "      <td>0.768644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.311279</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.745480</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.775687</td>\n",
       "      <td>0.770756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.66      0.60      0.63       237\n",
      "         radikalisme       0.73      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7035369774919614, F1 Micro: 0.7764960346070656, F1 Macro: 0.7673547956029148\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.66      0.60      0.63       237\n",
      "         radikalisme       0.73      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.68      0.84      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.10236265659332275\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.792560577392578 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276580</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.720947</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.727680</td>\n",
       "      <td>0.721137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.247875</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.751673</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.757020</td>\n",
       "      <td>0.749723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.233549</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.778204</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.771396</td>\n",
       "      <td>0.766607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.246005</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.755940</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.773481</td>\n",
       "      <td>0.768329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.261566</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.739876</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.768193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.762416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.280434</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.768357</td>\n",
       "      <td>0.761050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.299105</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.749823</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.768857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.302665</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.758345</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.772929</td>\n",
       "      <td>0.766724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.304299</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.757465</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.770656</td>\n",
       "      <td>0.763696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.74      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7016077170418007, F1 Micro: 0.7747035573122529, F1 Macro: 0.7681926700698194\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.74      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.02220315337181091\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.248746871948242 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270126</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.802554</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>0.697099</td>\n",
       "      <td>0.694367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.239068</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.785301</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.749704</td>\n",
       "      <td>0.739281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.812554</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.753740</td>\n",
       "      <td>0.735125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.241813</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.776592</td>\n",
       "      <td>0.769828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.256105</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.784223</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.774341</td>\n",
       "      <td>0.765262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.274316</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.789600</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.766304</td>\n",
       "      <td>0.758577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.284080</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.763699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.299550</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.748212</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.767988</td>\n",
       "      <td>0.762864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.303865</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.763061</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.772439</td>\n",
       "      <td>0.766361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.311196</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.765414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.65      0.66      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7080385852090032, F1 Micro: 0.7765918292234082, F1 Macro: 0.7698275637438274\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.65      0.66      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.03510700464248661\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.626382827758789 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266728</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.761944</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.718069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.238433</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.762649</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.767790</td>\n",
       "      <td>0.762579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.231487</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.766471</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.777860</td>\n",
       "      <td>0.769323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.242554</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.775615</td>\n",
       "      <td>0.770617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.253479</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.775744</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.771331</td>\n",
       "      <td>0.760219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.277848</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.739782</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.777380</td>\n",
       "      <td>0.772267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.289334</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.750520</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.782232</td>\n",
       "      <td>0.775063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.292517</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.754916</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.776193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.293991</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.774313</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.780397</td>\n",
       "      <td>0.772960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.302753</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.765004</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>0.774371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.70      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.712540192926045, F1 Micro: 0.7822318526543878, F1 Macro: 0.7750632037763763\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.70      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.012279927730560303\n",
      "Samples above threshold: 165\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.946549415588379 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270888</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.703051</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.740450</td>\n",
       "      <td>0.735470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.237450</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.752540</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.767012</td>\n",
       "      <td>0.757582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.246420</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.747629</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.760104</td>\n",
       "      <td>0.748630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.252564</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.762527</td>\n",
       "      <td>0.754255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.755343</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.764070</td>\n",
       "      <td>0.755370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.283485</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.742392</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.765973</td>\n",
       "      <td>0.756820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.292686</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.750900</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.768324</td>\n",
       "      <td>0.759905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.299365</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.758876</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.766243</td>\n",
       "      <td>0.754721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.303145</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.778120</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.769817</td>\n",
       "      <td>0.758826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.309013</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.765579</td>\n",
       "      <td>0.754164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.65      0.59      0.62       237\n",
      "         radikalisme       0.73      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.75      0.71      0.73       492\n",
      "\n",
      "           micro avg       0.78      0.76      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.78      0.76      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7157556270096463, F1 Micro: 0.7698170731707316, F1 Macro: 0.7588258730141089\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.65      0.59      0.62       237\n",
      "         radikalisme       0.73      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.75      0.71      0.73       492\n",
      "\n",
      "           micro avg       0.78      0.76      0.77      1326\n",
      "           macro avg       0.76      0.76      0.76      1326\n",
      "        weighted avg       0.78      0.76      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.004261505603790286\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.304629802703857 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257967</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.718623</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.758547</td>\n",
       "      <td>0.755142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.235552</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.772939</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.761103</td>\n",
       "      <td>0.740775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.233881</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.793408</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.768093</td>\n",
       "      <td>0.756550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.214100</td>\n",
       "      <td>0.236839</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.787316</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.777396</td>\n",
       "      <td>0.769600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.259862</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.751743</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.781159</td>\n",
       "      <td>0.775017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.285728</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.781082</td>\n",
       "      <td>0.773793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.281375</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.775357</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.776816</td>\n",
       "      <td>0.770016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.293111</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.764620</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.776540</td>\n",
       "      <td>0.771363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.306459</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.769004</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.777322</td>\n",
       "      <td>0.770064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.307962</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.769287</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.779308</td>\n",
       "      <td>0.772770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7196141479099678, F1 Micro: 0.7811594202898552, F1 Macro: 0.7750173840308552\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.00831056833267212\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.684798240661621 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256687</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.716125</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.754461</td>\n",
       "      <td>0.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.235128</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.811694</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.758538</td>\n",
       "      <td>0.742831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.257229</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.710044</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.772774</td>\n",
       "      <td>0.767969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.240665</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.766983</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.770469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.255179</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.755175</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.775944</td>\n",
       "      <td>0.767704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.275851</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.749477</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.778543</td>\n",
       "      <td>0.771613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.284825</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.763716</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.775343</td>\n",
       "      <td>0.766605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.288995</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.782101</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.769820</td>\n",
       "      <td>0.759850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.297686</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.766052</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>0.767092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.304379</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.758967</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.777941</td>\n",
       "      <td>0.772115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7099678456591639, F1 Micro: 0.7792207792207793, F1 Macro: 0.7704686470058046\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.012228333950042724\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.9739387035369873 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249420</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.732862</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.756658</td>\n",
       "      <td>0.755642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309100</td>\n",
       "      <td>0.224847</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.771407</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.776321</td>\n",
       "      <td>0.768378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.223211</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.786697</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.781321</td>\n",
       "      <td>0.770682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215400</td>\n",
       "      <td>0.239109</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.783803</td>\n",
       "      <td>0.777246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.244877</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.780147</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.790022</td>\n",
       "      <td>0.782841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.259650</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.773165</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.779813</td>\n",
       "      <td>0.770402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.275604</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.774481</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.780853</td>\n",
       "      <td>0.772119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.290240</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.779598</td>\n",
       "      <td>0.770992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.295690</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.768452</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.784343</td>\n",
       "      <td>0.777162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.302206</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.783543</td>\n",
       "      <td>0.777558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.93       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.77      0.82      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7234726688102894, F1 Micro: 0.7900223380491437, F1 Macro: 0.7828406277688784\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.93       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.77      0.82      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.004629862308502195\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2812511920928955 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244665</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.785246</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.752553</td>\n",
       "      <td>0.738517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.223039</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.782101</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.769820</td>\n",
       "      <td>0.760618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.222329</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.768179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.243668</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.749824</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.776282</td>\n",
       "      <td>0.772617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.249710</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.756930</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.779363</td>\n",
       "      <td>0.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.285257</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.732753</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.776162</td>\n",
       "      <td>0.771074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.281388</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.778070</td>\n",
       "      <td>0.773207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.289464</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.781487</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.779123</td>\n",
       "      <td>0.773325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.301214</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.767766</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.778893</td>\n",
       "      <td>0.773686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.304760</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.769060</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.776242</td>\n",
       "      <td>0.770099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.64      0.65      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7170418006430869, F1 Micro: 0.7793633369923161, F1 Macro: 0.7737001228442595\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.64      0.65      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.004147458076477052\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.6139726638793945 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239493</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.736585</td>\n",
       "      <td>0.714704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.226350</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.800329</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.766024</td>\n",
       "      <td>0.751845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.225785</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.790845</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.772850</td>\n",
       "      <td>0.758986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.232668</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.780153</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.775417</td>\n",
       "      <td>0.767841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.249829</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.766389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.265149</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.784024</td>\n",
       "      <td>0.775484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.279122</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.773264</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.781343</td>\n",
       "      <td>0.776040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.302533</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.757275</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.780256</td>\n",
       "      <td>0.770123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.302038</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.779269</td>\n",
       "      <td>0.768851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.303428</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.783253</td>\n",
       "      <td>0.774683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7215434083601286, F1 Micro: 0.7840236686390532, F1 Macro: 0.7754837941376534\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0035426378250122074\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.0685744285583496 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242391</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.753495</td>\n",
       "      <td>0.750924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.222947</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.820087</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.760016</td>\n",
       "      <td>0.744694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.222569</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.765772</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.780776</td>\n",
       "      <td>0.773344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.238808</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.746086</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.784258</td>\n",
       "      <td>0.777718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.253162</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.762383</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.781170</td>\n",
       "      <td>0.775147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.270875</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.755773</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.784029</td>\n",
       "      <td>0.778489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.285699</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.760962</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.779045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.295462</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.777528</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.780158</td>\n",
       "      <td>0.773661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.300720</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.769063</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.776631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.306307</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.775717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.64      0.69      0.67       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7254019292604501, F1 Micro: 0.7854014598540145, F1 Macro: 0.7790454887189036\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.64      0.69      0.67       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 179.79 seconds\n",
      "Total runtime: 11705.891491413116 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d8a79",
   "metadata": {
    "papermill": {
     "duration": 0.021215,
     "end_time": "2024-12-17T16:10:55.006639",
     "exception": false,
     "start_time": "2024-12-17T16:10:54.985424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74a2ddf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T16:10:55.052071Z",
     "iopub.status.busy": "2024-12-17T16:10:55.051668Z",
     "iopub.status.idle": "2024-12-17T19:27:08.008718Z",
     "shell.execute_reply": "2024-12-17T19:27:08.007785Z"
    },
    "papermill": {
     "duration": 11772.982446,
     "end_time": "2024-12-17T19:27:08.010980",
     "exception": false,
     "start_time": "2024-12-17T16:10:55.028534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.440514</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>0.044738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398824</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.236802</td>\n",
       "      <td>0.372479</td>\n",
       "      <td>0.261927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.830054</td>\n",
       "      <td>0.349925</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.420032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330393</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.553130</td>\n",
       "      <td>0.459224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.761511</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.525215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.605145</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0.597001</td>\n",
       "      <td>0.545943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299625</td>\n",
       "      <td>0.612862</td>\n",
       "      <td>0.739634</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.610205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297249</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.771834</td>\n",
       "      <td>0.533183</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.596109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294833</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.772004</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.641692</td>\n",
       "      <td>0.603582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.592582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6128617363344051, F1 Micro: 0.649174777824799, F1 Macro: 0.6102054118583491\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.833769391477108\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 20.444432497024536 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.457623</td>\n",
       "      <td>0.522186</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>0.230513</td>\n",
       "      <td>0.161462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339023</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>0.845339</td>\n",
       "      <td>0.300905</td>\n",
       "      <td>0.443826</td>\n",
       "      <td>0.356335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.611576</td>\n",
       "      <td>0.741164</td>\n",
       "      <td>0.537707</td>\n",
       "      <td>0.623252</td>\n",
       "      <td>0.612631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295249</td>\n",
       "      <td>0.602572</td>\n",
       "      <td>0.699746</td>\n",
       "      <td>0.622172</td>\n",
       "      <td>0.658683</td>\n",
       "      <td>0.631950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305601</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.748950</td>\n",
       "      <td>0.537707</td>\n",
       "      <td>0.625988</td>\n",
       "      <td>0.580727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317523</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.764182</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.617528</td>\n",
       "      <td>0.575472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303215</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.725543</td>\n",
       "      <td>0.604072</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.637667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305310</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.713322</td>\n",
       "      <td>0.638009</td>\n",
       "      <td>0.673567</td>\n",
       "      <td>0.657750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.310775</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.720690</td>\n",
       "      <td>0.630468</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.653122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.313669</td>\n",
       "      <td>0.621865</td>\n",
       "      <td>0.716113</td>\n",
       "      <td>0.633484</td>\n",
       "      <td>0.672269</td>\n",
       "      <td>0.654227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.86      0.87       362\n",
      "                sara       0.61      0.41      0.49       237\n",
      "         radikalisme       0.68      0.65      0.66       235\n",
      "pencemaran_nama_baik       0.63      0.58      0.61       492\n",
      "\n",
      "           micro avg       0.71      0.64      0.67      1326\n",
      "           macro avg       0.70      0.62      0.66      1326\n",
      "        weighted avg       0.71      0.64      0.67      1326\n",
      "         samples avg       0.39      0.37      0.37      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6205787781350482, F1 Micro: 0.6735668789808916, F1 Macro: 0.6577501133118858\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.86      0.87       362\n",
      "                sara       0.61      0.41      0.49       237\n",
      "         radikalisme       0.68      0.65      0.66       235\n",
      "pencemaran_nama_baik       0.63      0.58      0.61       492\n",
      "\n",
      "           micro avg       0.71      0.64      0.67      1326\n",
      "           macro avg       0.70      0.62      0.66      1326\n",
      "        weighted avg       0.71      0.64      0.67      1326\n",
      "         samples avg       0.39      0.37      0.37      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9440128356218338\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.354169607162476 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398581</td>\n",
       "      <td>0.545981</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.162896</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.185873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316895</td>\n",
       "      <td>0.592283</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.459276</td>\n",
       "      <td>0.577251</td>\n",
       "      <td>0.508734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302148</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.656849</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.677239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.287887</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.700962</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.707508</td>\n",
       "      <td>0.690124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293817</td>\n",
       "      <td>0.629582</td>\n",
       "      <td>0.747437</td>\n",
       "      <td>0.604827</td>\n",
       "      <td>0.668612</td>\n",
       "      <td>0.639493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.292686</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.718131</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.700657</td>\n",
       "      <td>0.690623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.302458</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.684806</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.707041</td>\n",
       "      <td>0.698042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.309311</td>\n",
       "      <td>0.645016</td>\n",
       "      <td>0.726446</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.693218</td>\n",
       "      <td>0.671450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.315246</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.675716</td>\n",
       "      <td>0.696734</td>\n",
       "      <td>0.676587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.636013</td>\n",
       "      <td>0.700977</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.702296</td>\n",
       "      <td>0.686943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.89      0.87       362\n",
      "                sara       0.63      0.53      0.58       237\n",
      "         radikalisme       0.66      0.61      0.63       235\n",
      "pencemaran_nama_baik       0.63      0.73      0.68       492\n",
      "\n",
      "           micro avg       0.70      0.71      0.71      1326\n",
      "           macro avg       0.70      0.69      0.69      1326\n",
      "        weighted avg       0.70      0.71      0.71      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6270096463022508, F1 Micro: 0.7075084049308928, F1 Macro: 0.6901240298872042\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.89      0.87       362\n",
      "                sara       0.63      0.53      0.58       237\n",
      "         radikalisme       0.66      0.61      0.63       235\n",
      "pencemaran_nama_baik       0.63      0.73      0.68       492\n",
      "\n",
      "           micro avg       0.70      0.71      0.71      1326\n",
      "           macro avg       0.70      0.69      0.69      1326\n",
      "        weighted avg       0.70      0.71      0.71      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8236494466662407\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.460479497909546 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380157</td>\n",
       "      <td>0.574277</td>\n",
       "      <td>0.906627</td>\n",
       "      <td>0.226998</td>\n",
       "      <td>0.363088</td>\n",
       "      <td>0.246063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299322</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.667327</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.711721</td>\n",
       "      <td>0.702477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280386</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.746736</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.663577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289340</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.663278</td>\n",
       "      <td>0.836350</td>\n",
       "      <td>0.739827</td>\n",
       "      <td>0.738275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.275659</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.757877</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.721959</td>\n",
       "      <td>0.701907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.290528</td>\n",
       "      <td>0.645016</td>\n",
       "      <td>0.720301</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.721386</td>\n",
       "      <td>0.692810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.301247</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.715015</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.727205</td>\n",
       "      <td>0.714959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.299369</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.720964</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.732468</td>\n",
       "      <td>0.720742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.304631</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.733538</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.727964</td>\n",
       "      <td>0.713145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.310847</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>0.711937</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.731009</td>\n",
       "      <td>0.717428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.88      0.89       362\n",
      "                sara       0.57      0.73      0.64       237\n",
      "         radikalisme       0.65      0.82      0.73       235\n",
      "pencemaran_nama_baik       0.60      0.87      0.71       492\n",
      "\n",
      "           micro avg       0.66      0.84      0.74      1326\n",
      "           macro avg       0.68      0.82      0.74      1326\n",
      "        weighted avg       0.68      0.84      0.75      1326\n",
      "         samples avg       0.44      0.47      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6443729903536978, F1 Micro: 0.7398265510340227, F1 Macro: 0.7382749134976028\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.88      0.89       362\n",
      "                sara       0.57      0.73      0.64       237\n",
      "         radikalisme       0.65      0.82      0.73       235\n",
      "pencemaran_nama_baik       0.60      0.87      0.71       492\n",
      "\n",
      "           micro avg       0.66      0.84      0.74      1326\n",
      "           macro avg       0.68      0.82      0.74      1326\n",
      "        weighted avg       0.68      0.84      0.75      1326\n",
      "         samples avg       0.44      0.47      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.5638537347316747\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.971923828125 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.411474</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.173454</td>\n",
       "      <td>0.294683</td>\n",
       "      <td>0.194233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301257</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.806944</td>\n",
       "      <td>0.438160</td>\n",
       "      <td>0.567937</td>\n",
       "      <td>0.524658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266130</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.747733</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.714455</td>\n",
       "      <td>0.704529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.266199</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.724803</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.744220</td>\n",
       "      <td>0.734935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.267721</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.746533</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.738567</td>\n",
       "      <td>0.729636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.293030</td>\n",
       "      <td>0.658521</td>\n",
       "      <td>0.708623</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.737337</td>\n",
       "      <td>0.723566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.299059</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.709437</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.746695</td>\n",
       "      <td>0.738236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.310849</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.714085</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.740283</td>\n",
       "      <td>0.725550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>0.311322</td>\n",
       "      <td>0.657235</td>\n",
       "      <td>0.715203</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.734873</td>\n",
       "      <td>0.723849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.318910</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.706566</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.741033</td>\n",
       "      <td>0.729225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.56      0.63      0.59       237\n",
      "         radikalisme       0.67      0.83      0.74       235\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.79      0.75      1326\n",
      "           macro avg       0.70      0.78      0.74      1326\n",
      "        weighted avg       0.72      0.79      0.75      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6694533762057878, F1 Micro: 0.7466952483029654, F1 Macro: 0.7382359496160397\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.88      0.90       362\n",
      "                sara       0.56      0.63      0.59       237\n",
      "         radikalisme       0.67      0.83      0.74       235\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.79      0.75      1326\n",
      "           macro avg       0.70      0.78      0.74      1326\n",
      "        weighted avg       0.72      0.79      0.75      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.4944411754608158\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.449349641799927 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.354686</td>\n",
       "      <td>0.566559</td>\n",
       "      <td>0.945255</td>\n",
       "      <td>0.195324</td>\n",
       "      <td>0.323750</td>\n",
       "      <td>0.226589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281494</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.679872</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.736077</td>\n",
       "      <td>0.730271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>0.269177</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.699098</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.753996</td>\n",
       "      <td>0.750018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>0.260668</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.743045</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.754086</td>\n",
       "      <td>0.742276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>0.278498</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.711625</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.768644</td>\n",
       "      <td>0.763462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.281816</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.722485</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.762380</td>\n",
       "      <td>0.757023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.317238</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.698184</td>\n",
       "      <td>0.840875</td>\n",
       "      <td>0.762915</td>\n",
       "      <td>0.759519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>0.303239</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.761665</td>\n",
       "      <td>0.751117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.719707</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.764498</td>\n",
       "      <td>0.756639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.310831</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.723605</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.765020</td>\n",
       "      <td>0.758454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.61      0.74      0.67       237\n",
      "         radikalisme       0.68      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.67      0.83      0.74       492\n",
      "\n",
      "           micro avg       0.71      0.84      0.77      1326\n",
      "           macro avg       0.71      0.83      0.76      1326\n",
      "        weighted avg       0.72      0.84      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6778135048231512, F1 Micro: 0.7686437738466875, F1 Macro: 0.7634624433901256\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.61      0.74      0.67       237\n",
      "         radikalisme       0.68      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.67      0.83      0.74       492\n",
      "\n",
      "           micro avg       0.71      0.84      0.77      1326\n",
      "           macro avg       0.71      0.83      0.76      1326\n",
      "        weighted avg       0.72      0.84      0.77      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.24177396297454834\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.193474054336548 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.323585</td>\n",
       "      <td>0.575563</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.316742</td>\n",
       "      <td>0.461032</td>\n",
       "      <td>0.377346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266408</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.730038</td>\n",
       "      <td>0.720711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.258122</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.776641</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.729092</td>\n",
       "      <td>0.722186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.263132</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.722074</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.767491</td>\n",
       "      <td>0.761371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.275398</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.721485</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.767819</td>\n",
       "      <td>0.760926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.686630</td>\n",
       "      <td>0.855958</td>\n",
       "      <td>0.762001</td>\n",
       "      <td>0.760190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.295462</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.725084</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.768522</td>\n",
       "      <td>0.762393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.306432</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.722296</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.766289</td>\n",
       "      <td>0.761127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.726536</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.766655</td>\n",
       "      <td>0.759009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.314985</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.724579</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.765564</td>\n",
       "      <td>0.758026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.69      0.85      0.76       235\n",
      "pencemaran_nama_baik       0.68      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.72      0.81      0.76      1326\n",
      "        weighted avg       0.73      0.82      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6881028938906752, F1 Micro: 0.7685218007798653, F1 Macro: 0.7623934222058979\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.90       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.69      0.85      0.76       235\n",
      "pencemaran_nama_baik       0.68      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.72      0.81      0.76      1326\n",
      "        weighted avg       0.73      0.82      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0981287956237793\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.923182964324951 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305854</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.761506</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.638037</td>\n",
       "      <td>0.625403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263644</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.780331</td>\n",
       "      <td>0.640271</td>\n",
       "      <td>0.703397</td>\n",
       "      <td>0.693727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.247327</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.733564</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.765067</td>\n",
       "      <td>0.759776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.258958</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.730201</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.764311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.288178</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.704261</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.769336</td>\n",
       "      <td>0.764777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.290117</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.718016</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.769769</td>\n",
       "      <td>0.765106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.298045</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.734417</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.773733</td>\n",
       "      <td>0.768983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.320058</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.711367</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.770401</td>\n",
       "      <td>0.766852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.320728</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.721785</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.767817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.316635</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.727946</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.769121</td>\n",
       "      <td>0.763431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.61      0.68      0.64       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.6977491961414791, F1 Micro: 0.7737330478229836, F1 Macro: 0.7689832337806624\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.61      0.68      0.64       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.058261364698410034\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.913101196289062 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304269</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.824100</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.581055</td>\n",
       "      <td>0.515030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253208</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.789792</td>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.735697</td>\n",
       "      <td>0.725431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.244975</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.759679</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.771800</td>\n",
       "      <td>0.759923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.256815</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.743894</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.772744</td>\n",
       "      <td>0.767189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.271401</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.734639</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.775205</td>\n",
       "      <td>0.768632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.278064</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.743536</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.771853</td>\n",
       "      <td>0.766297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.297332</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.727333</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>0.774762</td>\n",
       "      <td>0.769247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>0.312023</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.724161</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.773286</td>\n",
       "      <td>0.767784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.311064</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.732574</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.775727</td>\n",
       "      <td>0.770610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.317672</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.725050</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.772807</td>\n",
       "      <td>0.767272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.71      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.78      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.6971061093247588, F1 Micro: 0.7757274662881475, F1 Macro: 0.7706104711980583\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.71      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.78      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.024173581600189214\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 9.052999019622803 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310015</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.828076</td>\n",
       "      <td>0.395928</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.494897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248881</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.696833</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.729545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.243890</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.754231</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.757133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.242220</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.748939</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.772993</td>\n",
       "      <td>0.765505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.270134</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.725246</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.775868</td>\n",
       "      <td>0.770264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.290913</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.766395</td>\n",
       "      <td>0.758790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.294389</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.774240</td>\n",
       "      <td>0.768707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.321028</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.712364</td>\n",
       "      <td>0.838612</td>\n",
       "      <td>0.770350</td>\n",
       "      <td>0.766511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.323351</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.712532</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.767571</td>\n",
       "      <td>0.764115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.316287</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.732835</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.770826</td>\n",
       "      <td>0.765822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.58      0.70      0.64       237\n",
      "         radikalisme       0.71      0.89      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.78      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7035369774919614, F1 Micro: 0.7758681164503682, F1 Macro: 0.7702635689963047\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.58      0.70      0.64       237\n",
      "         radikalisme       0.71      0.89      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.78      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.04828953742980957\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.364179611206055 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 09:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281460</td>\n",
       "      <td>0.652090</td>\n",
       "      <td>0.784276</td>\n",
       "      <td>0.616893</td>\n",
       "      <td>0.690587</td>\n",
       "      <td>0.691970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.248439</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.755622</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.750201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.237754</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>0.769675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.773556</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.770628</td>\n",
       "      <td>0.756215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.260386</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.731938</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.772355</td>\n",
       "      <td>0.768453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.276196</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.730897</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.777111</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.292459</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.730615</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.774628</td>\n",
       "      <td>0.771790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.301950</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.722805</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.773492</td>\n",
       "      <td>0.769149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.299890</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.746186</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.777457</td>\n",
       "      <td>0.772420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.304362</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.749300</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.777052</td>\n",
       "      <td>0.769757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7054662379421222, F1 Micro: 0.777456647398844, F1 Macro: 0.7724196153867551\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.01313660144805908\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.563161611557007 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280129</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.724474</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.726110</td>\n",
       "      <td>0.709937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.248436</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.793411</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.727644</td>\n",
       "      <td>0.719373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297800</td>\n",
       "      <td>0.235236</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.748065</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.773935</td>\n",
       "      <td>0.769768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.239891</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.784223</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.774341</td>\n",
       "      <td>0.763832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.266946</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.736159</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.772320</td>\n",
       "      <td>0.767855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.278042</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.739792</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>0.768075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.131600</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.748951</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.777213</td>\n",
       "      <td>0.770464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.319409</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.722258</td>\n",
       "      <td>0.839367</td>\n",
       "      <td>0.776421</td>\n",
       "      <td>0.771673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.311258</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.741225</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.775099</td>\n",
       "      <td>0.769644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.314206</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.743113</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.776818</td>\n",
       "      <td>0.771719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.62      0.66      0.64       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.715112540192926, F1 Micro: 0.7772133526850509, F1 Macro: 0.7704641293942245\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.62      0.66      0.64       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.80      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.013950610160827633\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.7984299659729 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272168</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.757676</td>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.721454</td>\n",
       "      <td>0.721161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.762816</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.757311</td>\n",
       "      <td>0.756210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.240034</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.764394</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.762661</td>\n",
       "      <td>0.748587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.245899</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.768942</td>\n",
       "      <td>0.761371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.264047</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.733113</td>\n",
       "      <td>0.834842</td>\n",
       "      <td>0.780677</td>\n",
       "      <td>0.776252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.274976</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.750708</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.774288</td>\n",
       "      <td>0.766444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.292892</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.746827</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.771866</td>\n",
       "      <td>0.765986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.303168</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.775127</td>\n",
       "      <td>0.770499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.302877</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.758941</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.772673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.311789</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.748599</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.776325</td>\n",
       "      <td>0.768851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.58      0.75      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.78      1326\n",
      "           macro avg       0.73      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7093247588424437, F1 Micro: 0.7806770098730607, F1 Macro: 0.776252433539169\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.58      0.75      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.73      0.83      0.78      1326\n",
      "           macro avg       0.73      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.024097865819931025\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.246138095855713 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 10:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270330</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.769294</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.736635</td>\n",
       "      <td>0.724091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.239017</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.754124</td>\n",
       "      <td>0.743669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.248150</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.735967</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.767064</td>\n",
       "      <td>0.757677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.245634</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.778034</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.770928</td>\n",
       "      <td>0.760160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.261598</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.754676</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.772459</td>\n",
       "      <td>0.765249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.286696</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.730053</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.775972</td>\n",
       "      <td>0.772787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.287806</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.762079</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.773403</td>\n",
       "      <td>0.766964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.293510</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.756237</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.777574</td>\n",
       "      <td>0.771406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.300654</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.766862</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.777695</td>\n",
       "      <td>0.769448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.311232</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.752635</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.779192</td>\n",
       "      <td>0.772286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.712540192926045, F1 Micro: 0.7791924336122227, F1 Macro: 0.7722862991873517\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.009209966659545904\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.707566499710083 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267625</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.730530</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.718774</td>\n",
       "      <td>0.716034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.246526</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.738304</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.749814</td>\n",
       "      <td>0.748342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.232405</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.759913</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.771544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.241845</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.755957</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.772409</td>\n",
       "      <td>0.766413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.259386</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.763518</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.780686</td>\n",
       "      <td>0.771919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.719608</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>0.771008</td>\n",
       "      <td>0.765984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.284972</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.767062</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.773373</td>\n",
       "      <td>0.759352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.311881</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.744990</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.777497</td>\n",
       "      <td>0.772628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.309808</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.757706</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.776920</td>\n",
       "      <td>0.766374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.312494</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.753008</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.776926</td>\n",
       "      <td>0.768340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.62      0.63       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7163987138263666, F1 Micro: 0.7806855879100627, F1 Macro: 0.7719194805720672\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.62      0.63       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.020325028896331795\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.979373455047607 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257308</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.722513</td>\n",
       "      <td>0.719533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.234987</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.751166</td>\n",
       "      <td>0.737322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.768546</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.767863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.245493</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.761388</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.777409</td>\n",
       "      <td>0.768704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.256652</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.752592</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.785431</td>\n",
       "      <td>0.780294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.279395</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.755088</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.782261</td>\n",
       "      <td>0.773697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.297761</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.733199</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.775409</td>\n",
       "      <td>0.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.299256</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.758179</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.780381</td>\n",
       "      <td>0.770419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.307033</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.757917</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.784128</td>\n",
       "      <td>0.775999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.306226</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.761461</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.781043</td>\n",
       "      <td>0.771896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.60      0.76      0.67       237\n",
      "         radikalisme       0.70      0.88      0.78       235\n",
      "pencemaran_nama_baik       0.76      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7228295819935692, F1 Micro: 0.7854309412188965, F1 Macro: 0.7802937237399016\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.60      0.76      0.67       237\n",
      "         radikalisme       0.70      0.88      0.78       235\n",
      "pencemaran_nama_baik       0.76      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.0118179202079773\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.2845778465271 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 11:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252621</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.763382</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.752581</td>\n",
       "      <td>0.745605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.235480</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.744219</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.771522</td>\n",
       "      <td>0.763575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.233279</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.762362</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.770608</td>\n",
       "      <td>0.762285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.248906</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.750529</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.769764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.254649</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.792056</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.769683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.274322</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.752991</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.779032</td>\n",
       "      <td>0.769992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.291546</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.747928</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.774879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.304308</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.760319</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.775767</td>\n",
       "      <td>0.768105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.309328</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.751233</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.776685</td>\n",
       "      <td>0.769966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.313174</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.758941</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.771483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7118971061093248, F1 Micro: 0.7808219178082192, F1 Macro: 0.7748786061368818\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.004847490787506104\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.732814073562622 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251869</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.783830</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.736505</td>\n",
       "      <td>0.715402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308300</td>\n",
       "      <td>0.226508</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.799832</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.756262</td>\n",
       "      <td>0.740548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.224228</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.781321</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.778661</td>\n",
       "      <td>0.774360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.234813</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.778875</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.775927</td>\n",
       "      <td>0.767024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.258131</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.749141</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.783891</td>\n",
       "      <td>0.779365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.283269</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.741695</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.781150</td>\n",
       "      <td>0.775748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.286702</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.764061</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.776252</td>\n",
       "      <td>0.767954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.296074</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.756028</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.779240</td>\n",
       "      <td>0.772723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.301560</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.779230</td>\n",
       "      <td>0.772294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.069900</td>\n",
       "      <td>0.310143</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.780631</td>\n",
       "      <td>0.773355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.74      0.88      0.80       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7138263665594855, F1 Micro: 0.7838906868033082, F1 Macro: 0.7793646092836614\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.62      0.69      0.65       237\n",
      "         radikalisme       0.74      0.88      0.80       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.75      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.005424356460571289\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.9650485515594482 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244983</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.812386</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.735974</td>\n",
       "      <td>0.724830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303500</td>\n",
       "      <td>0.231560</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.783026</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.759612</td>\n",
       "      <td>0.746358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.235307</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.756719</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.771245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.234255</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.784134</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.779674</td>\n",
       "      <td>0.767862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.261429</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.762787</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.769346</td>\n",
       "      <td>0.757339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.269974</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.764490</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.775009</td>\n",
       "      <td>0.763909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118300</td>\n",
       "      <td>0.285292</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.760838</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.777122</td>\n",
       "      <td>0.766922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.295406</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.759740</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.776549</td>\n",
       "      <td>0.767520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.761075</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.775435</td>\n",
       "      <td>0.766464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.312182</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.758496</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.774456</td>\n",
       "      <td>0.765974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7144694533762058, F1 Micro: 0.781021897810219, F1 Macro: 0.7712454232148067\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.82      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.015227949619293205\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2994015216827393 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244591</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.699849</td>\n",
       "      <td>0.743292</td>\n",
       "      <td>0.731316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.234527</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.814183</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.743443</td>\n",
       "      <td>0.735705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.224326</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.778714</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.772796</td>\n",
       "      <td>0.764106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.233515</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.773407</td>\n",
       "      <td>0.761492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.245601</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.772997</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.779357</td>\n",
       "      <td>0.772814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.260677</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.768374</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.765378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.278547</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.758719</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.780666</td>\n",
       "      <td>0.772456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.296312</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.749480</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.780629</td>\n",
       "      <td>0.774399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.293371</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.779269</td>\n",
       "      <td>0.771753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.297589</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.766253</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.778479</td>\n",
       "      <td>0.771917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7183279742765273, F1 Micro: 0.7806664225558404, F1 Macro: 0.7724561114636295\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0019749879837036148\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.632524013519287 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243167</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.749630</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.756353</td>\n",
       "      <td>0.749630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.227903</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.765630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.227177</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.805099</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.770260</td>\n",
       "      <td>0.758841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.254450</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.727745</td>\n",
       "      <td>0.844646</td>\n",
       "      <td>0.781850</td>\n",
       "      <td>0.780515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.253327</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.745245</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.784132</td>\n",
       "      <td>0.778067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.262725</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.781083</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.776640</td>\n",
       "      <td>0.766739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.778354</td>\n",
       "      <td>0.768850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.291859</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.776208</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.781730</td>\n",
       "      <td>0.775841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073600</td>\n",
       "      <td>0.302769</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.786873</td>\n",
       "      <td>0.780021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.302172</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.775811</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.784489</td>\n",
       "      <td>0.776962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7234726688102894, F1 Micro: 0.7868731563421829, F1 Macro: 0.7800211301351094\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.001341700553894043\n",
      "Samples above threshold: 19\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.0065374374389648 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271169</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.678099</td>\n",
       "      <td>0.849925</td>\n",
       "      <td>0.754351</td>\n",
       "      <td>0.754286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.223192</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.780195</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.782249</td>\n",
       "      <td>0.773903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.220615</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.818723</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.769292</td>\n",
       "      <td>0.760368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.231372</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.775165</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.785262</td>\n",
       "      <td>0.776548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.254296</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.747426</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.779911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.258762</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.780562</td>\n",
       "      <td>0.773936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.782027</td>\n",
       "      <td>0.775074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.287422</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.785281</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.782905</td>\n",
       "      <td>0.777079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.305485</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>0.777611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.306281</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.769455</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.783414</td>\n",
       "      <td>0.776545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7241157556270097, F1 Micro: 0.7852623743952364, F1 Macro: 0.7765481009189894\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n",
      "Total sampling time: 181.34 seconds\n",
      "Total runtime: 11772.040750265121 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a86aae7",
   "metadata": {
    "papermill": {
     "duration": 0.039515,
     "end_time": "2024-12-17T19:27:08.089149",
     "exception": false,
     "start_time": "2024-12-17T19:27:08.049634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a86418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T19:27:08.172690Z",
     "iopub.status.busy": "2024-12-17T19:27:08.172267Z",
     "iopub.status.idle": "2024-12-17T22:42:29.033480Z",
     "shell.execute_reply": "2024-12-17T22:42:29.032542Z"
    },
    "papermill": {
     "duration": 11720.904436,
     "end_time": "2024-12-17T22:42:29.035524",
     "exception": false,
     "start_time": "2024-12-17T19:27:08.131088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466312</td>\n",
       "      <td>0.447588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392322</td>\n",
       "      <td>0.554984</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.317104</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349551</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.319759</td>\n",
       "      <td>0.462377</td>\n",
       "      <td>0.381456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331326</td>\n",
       "      <td>0.586495</td>\n",
       "      <td>0.799035</td>\n",
       "      <td>0.374811</td>\n",
       "      <td>0.510267</td>\n",
       "      <td>0.438305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317812</td>\n",
       "      <td>0.590997</td>\n",
       "      <td>0.812303</td>\n",
       "      <td>0.388386</td>\n",
       "      <td>0.525510</td>\n",
       "      <td>0.465296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312626</td>\n",
       "      <td>0.603859</td>\n",
       "      <td>0.802213</td>\n",
       "      <td>0.437406</td>\n",
       "      <td>0.566130</td>\n",
       "      <td>0.506563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301693</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.626549</td>\n",
       "      <td>0.600378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300017</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.759957</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.626164</td>\n",
       "      <td>0.598342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301048</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.765419</td>\n",
       "      <td>0.524133</td>\n",
       "      <td>0.622202</td>\n",
       "      <td>0.587982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>0.521116</td>\n",
       "      <td>0.621124</td>\n",
       "      <td>0.587391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6102893890675242, F1 Micro: 0.6265486725663717, F1 Macro: 0.6003779383425171\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9001256771385672\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 20.279946088790894 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.431681</td>\n",
       "      <td>0.481672</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.150523</td>\n",
       "      <td>0.115085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360434</td>\n",
       "      <td>0.576206</td>\n",
       "      <td>0.873362</td>\n",
       "      <td>0.301659</td>\n",
       "      <td>0.448430</td>\n",
       "      <td>0.373639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322015</td>\n",
       "      <td>0.592283</td>\n",
       "      <td>0.783967</td>\n",
       "      <td>0.435143</td>\n",
       "      <td>0.559651</td>\n",
       "      <td>0.490697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301275</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.730245</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.662546</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312008</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.749741</td>\n",
       "      <td>0.546757</td>\n",
       "      <td>0.632359</td>\n",
       "      <td>0.594849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299530</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.722128</td>\n",
       "      <td>0.644796</td>\n",
       "      <td>0.681275</td>\n",
       "      <td>0.656455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305954</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.753976</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.673069</td>\n",
       "      <td>0.650883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.313474</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.734089</td>\n",
       "      <td>0.634992</td>\n",
       "      <td>0.680954</td>\n",
       "      <td>0.654190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.313501</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.729915</td>\n",
       "      <td>0.644042</td>\n",
       "      <td>0.684295</td>\n",
       "      <td>0.668040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.316310</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.735602</td>\n",
       "      <td>0.635747</td>\n",
       "      <td>0.682039</td>\n",
       "      <td>0.660932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.84      0.86       362\n",
      "                sara       0.60      0.42      0.49       237\n",
      "         radikalisme       0.70      0.67      0.69       235\n",
      "pencemaran_nama_baik       0.67      0.60      0.63       492\n",
      "\n",
      "           micro avg       0.73      0.64      0.68      1326\n",
      "           macro avg       0.71      0.63      0.67      1326\n",
      "        weighted avg       0.72      0.64      0.68      1326\n",
      "         samples avg       0.38      0.37      0.37      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6353697749196141, F1 Micro: 0.6842948717948718, F1 Macro: 0.6680398341180707\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.84      0.86       362\n",
      "                sara       0.60      0.42      0.49       237\n",
      "         radikalisme       0.70      0.67      0.69       235\n",
      "pencemaran_nama_baik       0.67      0.60      0.63       492\n",
      "\n",
      "           micro avg       0.73      0.64      0.68      1326\n",
      "           macro avg       0.71      0.63      0.67      1326\n",
      "        weighted avg       0.72      0.64      0.68      1326\n",
      "         samples avg       0.38      0.37      0.37      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9604834452271462\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 18.34048342704773 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380186</td>\n",
       "      <td>0.561415</td>\n",
       "      <td>0.900322</td>\n",
       "      <td>0.211161</td>\n",
       "      <td>0.342089</td>\n",
       "      <td>0.240456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316414</td>\n",
       "      <td>0.594212</td>\n",
       "      <td>0.772843</td>\n",
       "      <td>0.459276</td>\n",
       "      <td>0.576159</td>\n",
       "      <td>0.508527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290471</td>\n",
       "      <td>0.613505</td>\n",
       "      <td>0.718943</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.663145</td>\n",
       "      <td>0.619180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289003</td>\n",
       "      <td>0.621222</td>\n",
       "      <td>0.713932</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.682158</td>\n",
       "      <td>0.648049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297766</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.733151</td>\n",
       "      <td>0.607089</td>\n",
       "      <td>0.664191</td>\n",
       "      <td>0.630518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.305933</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.717320</td>\n",
       "      <td>0.662142</td>\n",
       "      <td>0.688627</td>\n",
       "      <td>0.664446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.316594</td>\n",
       "      <td>0.637299</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.691397</td>\n",
       "      <td>0.670878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.316213</td>\n",
       "      <td>0.638585</td>\n",
       "      <td>0.715066</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.702723</td>\n",
       "      <td>0.687419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.322011</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.694424</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.699364</td>\n",
       "      <td>0.684138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.321270</td>\n",
       "      <td>0.632797</td>\n",
       "      <td>0.715981</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.698842</td>\n",
       "      <td>0.680184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.88      0.87       362\n",
      "                sara       0.61      0.46      0.52       237\n",
      "         radikalisme       0.68      0.73      0.70       235\n",
      "pencemaran_nama_baik       0.66      0.65      0.65       492\n",
      "\n",
      "           micro avg       0.72      0.69      0.70      1326\n",
      "           macro avg       0.70      0.68      0.69      1326\n",
      "        weighted avg       0.71      0.69      0.70      1326\n",
      "         samples avg       0.41      0.40      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6385852090032155, F1 Micro: 0.702723436900652, F1 Macro: 0.6874194850035489\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.88      0.87       362\n",
      "                sara       0.61      0.46      0.52       237\n",
      "         radikalisme       0.68      0.73      0.70       235\n",
      "pencemaran_nama_baik       0.66      0.65      0.65       492\n",
      "\n",
      "           micro avg       0.72      0.69      0.70      1326\n",
      "           macro avg       0.70      0.68      0.69      1326\n",
      "        weighted avg       0.71      0.69      0.70      1326\n",
      "         samples avg       0.41      0.40      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9160847365856173\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.579848051071167 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 05:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386353</td>\n",
       "      <td>0.567203</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.203620</td>\n",
       "      <td>0.334158</td>\n",
       "      <td>0.229097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293481</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.692542</td>\n",
       "      <td>0.677264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281488</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.772115</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.678783</td>\n",
       "      <td>0.656544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299001</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.763209</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.664395</td>\n",
       "      <td>0.604828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.305542</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.727586</td>\n",
       "      <td>0.636501</td>\n",
       "      <td>0.679002</td>\n",
       "      <td>0.645273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.287536</td>\n",
       "      <td>0.648875</td>\n",
       "      <td>0.744454</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.712544</td>\n",
       "      <td>0.699220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.295754</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.687783</td>\n",
       "      <td>0.713057</td>\n",
       "      <td>0.699573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.316333</td>\n",
       "      <td>0.636013</td>\n",
       "      <td>0.705248</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.722120</td>\n",
       "      <td>0.712118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.309833</td>\n",
       "      <td>0.647588</td>\n",
       "      <td>0.729214</td>\n",
       "      <td>0.720965</td>\n",
       "      <td>0.725066</td>\n",
       "      <td>0.715032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.313971</td>\n",
       "      <td>0.641801</td>\n",
       "      <td>0.717009</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.727138</td>\n",
       "      <td>0.719061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.90      0.88       362\n",
      "                sara       0.65      0.58      0.61       237\n",
      "         radikalisme       0.67      0.76      0.71       235\n",
      "pencemaran_nama_baik       0.66      0.68      0.67       492\n",
      "\n",
      "           micro avg       0.72      0.74      0.73      1326\n",
      "           macro avg       0.71      0.73      0.72      1326\n",
      "        weighted avg       0.72      0.74      0.73      1326\n",
      "         samples avg       0.43      0.42      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6418006430868167, F1 Micro: 0.7271375464684016, F1 Macro: 0.7190611762789676\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.85      0.90      0.88       362\n",
      "                sara       0.65      0.58      0.61       237\n",
      "         radikalisme       0.67      0.76      0.71       235\n",
      "pencemaran_nama_baik       0.66      0.68      0.67       492\n",
      "\n",
      "           micro avg       0.72      0.74      0.73      1326\n",
      "           macro avg       0.71      0.73      0.72      1326\n",
      "        weighted avg       0.72      0.74      0.73      1326\n",
      "         samples avg       0.43      0.42      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8117901474237443\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.891550064086914 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359753</td>\n",
       "      <td>0.565273</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.336010</td>\n",
       "      <td>0.234836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.733673</td>\n",
       "      <td>0.652338</td>\n",
       "      <td>0.690619</td>\n",
       "      <td>0.665151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271011</td>\n",
       "      <td>0.647588</td>\n",
       "      <td>0.772560</td>\n",
       "      <td>0.632730</td>\n",
       "      <td>0.695688</td>\n",
       "      <td>0.685945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.266707</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.733131</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.731191</td>\n",
       "      <td>0.721194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.281018</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.721937</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.731871</td>\n",
       "      <td>0.723610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.282829</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>0.743106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.300542</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.718508</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.743356</td>\n",
       "      <td>0.733588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.308406</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.727601</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.743173</td>\n",
       "      <td>0.732138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.309394</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.731921</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.743599</td>\n",
       "      <td>0.735495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.313657</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.724576</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.748359</td>\n",
       "      <td>0.740743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.91      0.88       362\n",
      "                sara       0.63      0.60      0.62       237\n",
      "         radikalisme       0.71      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.74      0.71       492\n",
      "\n",
      "           micro avg       0.72      0.77      0.75      1326\n",
      "           macro avg       0.72      0.77      0.74      1326\n",
      "        weighted avg       0.72      0.77      0.75      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6694533762057878, F1 Micro: 0.7483588621444202, F1 Macro: 0.740742975517812\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.86      0.91      0.88       362\n",
      "                sara       0.63      0.60      0.62       237\n",
      "         radikalisme       0.71      0.82      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.74      0.71       492\n",
      "\n",
      "           micro avg       0.72      0.77      0.75      1326\n",
      "           macro avg       0.72      0.77      0.74      1326\n",
      "        weighted avg       0.72      0.77      0.75      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.5142729371786122\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.498533725738525 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338668</td>\n",
       "      <td>0.563987</td>\n",
       "      <td>0.763966</td>\n",
       "      <td>0.412519</td>\n",
       "      <td>0.535749</td>\n",
       "      <td>0.420530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279870</td>\n",
       "      <td>0.647588</td>\n",
       "      <td>0.791455</td>\n",
       "      <td>0.586727</td>\n",
       "      <td>0.673885</td>\n",
       "      <td>0.661075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.262697</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.775201</td>\n",
       "      <td>0.655354</td>\n",
       "      <td>0.710257</td>\n",
       "      <td>0.695617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.277204</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.708505</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.742098</td>\n",
       "      <td>0.734619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.290331</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.752703</td>\n",
       "      <td>0.750175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.293706</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.711423</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.754516</td>\n",
       "      <td>0.751448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.312749</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.711656</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.747583</td>\n",
       "      <td>0.740654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.311848</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.750936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.327543</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.711989</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.754168</td>\n",
       "      <td>0.750980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.325884</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.715364</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.749282</td>\n",
       "      <td>0.742767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.70      0.84      0.76       235\n",
      "pencemaran_nama_baik       0.66      0.77      0.71       492\n",
      "\n",
      "           micro avg       0.72      0.80      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.72      0.80      0.76      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6739549839228296, F1 Micro: 0.7553648068669526, F1 Macro: 0.7509364479472371\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.70      0.84      0.76       235\n",
      "pencemaran_nama_baik       0.66      0.77      0.71       492\n",
      "\n",
      "           micro avg       0.72      0.80      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.72      0.80      0.76      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.16723424196243286\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 12.209644556045532 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331992</td>\n",
       "      <td>0.569132</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.291855</td>\n",
       "      <td>0.435811</td>\n",
       "      <td>0.340852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275400</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.524887</td>\n",
       "      <td>0.640884</td>\n",
       "      <td>0.605180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.257983</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.740941</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.732749</td>\n",
       "      <td>0.719736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.287859</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.688738</td>\n",
       "      <td>0.839367</td>\n",
       "      <td>0.756628</td>\n",
       "      <td>0.751689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.278985</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.725750</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.742099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.308369</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.711564</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.760534</td>\n",
       "      <td>0.754254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.305893</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.727582</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.765547</td>\n",
       "      <td>0.760423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.313344</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.723232</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.764141</td>\n",
       "      <td>0.758886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.323617</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.721629</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.765581</td>\n",
       "      <td>0.759709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.321819</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.730506</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.766141</td>\n",
       "      <td>0.759405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.63      0.66      0.64       237\n",
      "         radikalisme       0.70      0.84      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.78      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.73      0.81      0.77      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6938906752411576, F1 Micro: 0.7661406025824964, F1 Macro: 0.7594049117900403\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.63      0.66      0.64       237\n",
      "         radikalisme       0.70      0.84      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.78      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.73      0.80      0.76      1326\n",
      "        weighted avg       0.73      0.81      0.77      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.06955721974372864\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 11.038155317306519 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.324663</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.845703</td>\n",
       "      <td>0.326546</td>\n",
       "      <td>0.471164</td>\n",
       "      <td>0.431756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267965</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.738909</td>\n",
       "      <td>0.734938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.247440</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.746291</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.752431</td>\n",
       "      <td>0.743903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.255130</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.753040</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.750189</td>\n",
       "      <td>0.737269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.294900</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.698885</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.767347</td>\n",
       "      <td>0.765877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.289422</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.726783</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.768137</td>\n",
       "      <td>0.762689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.298712</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.761384</td>\n",
       "      <td>0.754992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.315075</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.730399</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.764029</td>\n",
       "      <td>0.756093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.326489</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.724764</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.766003</td>\n",
       "      <td>0.760297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.326358</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.731790</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.764100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.61      0.68      0.65       237\n",
      "         radikalisme       0.70      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.73      0.81      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.6958199356913183, F1 Micro: 0.7692307692307692, F1 Macro: 0.7641004165047378\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.61      0.68      0.65       237\n",
      "         radikalisme       0.70      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.69      0.79      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.81      0.77      1326\n",
      "           macro avg       0.73      0.81      0.76      1326\n",
      "        weighted avg       0.74      0.81      0.77      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.03221386671066284\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.956736326217651 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301830</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>0.876481</td>\n",
       "      <td>0.390649</td>\n",
       "      <td>0.540428</td>\n",
       "      <td>0.474922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.272111</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.702612</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.744236</td>\n",
       "      <td>0.745591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.244925</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.746356</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.759081</td>\n",
       "      <td>0.748577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.256461</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.728940</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.766976</td>\n",
       "      <td>0.765698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.274779</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.733920</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.773457</td>\n",
       "      <td>0.768869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.282154</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.739432</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.770675</td>\n",
       "      <td>0.767152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.326112</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.715023</td>\n",
       "      <td>0.836350</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>0.768109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.318657</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.768085</td>\n",
       "      <td>0.765611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.322928</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.766945</td>\n",
       "      <td>0.762513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.728016</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.764769</td>\n",
       "      <td>0.761443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.60      0.74      0.67       237\n",
      "         radikalisme       0.69      0.85      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.6990353697749196, F1 Micro: 0.7734570103460577, F1 Macro: 0.7688688738166694\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.60      0.74      0.67       237\n",
      "         radikalisme       0.69      0.85      0.76       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.05216557979583742\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 9.054314851760864 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285003</td>\n",
       "      <td>0.643730</td>\n",
       "      <td>0.747009</td>\n",
       "      <td>0.659125</td>\n",
       "      <td>0.700321</td>\n",
       "      <td>0.690270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250291</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.788014</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.720949</td>\n",
       "      <td>0.690408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.243039</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.751166</td>\n",
       "      <td>0.737715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.259933</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.740818</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.772120</td>\n",
       "      <td>0.768606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.277084</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.762537</td>\n",
       "      <td>0.750962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.289456</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.743937</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.764663</td>\n",
       "      <td>0.756560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.300523</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.758077</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.759503</td>\n",
       "      <td>0.747215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.324889</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.725946</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.772326</td>\n",
       "      <td>0.768143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.320642</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.737560</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.774794</td>\n",
       "      <td>0.770505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.328986</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.732928</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.772906</td>\n",
       "      <td>0.768392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.62      0.72      0.67       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7035369774919614, F1 Micro: 0.7747941281775867, F1 Macro: 0.770504582255823\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.62      0.72      0.67       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.014647561311721818\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.353179693222046 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 09:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.281472</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.521870</td>\n",
       "      <td>0.631675</td>\n",
       "      <td>0.607358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.250998</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.734520</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.755767</td>\n",
       "      <td>0.752594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.241056</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.758544</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.764222</td>\n",
       "      <td>0.761795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.250733</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.768882</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.768302</td>\n",
       "      <td>0.756612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.305109</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.692870</td>\n",
       "      <td>0.857466</td>\n",
       "      <td>0.766431</td>\n",
       "      <td>0.764691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.284499</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.739160</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.772940</td>\n",
       "      <td>0.768482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.739548</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.774865</td>\n",
       "      <td>0.771243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.318289</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.720762</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.770365</td>\n",
       "      <td>0.767047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.308597</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.748382</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.766286</td>\n",
       "      <td>0.760330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.318487</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.738796</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.766158</td>\n",
       "      <td>0.760165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.62      0.72      0.66       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7016077170418007, F1 Micro: 0.7748653500897665, F1 Macro: 0.7712430464406658\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.62      0.72      0.66       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.014285045862197872\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.525764465332031 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273518</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.822319</td>\n",
       "      <td>0.572398</td>\n",
       "      <td>0.674967</td>\n",
       "      <td>0.654683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.248402</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.738044</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.758343</td>\n",
       "      <td>0.750270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.238614</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.755703</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.764991</td>\n",
       "      <td>0.747918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.240424</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.766176</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.775875</td>\n",
       "      <td>0.767695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.264657</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.733876</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.772419</td>\n",
       "      <td>0.765537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.275815</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.775127</td>\n",
       "      <td>0.768382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.290324</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.753561</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.775092</td>\n",
       "      <td>0.766136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.309517</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.768521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.304950</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.752131</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>0.766943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.314245</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.742779</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>0.770001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.62      0.67      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7112540192926045, F1 Micro: 0.776978417266187, F1 Macro: 0.7700010738519437\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.62      0.67      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.00979846715927124\n",
      "Samples above threshold: 199\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.824963092803955 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271058</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>0.778095</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>0.687710</td>\n",
       "      <td>0.654181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.245497</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.774671</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.741149</td>\n",
       "      <td>0.717256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.254109</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.722111</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.765852</td>\n",
       "      <td>0.759929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.246729</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.775076</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.772142</td>\n",
       "      <td>0.762302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.260071</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.763433</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.756359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.269278</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.757728</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.775856</td>\n",
       "      <td>0.768244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.295425</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.743075</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.774729</td>\n",
       "      <td>0.768749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.316894</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.731053</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.773873</td>\n",
       "      <td>0.768629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.316850</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.742275</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.768727</td>\n",
       "      <td>0.760365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.316331</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.755540</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.775780</td>\n",
       "      <td>0.767794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7118971061093248, F1 Micro: 0.7758557232241443, F1 Macro: 0.7682435522371613\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.62      0.65      0.63       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.019610053300857543\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.242610454559326 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264586</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.779930</td>\n",
       "      <td>0.668175</td>\n",
       "      <td>0.719740</td>\n",
       "      <td>0.708970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.237022</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.777414</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.745683</td>\n",
       "      <td>0.734907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.237559</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.742797</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.769007</td>\n",
       "      <td>0.763669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.252840</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.729514</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.774673</td>\n",
       "      <td>0.769845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.256575</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.769117</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.775159</td>\n",
       "      <td>0.762896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.277530</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.759485</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.779288</td>\n",
       "      <td>0.771210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.296801</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.753060</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.770534</td>\n",
       "      <td>0.763058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.309432</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.758671</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>0.766620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.313752</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.777251</td>\n",
       "      <td>0.770828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.316048</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.770051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.70      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.715112540192926, F1 Micro: 0.7792875504957767, F1 Macro: 0.7712104605913823\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.70      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.01286957263946534\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.69666862487793 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263211</td>\n",
       "      <td>0.658521</td>\n",
       "      <td>0.782332</td>\n",
       "      <td>0.647813</td>\n",
       "      <td>0.708746</td>\n",
       "      <td>0.684397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.232252</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.769578</td>\n",
       "      <td>0.761967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.237883</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.766616</td>\n",
       "      <td>0.759146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.272871</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.706324</td>\n",
       "      <td>0.850679</td>\n",
       "      <td>0.771810</td>\n",
       "      <td>0.767685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.253684</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.766281</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.782127</td>\n",
       "      <td>0.773983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.280084</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.748619</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.781543</td>\n",
       "      <td>0.777284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.285924</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.753501</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.781409</td>\n",
       "      <td>0.775877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.304780</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.751397</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.780276</td>\n",
       "      <td>0.773481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.307812</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.753674</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.781851</td>\n",
       "      <td>0.775530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.306636</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.757123</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.778755</td>\n",
       "      <td>0.771472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7215434083601286, F1 Micro: 0.7821270310192024, F1 Macro: 0.7739832360408307\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.017988085746765137\n",
      "Samples above threshold: 138\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.930703401565552 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256315</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.751152</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.744292</td>\n",
       "      <td>0.737274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.230432</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.788933</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.770359</td>\n",
       "      <td>0.757599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.228749</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.769115</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.762616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.247729</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.742759</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.775937</td>\n",
       "      <td>0.771293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.258253</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.785261</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.765842</td>\n",
       "      <td>0.753093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.274176</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.777949</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.769348</td>\n",
       "      <td>0.756235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.290985</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.771281</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.778483</td>\n",
       "      <td>0.767145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.305053</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.757234</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.782355</td>\n",
       "      <td>0.776199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.310521</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.767425</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.777984</td>\n",
       "      <td>0.768746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.308962</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.768337</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.782834</td>\n",
       "      <td>0.773058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.92      0.93       362\n",
      "                sara       0.65      0.62      0.63       237\n",
      "         radikalisme       0.73      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7170418006430869, F1 Micro: 0.7828338882722901, F1 Macro: 0.7730581931686621\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.92      0.93       362\n",
      "                sara       0.65      0.62      0.63       237\n",
      "         radikalisme       0.73      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.0041475057601928714\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.233571767807007 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248887</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.771774</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.745908</td>\n",
       "      <td>0.736780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.230368</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.753791</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.770195</td>\n",
       "      <td>0.764243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.233209</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.781216</td>\n",
       "      <td>0.773538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.243412</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.777492</td>\n",
       "      <td>0.771163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.250318</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.791994</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.776154</td>\n",
       "      <td>0.766316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.277446</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.753025</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.774808</td>\n",
       "      <td>0.764704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.301297</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.743466</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.777698</td>\n",
       "      <td>0.770358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.302328</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.756345</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.771165</td>\n",
       "      <td>0.762242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.312956</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.775127</td>\n",
       "      <td>0.766875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.313010</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.759339</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.768225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.712540192926045, F1 Micro: 0.7812158718602111, F1 Macro: 0.7735377040991654\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.71      0.87      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.04359447956085205\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.756143569946289 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.748349</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.758646</td>\n",
       "      <td>0.752101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.228923</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.783635</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.767039</td>\n",
       "      <td>0.760863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.229346</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.780562</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.777904</td>\n",
       "      <td>0.766037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.237970</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.801639</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.768264</td>\n",
       "      <td>0.760081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152900</td>\n",
       "      <td>0.247603</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.772321</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.777528</td>\n",
       "      <td>0.767680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.271466</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.739451</td>\n",
       "      <td>0.832579</td>\n",
       "      <td>0.783256</td>\n",
       "      <td>0.778238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.279669</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.783543</td>\n",
       "      <td>0.775900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.756910</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.780417</td>\n",
       "      <td>0.773867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.775063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.301441</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.771533</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.784125</td>\n",
       "      <td>0.775662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7221864951768489, F1 Micro: 0.7841246290801188, F1 Macro: 0.7756621005810953\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0027400970458984373\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0224030017852783 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245015</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.798605</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.740801</td>\n",
       "      <td>0.724306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.225413</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.780093</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.771167</td>\n",
       "      <td>0.762736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.234711</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.770106</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.767776</td>\n",
       "      <td>0.761036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209100</td>\n",
       "      <td>0.240481</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.790386</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.773025</td>\n",
       "      <td>0.760408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153800</td>\n",
       "      <td>0.253851</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.784547</td>\n",
       "      <td>0.774466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.272798</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.773766</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.782706</td>\n",
       "      <td>0.775142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.278816</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.786798</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.784418</td>\n",
       "      <td>0.776588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.299114</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.767948</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.782994</td>\n",
       "      <td>0.776660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.302301</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.778443</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.781367</td>\n",
       "      <td>0.773055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.312619</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.764579</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.782320</td>\n",
       "      <td>0.775610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.74      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7247588424437299, F1 Micro: 0.7845468053491828, F1 Macro: 0.774466169414045\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.74      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0049104571342468255\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2727208137512207 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243294</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.760031</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.751335</td>\n",
       "      <td>0.745549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.235874</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.736771</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.775714</td>\n",
       "      <td>0.772127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.245944</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.721022</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>0.771819</td>\n",
       "      <td>0.765752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.236757</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.791009</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.773323</td>\n",
       "      <td>0.758131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.250745</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.779510</td>\n",
       "      <td>0.770768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.267022</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.783825</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.782937</td>\n",
       "      <td>0.774903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.283130</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.779699</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.780873</td>\n",
       "      <td>0.771406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.290102</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.769455</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.783414</td>\n",
       "      <td>0.777105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.299908</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.771778</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.789687</td>\n",
       "      <td>0.784131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>0.303305</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.768953</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.785688</td>\n",
       "      <td>0.778358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.81      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7247588424437299, F1 Micro: 0.7896869244935544, F1 Macro: 0.7841308499155537\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.81      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0017831444740295415\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.5437359809875488 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243668</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.763593</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.746821</td>\n",
       "      <td>0.744343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.227754</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.781216</td>\n",
       "      <td>0.777491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>0.240191</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.732581</td>\n",
       "      <td>0.832579</td>\n",
       "      <td>0.779386</td>\n",
       "      <td>0.771905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.234289</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.788743</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.780023</td>\n",
       "      <td>0.769668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.241465</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.775618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>0.264417</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.762272</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.789971</td>\n",
       "      <td>0.782713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.277891</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.782641</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.789080</td>\n",
       "      <td>0.782645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.279970</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.793602</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.789693</td>\n",
       "      <td>0.781721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.308196</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.762105</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.789531</td>\n",
       "      <td>0.782845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.304432</td>\n",
       "      <td>0.731833</td>\n",
       "      <td>0.773055</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.790715</td>\n",
       "      <td>0.783235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.93       362\n",
      "                sara       0.64      0.67      0.66       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7318327974276527, F1 Micro: 0.7907148120854827, F1 Macro: 0.783234866425879\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.93       362\n",
      "                sara       0.64      0.67      0.66       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0010763764381408693\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.0363752841949463 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239288</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.791737</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.747611</td>\n",
       "      <td>0.736008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.228361</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.774316</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.771385</td>\n",
       "      <td>0.757855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.225194</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.788941</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.776245</td>\n",
       "      <td>0.765057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.241487</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.749653</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.781069</td>\n",
       "      <td>0.772533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.249673</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.783723</td>\n",
       "      <td>0.774061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.258645</td>\n",
       "      <td>0.737621</td>\n",
       "      <td>0.796649</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.792725</td>\n",
       "      <td>0.784620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.280762</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.778271</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.786114</td>\n",
       "      <td>0.780042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.750858</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.786202</td>\n",
       "      <td>0.780988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.305839</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.775256</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.786776</td>\n",
       "      <td>0.781119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.769342</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.785530</td>\n",
       "      <td>0.780192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       362\n",
      "                sara       0.70      0.63      0.66       237\n",
      "         radikalisme       0.77      0.82      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.80      0.79      0.79      1326\n",
      "           macro avg       0.79      0.78      0.78      1326\n",
      "        weighted avg       0.80      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.737620578778135, F1 Micro: 0.7927245168624478, F1 Macro: 0.78461996324161\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       362\n",
      "                sara       0.70      0.63      0.66       237\n",
      "         radikalisme       0.77      0.82      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.80      0.79      0.79      1326\n",
      "           macro avg       0.79      0.78      0.78      1326\n",
      "        weighted avg       0.80      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n",
      "Total sampling time: 181.29 seconds\n",
      "Total runtime: 11719.892806529999 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82e788",
   "metadata": {},
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541586d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4376d6007a714e2095c1688f0209c8ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicost918\u001b[0m (\u001b[33mnicost918-petra-christian-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241218_035041-0c14e40a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-lc-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/0c14e40a\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.462379</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.049751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391793</td>\n",
       "      <td>0.568489</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.278281</td>\n",
       "      <td>0.416949</td>\n",
       "      <td>0.340929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357158</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.250377</td>\n",
       "      <td>0.389215</td>\n",
       "      <td>0.305181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331397</td>\n",
       "      <td>0.590354</td>\n",
       "      <td>0.783858</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.557122</td>\n",
       "      <td>0.487882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317543</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.790637</td>\n",
       "      <td>0.458522</td>\n",
       "      <td>0.580430</td>\n",
       "      <td>0.516101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307228</td>\n",
       "      <td>0.619293</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>0.515083</td>\n",
       "      <td>0.620627</td>\n",
       "      <td>0.590389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304412</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.775442</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.586116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.763407</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.605725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302151</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.764644</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.640666</td>\n",
       "      <td>0.610989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300772</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.751984</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.649529</td>\n",
       "      <td>0.626356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6289389067524116, F1 Micro: 0.6495287060839761, F1 Macro: 0.626355645176144\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8938983887434007\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 19.815344095230103 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.444130</td>\n",
       "      <td>0.502251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.104827</td>\n",
       "      <td>0.189761</td>\n",
       "      <td>0.138723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330863</td>\n",
       "      <td>0.576206</td>\n",
       "      <td>0.797357</td>\n",
       "      <td>0.409502</td>\n",
       "      <td>0.541106</td>\n",
       "      <td>0.473706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301122</td>\n",
       "      <td>0.632797</td>\n",
       "      <td>0.748555</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.657360</td>\n",
       "      <td>0.630764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.315555</td>\n",
       "      <td>0.613505</td>\n",
       "      <td>0.776190</td>\n",
       "      <td>0.491704</td>\n",
       "      <td>0.602031</td>\n",
       "      <td>0.581193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299027</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.692654</td>\n",
       "      <td>0.696833</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.676591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305990</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.718227</td>\n",
       "      <td>0.647813</td>\n",
       "      <td>0.681205</td>\n",
       "      <td>0.665327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309180</td>\n",
       "      <td>0.632154</td>\n",
       "      <td>0.726098</td>\n",
       "      <td>0.635747</td>\n",
       "      <td>0.677925</td>\n",
       "      <td>0.661940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.318195</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.710098</td>\n",
       "      <td>0.657617</td>\n",
       "      <td>0.682850</td>\n",
       "      <td>0.663449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.153600</td>\n",
       "      <td>0.321354</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.722269</td>\n",
       "      <td>0.643288</td>\n",
       "      <td>0.680495</td>\n",
       "      <td>0.665551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.153600</td>\n",
       "      <td>0.322750</td>\n",
       "      <td>0.633441</td>\n",
       "      <td>0.716903</td>\n",
       "      <td>0.649321</td>\n",
       "      <td>0.681440</td>\n",
       "      <td>0.666858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.79      0.84       362\n",
      "                sara       0.64      0.51      0.57       237\n",
      "         radikalisme       0.58      0.63      0.60       235\n",
      "pencemaran_nama_baik       0.65      0.75      0.69       492\n",
      "\n",
      "           micro avg       0.69      0.70      0.69      1326\n",
      "           macro avg       0.69      0.67      0.68      1326\n",
      "        weighted avg       0.70      0.70      0.70      1326\n",
      "         samples avg       0.39      0.39      0.38      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.62508038585209, F1 Micro: 0.6947368421052631, F1 Macro: 0.6765913030860169\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.79      0.84       362\n",
      "                sara       0.64      0.51      0.57       237\n",
      "         radikalisme       0.58      0.63      0.60       235\n",
      "pencemaran_nama_baik       0.65      0.75      0.69       492\n",
      "\n",
      "           micro avg       0.69      0.70      0.69      1326\n",
      "           macro avg       0.69      0.67      0.68      1326\n",
      "        weighted avg       0.70      0.70      0.70      1326\n",
      "         samples avg       0.39      0.39      0.38      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9036853894591333\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 17.85330605506897 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.416357</td>\n",
       "      <td>0.549196</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.284062</td>\n",
       "      <td>0.201475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310296</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.776271</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.621438</td>\n",
       "      <td>0.598352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.308178</td>\n",
       "      <td>0.630868</td>\n",
       "      <td>0.685535</td>\n",
       "      <td>0.657617</td>\n",
       "      <td>0.671286</td>\n",
       "      <td>0.668668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.292395</td>\n",
       "      <td>0.643730</td>\n",
       "      <td>0.719967</td>\n",
       "      <td>0.655354</td>\n",
       "      <td>0.686143</td>\n",
       "      <td>0.672406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297415</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.730964</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.688995</td>\n",
       "      <td>0.679137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.327460</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.650754</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.710075</td>\n",
       "      <td>0.706530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.322523</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.676630</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.711937</td>\n",
       "      <td>0.703559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.325789</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>0.737118</td>\n",
       "      <td>0.636501</td>\n",
       "      <td>0.683124</td>\n",
       "      <td>0.666735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.329062</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.713496</td>\n",
       "      <td>0.681750</td>\n",
       "      <td>0.697262</td>\n",
       "      <td>0.687439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.150100</td>\n",
       "      <td>0.329809</td>\n",
       "      <td>0.643730</td>\n",
       "      <td>0.708270</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.702888</td>\n",
       "      <td>0.694133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.84      0.85       362\n",
      "                sara       0.57      0.57      0.57       237\n",
      "         radikalisme       0.61      0.83      0.71       235\n",
      "pencemaran_nama_baik       0.64      0.74      0.68       492\n",
      "\n",
      "           micro avg       0.68      0.75      0.71      1326\n",
      "           macro avg       0.67      0.74      0.70      1326\n",
      "        weighted avg       0.68      0.75      0.71      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.639871382636656, F1 Micro: 0.7119370979270907, F1 Macro: 0.7035591122963345\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.84      0.85       362\n",
      "                sara       0.57      0.57      0.57       237\n",
      "         radikalisme       0.61      0.83      0.71       235\n",
      "pencemaran_nama_baik       0.64      0.74      0.68       492\n",
      "\n",
      "           micro avg       0.68      0.75      0.71      1326\n",
      "           macro avg       0.67      0.74      0.70      1326\n",
      "        weighted avg       0.68      0.75      0.71      1326\n",
      "         samples avg       0.42      0.43      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8686201184988026\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.096834182739258 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356887</td>\n",
       "      <td>0.567846</td>\n",
       "      <td>0.882653</td>\n",
       "      <td>0.260935</td>\n",
       "      <td>0.402794</td>\n",
       "      <td>0.292652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301741</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>0.770742</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.629795</td>\n",
       "      <td>0.616624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322707</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.605490</td>\n",
       "      <td>0.848416</td>\n",
       "      <td>0.706658</td>\n",
       "      <td>0.704701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.292754</td>\n",
       "      <td>0.638585</td>\n",
       "      <td>0.679452</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.712132</td>\n",
       "      <td>0.711098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.298174</td>\n",
       "      <td>0.641158</td>\n",
       "      <td>0.683578</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.725212</td>\n",
       "      <td>0.723104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.652090</td>\n",
       "      <td>0.705219</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.728863</td>\n",
       "      <td>0.724491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.304110</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.720419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.312404</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.719273</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.732321</td>\n",
       "      <td>0.729324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.321894</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.703266</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.732007</td>\n",
       "      <td>0.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.325584</td>\n",
       "      <td>0.659164</td>\n",
       "      <td>0.702759</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.734150</td>\n",
       "      <td>0.730330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.87      0.87       362\n",
      "                sara       0.61      0.65      0.63       237\n",
      "         radikalisme       0.67      0.82      0.73       235\n",
      "pencemaran_nama_baik       0.65      0.73      0.69       492\n",
      "\n",
      "           micro avg       0.70      0.77      0.73      1326\n",
      "           macro avg       0.70      0.77      0.73      1326\n",
      "        weighted avg       0.71      0.77      0.74      1326\n",
      "         samples avg       0.42      0.44      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6591639871382636, F1 Micro: 0.734149855907781, F1 Macro: 0.7303303425644769\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.87      0.87       362\n",
      "                sara       0.61      0.65      0.63       237\n",
      "         radikalisme       0.67      0.82      0.73       235\n",
      "pencemaran_nama_baik       0.65      0.73      0.69       492\n",
      "\n",
      "           micro avg       0.70      0.77      0.73      1326\n",
      "           macro avg       0.70      0.77      0.73      1326\n",
      "        weighted avg       0.71      0.77      0.74      1326\n",
      "         samples avg       0.42      0.44      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8139048308134079\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.540822744369507 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372898</td>\n",
       "      <td>0.561415</td>\n",
       "      <td>0.957529</td>\n",
       "      <td>0.187029</td>\n",
       "      <td>0.312934</td>\n",
       "      <td>0.218234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301439</td>\n",
       "      <td>0.615434</td>\n",
       "      <td>0.824611</td>\n",
       "      <td>0.439668</td>\n",
       "      <td>0.573537</td>\n",
       "      <td>0.544169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267420</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.770985</td>\n",
       "      <td>0.637255</td>\n",
       "      <td>0.697770</td>\n",
       "      <td>0.687884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.272416</td>\n",
       "      <td>0.657235</td>\n",
       "      <td>0.756345</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.712919</td>\n",
       "      <td>0.699861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.283523</td>\n",
       "      <td>0.652090</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.738147</td>\n",
       "      <td>0.729857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.288519</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.725899</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.743004</td>\n",
       "      <td>0.736651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.306019</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.712989</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.740392</td>\n",
       "      <td>0.737029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.309596</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.717227</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.745471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.321098</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.751334</td>\n",
       "      <td>0.745432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.318144</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.718125</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.750450</td>\n",
       "      <td>0.746274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.88      0.88       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.67      0.80      0.73       235\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.80      0.75      1326\n",
      "           macro avg       0.71      0.79      0.75      1326\n",
      "        weighted avg       0.72      0.80      0.75      1326\n",
      "         samples avg       0.43      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6707395498392283, F1 Micro: 0.7513340448239061, F1 Macro: 0.745432261171179\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.88      0.88       362\n",
      "                sara       0.61      0.69      0.65       237\n",
      "         radikalisme       0.67      0.80      0.73       235\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.80      0.75      1326\n",
      "           macro avg       0.71      0.79      0.75      1326\n",
      "        weighted avg       0.72      0.80      0.75      1326\n",
      "         samples avg       0.43      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.5137405484914781\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.075809478759766 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.339968</td>\n",
       "      <td>0.579421</td>\n",
       "      <td>0.867965</td>\n",
       "      <td>0.302413</td>\n",
       "      <td>0.448546</td>\n",
       "      <td>0.363854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277708</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.762257</td>\n",
       "      <td>0.621418</td>\n",
       "      <td>0.684670</td>\n",
       "      <td>0.672838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.269053</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.711923</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.743968</td>\n",
       "      <td>0.738645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.268142</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.743089</td>\n",
       "      <td>0.733001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.272136</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.752404</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.729604</td>\n",
       "      <td>0.712354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.291127</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.739535</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.729358</td>\n",
       "      <td>0.714616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.303268</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.703412</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.746659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.312357</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.705607</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.748584</td>\n",
       "      <td>0.741595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.314505</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.706851</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.754571</td>\n",
       "      <td>0.749414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.315821</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.710438</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.750623</td>\n",
       "      <td>0.744643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.89      0.89       362\n",
      "                sara       0.59      0.69      0.64       237\n",
      "         radikalisme       0.69      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.80      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.81      0.75      1326\n",
      "           macro avg       0.71      0.80      0.75      1326\n",
      "        weighted avg       0.71      0.81      0.76      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6694533762057878, F1 Micro: 0.7545710267229255, F1 Macro: 0.7494140056784451\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.89      0.89       362\n",
      "                sara       0.59      0.69      0.64       237\n",
      "         radikalisme       0.69      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.66      0.80      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.81      0.75      1326\n",
      "           macro avg       0.71      0.80      0.75      1326\n",
      "        weighted avg       0.71      0.81      0.76      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.21468675136566162\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 11.824037313461304 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329788</td>\n",
       "      <td>0.566559</td>\n",
       "      <td>0.916418</td>\n",
       "      <td>0.231523</td>\n",
       "      <td>0.369657</td>\n",
       "      <td>0.301617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267343</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.719942</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.736648</td>\n",
       "      <td>0.729596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.255544</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.723994</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.754335</td>\n",
       "      <td>0.747537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.268451</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.709197</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.763066</td>\n",
       "      <td>0.759910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.283625</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.722517</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.769394</td>\n",
       "      <td>0.765667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.314563</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.696049</td>\n",
       "      <td>0.863499</td>\n",
       "      <td>0.770784</td>\n",
       "      <td>0.767642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.305070</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.719504</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.771598</td>\n",
       "      <td>0.769638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.314757</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.719035</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.771329</td>\n",
       "      <td>0.766963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.320715</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.715667</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.771637</td>\n",
       "      <td>0.770978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.319182</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.720991</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.773427</td>\n",
       "      <td>0.770440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.60      0.78      0.68       237\n",
      "         radikalisme       0.69      0.84      0.76       235\n",
      "pencemaran_nama_baik       0.68      0.82      0.74       492\n",
      "\n",
      "           micro avg       0.72      0.83      0.77      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6881028938906752, F1 Micro: 0.7734265734265735, F1 Macro: 0.7704396634352745\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.90       362\n",
      "                sara       0.60      0.78      0.68       237\n",
      "         radikalisme       0.69      0.84      0.76       235\n",
      "pencemaran_nama_baik       0.68      0.82      0.74       492\n",
      "\n",
      "           micro avg       0.72      0.83      0.77      1326\n",
      "           macro avg       0.72      0.83      0.77      1326\n",
      "        weighted avg       0.73      0.83      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.08390694856643677\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.689727544784546 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.305846</td>\n",
       "      <td>0.606431</td>\n",
       "      <td>0.823358</td>\n",
       "      <td>0.425339</td>\n",
       "      <td>0.560915</td>\n",
       "      <td>0.538026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258356</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.744859</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.741190</td>\n",
       "      <td>0.739233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.255467</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.740129</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.758367</td>\n",
       "      <td>0.749245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.252748</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.775237</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.757903</td>\n",
       "      <td>0.746809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.283485</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.709332</td>\n",
       "      <td>0.848416</td>\n",
       "      <td>0.772665</td>\n",
       "      <td>0.768372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.289086</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.719287</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.766901</td>\n",
       "      <td>0.760123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.296086</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.729602</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.770381</td>\n",
       "      <td>0.765589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.298215</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.767773</td>\n",
       "      <td>0.759607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.312681</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.732794</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.768307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.317861</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.731987</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.773390</td>\n",
       "      <td>0.767841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.6932475884244373, F1 Micro: 0.7735042735042735, F1 Macro: 0.7683068804264714\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.72      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.81      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.048078835010528564\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.60176396369934 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346357</td>\n",
       "      <td>0.539550</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.350515</td>\n",
       "      <td>0.323555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249285</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.763911</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.743808</td>\n",
       "      <td>0.739347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.248848</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.759563</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.746452</td>\n",
       "      <td>0.731111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.259507</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.729748</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.767084</td>\n",
       "      <td>0.758418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.743825</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.768502</td>\n",
       "      <td>0.763066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.726902</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.764832</td>\n",
       "      <td>0.758896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.285713</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.749284</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.768553</td>\n",
       "      <td>0.759156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.731233</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.774308</td>\n",
       "      <td>0.770346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.302738</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.760361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.314379</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.735213</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.769065</td>\n",
       "      <td>0.762808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.60      0.74      0.66       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7016077170418007, F1 Micro: 0.7743080198722498, F1 Macro: 0.7703455518757695\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.60      0.74      0.66       237\n",
      "         radikalisme       0.71      0.85      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.82      0.77      1326\n",
      "           macro avg       0.73      0.82      0.77      1326\n",
      "        weighted avg       0.74      0.82      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.03217780590057375\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 8.778464317321777 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296707</td>\n",
       "      <td>0.645659</td>\n",
       "      <td>0.724165</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.705108</td>\n",
       "      <td>0.697085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248424</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.782933</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.746151</td>\n",
       "      <td>0.740468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.247733</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.755390</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.760764</td>\n",
       "      <td>0.753469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.284200</td>\n",
       "      <td>0.251726</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.765568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.277662</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.841629</td>\n",
       "      <td>0.774731</td>\n",
       "      <td>0.772780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.281616</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.739792</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>0.762986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.288267</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.744990</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.777497</td>\n",
       "      <td>0.771858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.325578</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.713203</td>\n",
       "      <td>0.851433</td>\n",
       "      <td>0.776212</td>\n",
       "      <td>0.772690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.313053</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.736388</td>\n",
       "      <td>0.836350</td>\n",
       "      <td>0.783192</td>\n",
       "      <td>0.779963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.312386</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.742045</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.782019</td>\n",
       "      <td>0.778036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.62      0.75      0.68       237\n",
      "         radikalisme       0.70      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.78      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7080385852090032, F1 Micro: 0.7831920903954803, F1 Macro: 0.779962823685988\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.62      0.75      0.68       237\n",
      "         radikalisme       0.70      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.78      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.016597557067871103\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.072646617889404 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278466</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.790766</td>\n",
       "      <td>0.607089</td>\n",
       "      <td>0.686860</td>\n",
       "      <td>0.679124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.290800</td>\n",
       "      <td>0.245998</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.806335</td>\n",
       "      <td>0.671946</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.722982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.290800</td>\n",
       "      <td>0.238193</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.776990</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.759923</td>\n",
       "      <td>0.748016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.242791</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.785884</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.766138</td>\n",
       "      <td>0.755682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.271864</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.728620</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.769833</td>\n",
       "      <td>0.767973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.265992</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.783282</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.763650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.285968</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.756776</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.777859</td>\n",
       "      <td>0.771204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.305961</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.736382</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.778528</td>\n",
       "      <td>0.773975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.742069</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.775216</td>\n",
       "      <td>0.767453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.310883</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.742561</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.774450</td>\n",
       "      <td>0.767217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7080385852090032, F1 Micro: 0.7785282616423747, F1 Macro: 0.773975022289337\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.013437092304229735\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.299011945724487 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275942</td>\n",
       "      <td>0.657878</td>\n",
       "      <td>0.710469</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.725931</td>\n",
       "      <td>0.723585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.241657</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.769110</td>\n",
       "      <td>0.736048</td>\n",
       "      <td>0.752216</td>\n",
       "      <td>0.743413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.240947</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.754075</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.777494</td>\n",
       "      <td>0.769531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.736916</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.765495</td>\n",
       "      <td>0.757905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.752340</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.769797</td>\n",
       "      <td>0.761391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.281507</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.772495</td>\n",
       "      <td>0.766479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.302138</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.734014</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.771817</td>\n",
       "      <td>0.765081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.304931</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.747857</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.768158</td>\n",
       "      <td>0.759720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.316380</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.735616</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.770998</td>\n",
       "      <td>0.763768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.317713</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.740278</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.770788</td>\n",
       "      <td>0.764104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7157556270096463, F1 Micro: 0.7774936061381074, F1 Macro: 0.769530932410716\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.66      0.64      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.09872881770133972\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.590763092041016 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271003</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.742292</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.724817</td>\n",
       "      <td>0.719587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.245221</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.732365</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.759462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.238398</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.769112</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.760015</td>\n",
       "      <td>0.752545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.242466</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.757598</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>0.756729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.255189</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.755334</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.777452</td>\n",
       "      <td>0.770950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.744105</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.775289</td>\n",
       "      <td>0.768449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>0.284810</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.754110</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.767228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.292214</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.758321</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.774003</td>\n",
       "      <td>0.767107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.301002</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.757971</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.773097</td>\n",
       "      <td>0.766703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.310449</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.752307</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.769103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.76      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7054662379421222, F1 Micro: 0.7774524158125915, F1 Macro: 0.7709502906666368\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.76      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.026171576976776113\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 5.9936583042144775 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271038</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.789084</td>\n",
       "      <td>0.643288</td>\n",
       "      <td>0.708766</td>\n",
       "      <td>0.697079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.244173</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.739024</td>\n",
       "      <td>0.731228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.236142</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.782362</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.754879</td>\n",
       "      <td>0.747108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.245565</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.740843</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.773170</td>\n",
       "      <td>0.768011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.258603</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.760088</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.770547</td>\n",
       "      <td>0.761380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.277540</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.745595</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.770856</td>\n",
       "      <td>0.763548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.289042</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.750704</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.776402</td>\n",
       "      <td>0.771793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>0.286634</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.775969</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.765291</td>\n",
       "      <td>0.754597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.297916</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.772795</td>\n",
       "      <td>0.764226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.309868</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.748432</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.777979</td>\n",
       "      <td>0.772118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.63      0.68      0.66       237\n",
      "         radikalisme       0.72      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7144694533762058, F1 Micro: 0.7779789931184354, F1 Macro: 0.7721179125209016\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.63      0.68      0.66       237\n",
      "         radikalisme       0.72      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.70      0.78      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.011598050594329834\n",
      "Samples above threshold: 161\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.464770078659058 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260304</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.750781</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.737529</td>\n",
       "      <td>0.732946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.237471</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.758775</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.762477</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.228880</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.768999</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.769868</td>\n",
       "      <td>0.763655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.245126</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.731025</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.776521</td>\n",
       "      <td>0.772117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.245055</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.785004</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.779339</td>\n",
       "      <td>0.767365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.261837</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.765522</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.777737</td>\n",
       "      <td>0.769908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.283090</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.748945</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.775109</td>\n",
       "      <td>0.769704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.302606</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.739042</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.780349</td>\n",
       "      <td>0.775836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.301425</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.747911</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.777697</td>\n",
       "      <td>0.770598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.302546</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.752801</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.780683</td>\n",
       "      <td>0.774559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.74      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7183279742765273, F1 Micro: 0.7806826434277414, F1 Macro: 0.774559325331042\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.74      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.004984986782073975\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.775598764419556 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259149</td>\n",
       "      <td>0.670096</td>\n",
       "      <td>0.750796</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.730442</td>\n",
       "      <td>0.725570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.236169</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.756496</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.762439</td>\n",
       "      <td>0.758265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.306500</td>\n",
       "      <td>0.232303</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.758646</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.775976</td>\n",
       "      <td>0.772643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.238710</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.775094</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.766040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.277349</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.716380</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.776511</td>\n",
       "      <td>0.772144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.148600</td>\n",
       "      <td>0.273679</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.748428</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.776931</td>\n",
       "      <td>0.767411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.307729</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.837104</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>0.776384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.760059</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.771630</td>\n",
       "      <td>0.763172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.308554</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.751933</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.778465</td>\n",
       "      <td>0.770108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.762491</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.777983</td>\n",
       "      <td>0.770183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.93      0.91       362\n",
      "                sara       0.61      0.72      0.66       237\n",
      "         radikalisme       0.70      0.88      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.83      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.78      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.715112540192926, F1 Micro: 0.7822410147991543, F1 Macro: 0.7763837491561971\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.93      0.91       362\n",
      "                sara       0.61      0.72      0.66       237\n",
      "         radikalisme       0.70      0.88      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.73      0.84      0.78      1326\n",
      "           macro avg       0.73      0.83      0.78      1326\n",
      "        weighted avg       0.74      0.84      0.78      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.004929125308990482\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.120500326156616 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250613</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.716919</td>\n",
       "      <td>0.710446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.235575</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.833969</td>\n",
       "      <td>0.659125</td>\n",
       "      <td>0.736310</td>\n",
       "      <td>0.716609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301800</td>\n",
       "      <td>0.222461</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.768105</td>\n",
       "      <td>0.755892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.240357</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.752131</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>0.769071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.263847</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.740358</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.773938</td>\n",
       "      <td>0.769198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>0.285546</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.733468</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.774217</td>\n",
       "      <td>0.768827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.277339</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.766889</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.772914</td>\n",
       "      <td>0.767923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.296166</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.746469</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.770970</td>\n",
       "      <td>0.762525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.303264</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.754703</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.770310</td>\n",
       "      <td>0.763222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.303320</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.759410</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.767624</td>\n",
       "      <td>0.758361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7093247588424437, F1 Micro: 0.7746891002194586, F1 Macro: 0.7690709121958127\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.021856379508972176\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.560370683670044 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260514</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.844519</td>\n",
       "      <td>0.569382</td>\n",
       "      <td>0.680180</td>\n",
       "      <td>0.674237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.228957</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.769404</td>\n",
       "      <td>0.759324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.230210</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.788263</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.768458</td>\n",
       "      <td>0.752319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.234236</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.783721</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.772936</td>\n",
       "      <td>0.757771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.255873</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.800165</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.763894</td>\n",
       "      <td>0.746877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.269553</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.764355</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.768654</td>\n",
       "      <td>0.756279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.292946</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.751927</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.779513</td>\n",
       "      <td>0.773386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.301430</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.759178</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.769345</td>\n",
       "      <td>0.759192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.307682</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.761561</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.777860</td>\n",
       "      <td>0.768610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.309267</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.764103</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.775177</td>\n",
       "      <td>0.765968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7144694533762058, F1 Micro: 0.7795132582637123, F1 Macro: 0.7733857083111553\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0035712480545043944\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.8612165451049805 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248241</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.742402</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.757755</td>\n",
       "      <td>0.751358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301200</td>\n",
       "      <td>0.233004</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.773865</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.759601</td>\n",
       "      <td>0.747573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.233211</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.757465</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.770656</td>\n",
       "      <td>0.759125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.238960</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.779803</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.777147</td>\n",
       "      <td>0.763838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.252859</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.770302</td>\n",
       "      <td>0.760316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.265510</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.774024</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.775771</td>\n",
       "      <td>0.767474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.286961</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.764275</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.775632</td>\n",
       "      <td>0.769176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.296542</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.767580</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.774748</td>\n",
       "      <td>0.767407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.312889</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.754423</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.778386</td>\n",
       "      <td>0.772750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.310932</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.761043</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.776505</td>\n",
       "      <td>0.769470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.72      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7138263665594855, F1 Micro: 0.7783862723621761, F1 Macro: 0.7727503552930881\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.72      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.78      1326\n",
      "           macro avg       0.75      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0017364263534545897\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.196903705596924 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238873</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.770998</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.751932</td>\n",
       "      <td>0.740085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.224279</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.773873</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.768880</td>\n",
       "      <td>0.756342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.221763</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.779491</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.770873</td>\n",
       "      <td>0.764985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.236642</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.762025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.257310</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.743729</td>\n",
       "      <td>0.827300</td>\n",
       "      <td>0.783292</td>\n",
       "      <td>0.778391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.284378</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.734119</td>\n",
       "      <td>0.845400</td>\n",
       "      <td>0.785839</td>\n",
       "      <td>0.781491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.281181</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.758719</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.780666</td>\n",
       "      <td>0.775007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.298815</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.759233</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.782004</td>\n",
       "      <td>0.776874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.310440</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.754730</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.782419</td>\n",
       "      <td>0.777120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.307316</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.764493</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.779749</td>\n",
       "      <td>0.773952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.93      0.90       362\n",
      "                sara       0.61      0.75      0.67       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.83      0.76       492\n",
      "\n",
      "           micro avg       0.73      0.85      0.79      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.85      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7112540192926045, F1 Micro: 0.7858394672274798, F1 Macro: 0.7814912338292623\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.93      0.90       362\n",
      "                sara       0.61      0.75      0.67       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.83      0.76       492\n",
      "\n",
      "           micro avg       0.73      0.85      0.79      1326\n",
      "           macro avg       0.73      0.84      0.78      1326\n",
      "        weighted avg       0.74      0.85      0.79      1326\n",
      "         samples avg       0.47      0.48      0.47      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0025656223297119145\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.518622636795044 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241805</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.752054</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.755722</td>\n",
       "      <td>0.749641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.221628</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.796721</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.763551</td>\n",
       "      <td>0.755578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.768179</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.786004</td>\n",
       "      <td>0.777857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.234195</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.772292</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.781215</td>\n",
       "      <td>0.774453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.250311</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.769889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.116400</td>\n",
       "      <td>0.275191</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.766983</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.771482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.279699</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.794457</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.786286</td>\n",
       "      <td>0.780329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.293146</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.791056</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.782310</td>\n",
       "      <td>0.775500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.304958</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.775888</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.783420</td>\n",
       "      <td>0.779020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.311287</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770073</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.782641</td>\n",
       "      <td>0.777945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.70      0.63      0.66       237\n",
      "         radikalisme       0.78      0.82      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.79      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7331189710610932, F1 Micro: 0.7862857142857143, F1 Macro: 0.7803286738541613\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.70      0.63      0.66       237\n",
      "         radikalisme       0.78      0.82      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.79      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.002354919910430908\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.058779001235962 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239418</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.815111</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.748266</td>\n",
       "      <td>0.738830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.228415</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.770628</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.769173</td>\n",
       "      <td>0.764317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.227151</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.829749</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.758395</td>\n",
       "      <td>0.743603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.233192</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.768786</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.785240</td>\n",
       "      <td>0.776619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.254483</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.783804</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.778748</td>\n",
       "      <td>0.770138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.268694</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.768213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.277132</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.786719</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.772832</td>\n",
       "      <td>0.763031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.294948</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.768275</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.780252</td>\n",
       "      <td>0.773996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.305131</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.758351</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.780827</td>\n",
       "      <td>0.773910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.303606</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.769175</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.781447</td>\n",
       "      <td>0.774363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.66      0.63      0.64       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.81      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7228295819935692, F1 Micro: 0.785239852398524, F1 Macro: 0.7766186751566331\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.66      0.63      0.64       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.81      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 175.79 seconds\n",
      "Total runtime: 11324.78699684143 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93937f6c",
   "metadata": {},
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458386</td>\n",
       "      <td>0.505466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.149337</td>\n",
       "      <td>0.114072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.384749</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>0.233786</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>0.251831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356113</td>\n",
       "      <td>0.571704</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.347973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330139</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.453938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312512</td>\n",
       "      <td>0.608360</td>\n",
       "      <td>0.758850</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.615247</td>\n",
       "      <td>0.548237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303364</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.745247</td>\n",
       "      <td>0.591252</td>\n",
       "      <td>0.659378</td>\n",
       "      <td>0.634356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297518</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.737660</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.666942</td>\n",
       "      <td>0.633439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296958</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.567119</td>\n",
       "      <td>0.646604</td>\n",
       "      <td>0.609105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293293</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.743662</td>\n",
       "      <td>0.597285</td>\n",
       "      <td>0.662484</td>\n",
       "      <td>0.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293404</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.629208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.62508038585209, F1 Micro: 0.6669421487603305, F1 Macro: 0.6334393870554681\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8863574646413328\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 19.84381866455078 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.427968</td>\n",
       "      <td>0.553055</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.170437</td>\n",
       "      <td>0.290488</td>\n",
       "      <td>0.206246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332813</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.422323</td>\n",
       "      <td>0.540802</td>\n",
       "      <td>0.398713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304915</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.715260</td>\n",
       "      <td>0.632730</td>\n",
       "      <td>0.671469</td>\n",
       "      <td>0.645029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310326</td>\n",
       "      <td>0.600643</td>\n",
       "      <td>0.651329</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.700593</td>\n",
       "      <td>0.685260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>0.620579</td>\n",
       "      <td>0.687948</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.705147</td>\n",
       "      <td>0.688958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294074</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.739865</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.698008</td>\n",
       "      <td>0.682417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297824</td>\n",
       "      <td>0.646302</td>\n",
       "      <td>0.731489</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>0.703718</td>\n",
       "      <td>0.686638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296019</td>\n",
       "      <td>0.648232</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.693811</td>\n",
       "      <td>0.680338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.299764</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.732806</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>0.715554</td>\n",
       "      <td>0.701088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.301377</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>0.738076</td>\n",
       "      <td>0.688537</td>\n",
       "      <td>0.712446</td>\n",
       "      <td>0.697991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.82      0.88      0.85       362\n",
      "                sara       0.70      0.52      0.60       237\n",
      "         radikalisme       0.70      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.69      0.67      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.70      0.72      1326\n",
      "           macro avg       0.73      0.68      0.70      1326\n",
      "        weighted avg       0.73      0.70      0.71      1326\n",
      "         samples avg       0.39      0.39      0.38      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6553054662379422, F1 Micro: 0.7155538402161328, F1 Macro: 0.701088411334796\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.82      0.88      0.85       362\n",
      "                sara       0.70      0.52      0.60       237\n",
      "         radikalisme       0.70      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.69      0.67      0.68       492\n",
      "\n",
      "           micro avg       0.73      0.70      0.72      1326\n",
      "           macro avg       0.73      0.68      0.70      1326\n",
      "        weighted avg       0.73      0.70      0.71      1326\n",
      "         samples avg       0.39      0.39      0.38      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.9607703499495983\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 17.868242263793945 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.426703</td>\n",
       "      <td>0.558199</td>\n",
       "      <td>0.885993</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.333129</td>\n",
       "      <td>0.227925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.334307</td>\n",
       "      <td>0.557556</td>\n",
       "      <td>0.707986</td>\n",
       "      <td>0.447964</td>\n",
       "      <td>0.548730</td>\n",
       "      <td>0.444515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286290</td>\n",
       "      <td>0.644373</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.648567</td>\n",
       "      <td>0.694669</td>\n",
       "      <td>0.675476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297634</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.764067</td>\n",
       "      <td>0.583710</td>\n",
       "      <td>0.661821</td>\n",
       "      <td>0.622625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286399</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.703170</td>\n",
       "      <td>0.736048</td>\n",
       "      <td>0.719234</td>\n",
       "      <td>0.702375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.302381</td>\n",
       "      <td>0.643087</td>\n",
       "      <td>0.675727</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.735213</td>\n",
       "      <td>0.726249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.289574</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>0.730422</td>\n",
       "      <td>0.718552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.292423</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.728302</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.728027</td>\n",
       "      <td>0.717911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.299407</td>\n",
       "      <td>0.657235</td>\n",
       "      <td>0.721898</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.733680</td>\n",
       "      <td>0.723209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>0.297591</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.736719</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.723715</td>\n",
       "      <td>0.709775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.79      0.90      0.84       362\n",
      "                sara       0.58      0.72      0.64       237\n",
      "         radikalisme       0.66      0.74      0.70       235\n",
      "pencemaran_nama_baik       0.65      0.81      0.72       492\n",
      "\n",
      "           micro avg       0.68      0.81      0.74      1326\n",
      "           macro avg       0.67      0.79      0.73      1326\n",
      "        weighted avg       0.68      0.81      0.74      1326\n",
      "         samples avg       0.41      0.45      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6430868167202572, F1 Micro: 0.7352132049518569, F1 Macro: 0.7262493333052836\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.79      0.90      0.84       362\n",
      "                sara       0.58      0.72      0.64       237\n",
      "         radikalisme       0.66      0.74      0.70       235\n",
      "pencemaran_nama_baik       0.65      0.81      0.72       492\n",
      "\n",
      "           micro avg       0.68      0.81      0.74      1326\n",
      "           macro avg       0.67      0.79      0.73      1326\n",
      "        weighted avg       0.68      0.81      0.74      1326\n",
      "         samples avg       0.41      0.45      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.8456389755010613\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 16.09619140625 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.414244</td>\n",
       "      <td>0.549196</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.242081</td>\n",
       "      <td>0.370242</td>\n",
       "      <td>0.248539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.596785</td>\n",
       "      <td>0.697617</td>\n",
       "      <td>0.640271</td>\n",
       "      <td>0.667715</td>\n",
       "      <td>0.641205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288604</td>\n",
       "      <td>0.642444</td>\n",
       "      <td>0.693118</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.717818</td>\n",
       "      <td>0.708078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319901</td>\n",
       "      <td>0.599357</td>\n",
       "      <td>0.631459</td>\n",
       "      <td>0.838612</td>\n",
       "      <td>0.720441</td>\n",
       "      <td>0.714559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.284270</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.729358</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.724374</td>\n",
       "      <td>0.696869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.298292</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.706757</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.745545</td>\n",
       "      <td>0.737611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.736513</td>\n",
       "      <td>0.710407</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.710491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.315518</td>\n",
       "      <td>0.650161</td>\n",
       "      <td>0.724296</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.720728</td>\n",
       "      <td>0.702222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.308076</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.732236</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.735261</td>\n",
       "      <td>0.723701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.312946</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.726077</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.737662</td>\n",
       "      <td>0.726047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.88      0.87       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.64      0.79      0.71       235\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.79      0.75      1326\n",
      "           macro avg       0.70      0.78      0.74      1326\n",
      "        weighted avg       0.71      0.79      0.75      1326\n",
      "         samples avg       0.43      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.662379421221865, F1 Micro: 0.7455452601568069, F1 Macro: 0.7376111317034801\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.87      0.88      0.87       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.64      0.79      0.71       235\n",
      "pencemaran_nama_baik       0.67      0.78      0.72       492\n",
      "\n",
      "           micro avg       0.71      0.79      0.75      1326\n",
      "           macro avg       0.70      0.78      0.74      1326\n",
      "        weighted avg       0.71      0.79      0.75      1326\n",
      "         samples avg       0.43      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.7069373190402986\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 14.5509774684906 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.382465</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>0.927673</td>\n",
       "      <td>0.222474</td>\n",
       "      <td>0.358881</td>\n",
       "      <td>0.238643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299033</td>\n",
       "      <td>0.619936</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.523379</td>\n",
       "      <td>0.628054</td>\n",
       "      <td>0.623398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275214</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.707983</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.734205</td>\n",
       "      <td>0.721529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.264165</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.721546</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.740360</td>\n",
       "      <td>0.728775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.273975</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.721484</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.748457</td>\n",
       "      <td>0.736891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.310303</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.753664</td>\n",
       "      <td>0.743826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.297634</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.713311</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.748836</td>\n",
       "      <td>0.739449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.303504</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.733824</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.743112</td>\n",
       "      <td>0.727744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.310156</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.724162</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.751994</td>\n",
       "      <td>0.739718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.312536</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.727594</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.751732</td>\n",
       "      <td>0.739727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.92      0.88       362\n",
      "                sara       0.63      0.65      0.64       237\n",
      "         radikalisme       0.65      0.83      0.73       235\n",
      "pencemaran_nama_baik       0.67      0.81      0.73       492\n",
      "\n",
      "           micro avg       0.70      0.81      0.75      1326\n",
      "           macro avg       0.70      0.80      0.74      1326\n",
      "        weighted avg       0.70      0.81      0.75      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.6707395498392283, F1 Micro: 0.7536636427076064, F1 Macro: 0.7438261870651701\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.92      0.88       362\n",
      "                sara       0.63      0.65      0.64       237\n",
      "         radikalisme       0.65      0.83      0.73       235\n",
      "pencemaran_nama_baik       0.67      0.81      0.73       492\n",
      "\n",
      "           micro avg       0.70      0.81      0.75      1326\n",
      "           macro avg       0.70      0.80      0.74      1326\n",
      "        weighted avg       0.70      0.81      0.75      1326\n",
      "         samples avg       0.44      0.46      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.4306322515010838\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 13.124965190887451 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352035</td>\n",
       "      <td>0.509325</td>\n",
       "      <td>0.703349</td>\n",
       "      <td>0.221719</td>\n",
       "      <td>0.337156</td>\n",
       "      <td>0.243792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286232</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.710009</td>\n",
       "      <td>0.625943</td>\n",
       "      <td>0.665331</td>\n",
       "      <td>0.663589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.264161</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.722865</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.737814</td>\n",
       "      <td>0.726587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.269960</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.748396</td>\n",
       "      <td>0.741773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.299677</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.680993</td>\n",
       "      <td>0.848416</td>\n",
       "      <td>0.755541</td>\n",
       "      <td>0.757391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.279899</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.761081</td>\n",
       "      <td>0.755233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.309913</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.758764</td>\n",
       "      <td>0.754602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.310913</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.728238</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.751369</td>\n",
       "      <td>0.735840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.317705</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.706339</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.756798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.312450</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.723477</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.758522</td>\n",
       "      <td>0.752489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.89      0.88       362\n",
      "                sara       0.59      0.70      0.64       237\n",
      "         radikalisme       0.72      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.80      0.76      1326\n",
      "           macro avg       0.72      0.79      0.76      1326\n",
      "        weighted avg       0.73      0.80      0.76      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.6855305466237942, F1 Micro: 0.761081081081081, F1 Macro: 0.7552333746832414\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.89      0.88       362\n",
      "                sara       0.59      0.70      0.64       237\n",
      "         radikalisme       0.72      0.81      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.77      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.80      0.76      1326\n",
      "           macro avg       0.72      0.79      0.76      1326\n",
      "        weighted avg       0.73      0.80      0.76      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.2825503349304199\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 11.821879148483276 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 07:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.321035</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.426534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270069</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.767668</td>\n",
       "      <td>0.655354</td>\n",
       "      <td>0.707079</td>\n",
       "      <td>0.692626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.261947</td>\n",
       "      <td>0.674598</td>\n",
       "      <td>0.704262</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.753420</td>\n",
       "      <td>0.743782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.262873</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.741027</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.766655</td>\n",
       "      <td>0.757600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.280777</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.736370</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.769009</td>\n",
       "      <td>0.761634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.321600</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.682325</td>\n",
       "      <td>0.876320</td>\n",
       "      <td>0.767250</td>\n",
       "      <td>0.766654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.308782</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.707809</td>\n",
       "      <td>0.847662</td>\n",
       "      <td>0.771448</td>\n",
       "      <td>0.767180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.334138</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.694833</td>\n",
       "      <td>0.861991</td>\n",
       "      <td>0.769438</td>\n",
       "      <td>0.764882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.331058</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.707378</td>\n",
       "      <td>0.860483</td>\n",
       "      <td>0.776455</td>\n",
       "      <td>0.772376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.320247</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.716199</td>\n",
       "      <td>0.846908</td>\n",
       "      <td>0.776088</td>\n",
       "      <td>0.770523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.92      0.90       362\n",
      "                sara       0.59      0.77      0.67       237\n",
      "         radikalisme       0.69      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.67      0.85      0.75       492\n",
      "\n",
      "           micro avg       0.71      0.86      0.78      1326\n",
      "           macro avg       0.71      0.85      0.77      1326\n",
      "        weighted avg       0.72      0.86      0.78      1326\n",
      "         samples avg       0.46      0.49      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.6977491961414791, F1 Micro: 0.7764545763865259, F1 Macro: 0.7723763262492246\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.88      0.92      0.90       362\n",
      "                sara       0.59      0.77      0.67       237\n",
      "         radikalisme       0.69      0.88      0.77       235\n",
      "pencemaran_nama_baik       0.67      0.85      0.75       492\n",
      "\n",
      "           micro avg       0.71      0.86      0.78      1326\n",
      "           macro avg       0.71      0.85      0.77      1326\n",
      "        weighted avg       0.72      0.86      0.78      1326\n",
      "         samples avg       0.46      0.49      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.05199238657951355\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 10.708080291748047 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294852</td>\n",
       "      <td>0.629582</td>\n",
       "      <td>0.780320</td>\n",
       "      <td>0.514329</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.599359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261685</td>\n",
       "      <td>0.663023</td>\n",
       "      <td>0.719085</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.738349</td>\n",
       "      <td>0.731101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.279982</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.668824</td>\n",
       "      <td>0.857466</td>\n",
       "      <td>0.751487</td>\n",
       "      <td>0.750520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.268081</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.713642</td>\n",
       "      <td>0.836350</td>\n",
       "      <td>0.770139</td>\n",
       "      <td>0.766220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.297291</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.694614</td>\n",
       "      <td>0.855958</td>\n",
       "      <td>0.766892</td>\n",
       "      <td>0.765274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.293874</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.726081</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.776999</td>\n",
       "      <td>0.772322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.293623</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.737964</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.763238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.716465</td>\n",
       "      <td>0.849925</td>\n",
       "      <td>0.777509</td>\n",
       "      <td>0.773978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.321799</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.720871</td>\n",
       "      <td>0.849170</td>\n",
       "      <td>0.779778</td>\n",
       "      <td>0.775766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054300</td>\n",
       "      <td>0.317891</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.726976</td>\n",
       "      <td>0.839367</td>\n",
       "      <td>0.779139</td>\n",
       "      <td>0.775655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.91       362\n",
      "                sara       0.60      0.77      0.68       237\n",
      "         radikalisme       0.70      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.72      0.85      0.78      1326\n",
      "           macro avg       0.72      0.84      0.78      1326\n",
      "        weighted avg       0.73      0.85      0.78      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7016077170418007, F1 Micro: 0.7797783933518007, F1 Macro: 0.7757664557123599\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.92      0.91       362\n",
      "                sara       0.60      0.77      0.68       237\n",
      "         radikalisme       0.70      0.86      0.77       235\n",
      "pencemaran_nama_baik       0.68      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.72      0.85      0.78      1326\n",
      "           macro avg       0.72      0.84      0.78      1326\n",
      "        weighted avg       0.73      0.85      0.78      1326\n",
      "         samples avg       0.46      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.02945581078529358\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 9.607912540435791 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283954</td>\n",
       "      <td>0.646945</td>\n",
       "      <td>0.760909</td>\n",
       "      <td>0.631222</td>\n",
       "      <td>0.690025</td>\n",
       "      <td>0.669941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248441</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.751142</td>\n",
       "      <td>0.741043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.254324</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.714656</td>\n",
       "      <td>0.831071</td>\n",
       "      <td>0.768480</td>\n",
       "      <td>0.764490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.254520</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.734203</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.768512</td>\n",
       "      <td>0.758419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.282856</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.712276</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.770934</td>\n",
       "      <td>0.769265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.281662</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.729908</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.779184</td>\n",
       "      <td>0.776299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.306482</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.715561</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.775397</td>\n",
       "      <td>0.772999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.297189</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>0.777531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.307553</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.732527</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.774698</td>\n",
       "      <td>0.769921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.316769</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.722837</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>0.776109</td>\n",
       "      <td>0.772980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.60      0.76      0.67       237\n",
      "         radikalisme       0.77      0.82      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.74      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7086816720257235, F1 Micro: 0.7795889440113394, F1 Macro: 0.7775314175931998\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.60      0.76      0.67       237\n",
      "         radikalisme       0.77      0.82      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.81      0.74       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.78      1326\n",
      "        weighted avg       0.74      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.030963277816772466\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 8.736328840255737 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.657235</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.679422</td>\n",
       "      <td>0.674760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256304</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.721958</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.759385</td>\n",
       "      <td>0.757940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.243234</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.777601</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>0.744174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>0.255554</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.740405</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.769119</td>\n",
       "      <td>0.764222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.261577</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.767804</td>\n",
       "      <td>0.755705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.280001</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.743132</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.777858</td>\n",
       "      <td>0.774304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.299249</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.736733</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.769896</td>\n",
       "      <td>0.759763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.309008</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.732347</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.774262</td>\n",
       "      <td>0.767521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.320895</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.722368</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.771609</td>\n",
       "      <td>0.767315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.314987</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.734100</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.773894</td>\n",
       "      <td>0.769359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.59      0.71      0.65       237\n",
      "         radikalisme       0.78      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7080385852090032, F1 Micro: 0.7778576563623293, F1 Macro: 0.7743038877972652\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.59      0.71      0.65       237\n",
      "         radikalisme       0.78      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.70      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.82      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.82      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.04432213306427002\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 8.157275199890137 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280315</td>\n",
       "      <td>0.656592</td>\n",
       "      <td>0.805439</td>\n",
       "      <td>0.580694</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>0.657377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.253067</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.723702</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.768741</td>\n",
       "      <td>0.763600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.250598</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.748908</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.746149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.255289</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.738192</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.779202</td>\n",
       "      <td>0.774272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.271869</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.735709</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.777817</td>\n",
       "      <td>0.773449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.280563</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.747207</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>0.770419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.298578</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.741249</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.776141</td>\n",
       "      <td>0.768890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.312838</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.734050</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.776554</td>\n",
       "      <td>0.771819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.325384</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.724342</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>0.773717</td>\n",
       "      <td>0.767850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.314989</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.738683</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.773707</td>\n",
       "      <td>0.766318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.84      0.76       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7054662379421222, F1 Micro: 0.7792022792022791, F1 Macro: 0.7742720098101732\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.87      0.90       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.84      0.76       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.82      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.45      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.06491667628288268\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 7.40594744682312 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275365</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.750613</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.720282</td>\n",
       "      <td>0.705945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.243415</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.756080</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.764816</td>\n",
       "      <td>0.755374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.294500</td>\n",
       "      <td>0.248398</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.732830</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.767074</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.257163</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.729547</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.769340</td>\n",
       "      <td>0.765443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.263383</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.759559</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.769173</td>\n",
       "      <td>0.757633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.291747</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.774813</td>\n",
       "      <td>0.768330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.306246</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.733557</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.776278</td>\n",
       "      <td>0.771424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.311107</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.747214</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.776973</td>\n",
       "      <td>0.770137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.316787</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.745669</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.777176</td>\n",
       "      <td>0.770627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.321378</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.741427</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.776580</td>\n",
       "      <td>0.770421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.72      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7112540192926045, F1 Micro: 0.7771758757674251, F1 Macro: 0.7706270790620398\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.61      0.70      0.65       237\n",
      "         radikalisme       0.72      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.010840308666229247\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.673736810684204 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271653</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.825518</td>\n",
       "      <td>0.570890</td>\n",
       "      <td>0.674989</td>\n",
       "      <td>0.660761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.756594</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.756879</td>\n",
       "      <td>0.752466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.238264</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.761522</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.773115</td>\n",
       "      <td>0.765064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.246694</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.778727</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.767406</td>\n",
       "      <td>0.760203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.275836</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.727811</td>\n",
       "      <td>0.834842</td>\n",
       "      <td>0.777661</td>\n",
       "      <td>0.770885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.270304</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.750526</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.778060</td>\n",
       "      <td>0.772348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.297487</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.729153</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.773805</td>\n",
       "      <td>0.767142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.302699</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.739932</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.776783</td>\n",
       "      <td>0.770106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.302787</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.754623</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.776720</td>\n",
       "      <td>0.769708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.311985</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.779183</td>\n",
       "      <td>0.772597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7170418006430869, F1 Micro: 0.7791832309360318, F1 Macro: 0.77259699348055\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.91      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.75      0.81      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.009192407131195068\n",
      "Samples above threshold: 184\n",
      "Acquired samples: 133\n",
      "Sampling duration: 6.001875162124634 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263670</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.737872</td>\n",
       "      <td>0.731169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.236125</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.773994</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.763942</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.233237</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.771527</td>\n",
       "      <td>0.758110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.261103</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.721643</td>\n",
       "      <td>0.834842</td>\n",
       "      <td>0.774126</td>\n",
       "      <td>0.767470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.264807</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.777656</td>\n",
       "      <td>0.767328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>0.278476</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.760059</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.771630</td>\n",
       "      <td>0.763061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.284777</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.759768</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.775480</td>\n",
       "      <td>0.766340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.301144</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.778878</td>\n",
       "      <td>0.770939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.317158</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.777857</td>\n",
       "      <td>0.771032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.315488</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.776488</td>\n",
       "      <td>0.770259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.62      0.67      0.65       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7176848874598071, F1 Micro: 0.7788778877887789, F1 Macro: 0.7709391172546838\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.62      0.67      0.65       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.007476878166198731\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.496657609939575 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256831</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.777211</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.730616</td>\n",
       "      <td>0.728780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.231480</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.786624</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.765298</td>\n",
       "      <td>0.754979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.239014</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.741168</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.779843</td>\n",
       "      <td>0.774901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.254895</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.739792</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.771563</td>\n",
       "      <td>0.759998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.269192</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.735077</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.778133</td>\n",
       "      <td>0.772527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.274414</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.782414</td>\n",
       "      <td>0.774938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.290995</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.766369</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.771536</td>\n",
       "      <td>0.760553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.299345</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.761107</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.774361</td>\n",
       "      <td>0.766755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.308775</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.757948</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.766842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.317721</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.749826</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.779428</td>\n",
       "      <td>0.773378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7202572347266881, F1 Micro: 0.782414307004471, F1 Macro: 0.7749378080139446\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.010385572910308838\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.87216329574585 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260286</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.719502</td>\n",
       "      <td>0.689558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.232983</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.758345</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.772929</td>\n",
       "      <td>0.766328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301100</td>\n",
       "      <td>0.230876</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.794996</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.768031</td>\n",
       "      <td>0.750024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.244503</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.768882</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.768302</td>\n",
       "      <td>0.761606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.255422</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.762192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.272721</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.772866</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.768764</td>\n",
       "      <td>0.763104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.106100</td>\n",
       "      <td>0.289799</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.744976</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.776454</td>\n",
       "      <td>0.769506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.298990</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.749640</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.767305</td>\n",
       "      <td>0.758680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.306495</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.757994</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.763397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.311117</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.756429</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.776963</td>\n",
       "      <td>0.768139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.63      0.65      0.64       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7170418006430869, F1 Micro: 0.776962582538518, F1 Macro: 0.7681386340024651\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.63      0.65      0.64       237\n",
      "         radikalisme       0.73      0.82      0.77       235\n",
      "pencemaran_nama_baik       0.72      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.003636658191680909\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.200016021728516 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248643</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.770400</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.744686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.228456</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.793435</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.769709</td>\n",
       "      <td>0.751073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.235249</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.772575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.234967</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.786798</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.784418</td>\n",
       "      <td>0.775419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.258797</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.749653</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.781069</td>\n",
       "      <td>0.775890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.270647</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.782708</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.777060</td>\n",
       "      <td>0.769635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.295591</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.748059</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.772876</td>\n",
       "      <td>0.764739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.314492</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.734322</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.775365</td>\n",
       "      <td>0.768583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.312838</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.758769</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.778553</td>\n",
       "      <td>0.771731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.317934</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.760342</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.781525</td>\n",
       "      <td>0.773535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.77      0.77      0.77       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7260450160771704, F1 Micro: 0.7844175491679274, F1 Macro: 0.7754191380149934\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.77      0.77      0.77       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.025242233276367192\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 3.575199604034424 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246259</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.750190</td>\n",
       "      <td>0.743776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.227884</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.809731</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.752523</td>\n",
       "      <td>0.742826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.232112</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.785661</td>\n",
       "      <td>0.779243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.242884</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.783656</td>\n",
       "      <td>0.775124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.252191</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.759547</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.777875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.268236</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.766618</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.783026</td>\n",
       "      <td>0.774604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.289832</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.757447</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.772773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.297628</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.778029</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.778908</td>\n",
       "      <td>0.770480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.766715</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.780903</td>\n",
       "      <td>0.772452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.310822</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.762518</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.782673</td>\n",
       "      <td>0.774304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7247588424437299, F1 Micro: 0.7856614929785662, F1 Macro: 0.779242729488879\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.028077578544616694\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.9011476039886475 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243421</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.761582</td>\n",
       "      <td>0.751727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.221513</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.780864</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.763128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.234325</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.741184</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.787557</td>\n",
       "      <td>0.780960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.223780</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.784954</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.781983</td>\n",
       "      <td>0.775052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.244736</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.755571</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.785663</td>\n",
       "      <td>0.778619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.265847</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.757491</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.787396</td>\n",
       "      <td>0.781176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.270734</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.785606</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.783825</td>\n",
       "      <td>0.774204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.289742</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.776134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.297671</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.761702</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.779724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.298223</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.766382</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.788278</td>\n",
       "      <td>0.783265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.63      0.70      0.67       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7241157556270097, F1 Micro: 0.7882783882783884, F1 Macro: 0.7832649775222131\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.63      0.70      0.67       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.0027696490287780757\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.237337112426758 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242367</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.759637</td>\n",
       "      <td>0.752728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.226886</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.839925</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.747069</td>\n",
       "      <td>0.733255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.219536</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.797923</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.775019</td>\n",
       "      <td>0.764799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.224311</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.794232</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.781142</td>\n",
       "      <td>0.770330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.244034</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.769121</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.789725</td>\n",
       "      <td>0.780449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.258141</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.765423</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.784559</td>\n",
       "      <td>0.780313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.275919</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.769509</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.785978</td>\n",
       "      <td>0.778957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.294814</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.755230</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.784783</td>\n",
       "      <td>0.779271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.301076</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.759859</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.785870</td>\n",
       "      <td>0.780047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.297072</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.786873</td>\n",
       "      <td>0.781063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.47      0.46      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7234726688102894, F1 Micro: 0.7897247706422019, F1 Macro: 0.7804488932310327\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.71      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.47      0.46      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.004361784458160401\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 1.5323712825775146 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243555</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.746215</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.762993</td>\n",
       "      <td>0.756711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>0.220209</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.791174</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.773796</td>\n",
       "      <td>0.765243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206100</td>\n",
       "      <td>0.223017</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.785824</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.777439</td>\n",
       "      <td>0.764751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.232690</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.771093</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.775369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160100</td>\n",
       "      <td>0.241969</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.796412</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.782975</td>\n",
       "      <td>0.772774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117100</td>\n",
       "      <td>0.273454</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.778839</td>\n",
       "      <td>0.772216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.288842</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.783460</td>\n",
       "      <td>0.777117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.295906</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.774721</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.780232</td>\n",
       "      <td>0.773755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.304981</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.768390</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.781771</td>\n",
       "      <td>0.775013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.311975</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.754584</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.779883</td>\n",
       "      <td>0.774474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7228295819935692, F1 Micro: 0.7834602829162133, F1 Macro: 0.7771168917422758\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.92      0.92       362\n",
      "                sara       0.62      0.70      0.66       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.81      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 0.001691579818725586\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 0.9600405693054199 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237645</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.791980</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.751486</td>\n",
       "      <td>0.743326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.223919</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.778118</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.772503</td>\n",
       "      <td>0.761715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.225239</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.778682</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.785954</td>\n",
       "      <td>0.775734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.233548</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.786898</td>\n",
       "      <td>0.778815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.269131</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.778839</td>\n",
       "      <td>0.770224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.264997</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.786350</td>\n",
       "      <td>0.780636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.292577</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.760454</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.784070</td>\n",
       "      <td>0.779704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.298632</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.768284</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.783894</td>\n",
       "      <td>0.779332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.304936</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.770241</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.783092</td>\n",
       "      <td>0.777743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.310901</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.766618</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.783026</td>\n",
       "      <td>0.778287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7266881028938906, F1 Micro: 0.7868975903614458, F1 Macro: 0.7788154584986352\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n",
      "Total sampling time: 176.37 seconds\n",
      "Total runtime: 11369.735578298569 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5992938,
     "sourceId": 9782034,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35228.910639,
   "end_time": "2024-12-17T22:42:31.919529",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-17T12:55:23.008890",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07e60833544e4621928ba7ebaa951021": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "12fe0f059a924143a7e88d99ef9a5cff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1351b4afe9974bd58331b573b964df00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_32f55031e3ac4667a8d062844301c067",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5d188d77577433eb2d2ec9680ff1350",
       "value": 2
      }
     },
     "1d98193437674bc0b792e0418cb70486": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe9a1a5e3cf24b459469e54ac119f30d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_33e0e21567a04a008f24bf8656b8434b",
       "value": "special_tokens_map.json:â€‡100%"
      }
     },
     "265163a2f2254831a33be75f586a9d19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4ddbff15fb041369fa9dff3d210c1ea",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_682a0e560d964dc5aa897faaf93650a8",
       "value": "config.json:â€‡100%"
      }
     },
     "2c7280ba19054d06a26edc099c9069f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1d98193437674bc0b792e0418cb70486",
        "IPY_MODEL_69ecb1dae6364928b328b445cfe7c8f8",
        "IPY_MODEL_6a377a88e75642bd8e7ba6a009915c50"
       ],
       "layout": "IPY_MODEL_5fc7a3458db8408993e8d35e7bf22842"
      }
     },
     "31020ae3f78746158b4a8afc4638418c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32f55031e3ac4667a8d062844301c067": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33e0e21567a04a008f24bf8656b8434b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "36be185ae6e74bf0b047d4af839be9df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e22278a73f7549e78ed44373d92feb35",
        "IPY_MODEL_1351b4afe9974bd58331b573b964df00",
        "IPY_MODEL_fe2575b389bf48d8bcc207e7442989ee"
       ],
       "layout": "IPY_MODEL_7c97ff42c61e424f82e79fc25d48068e"
      }
     },
     "3c635664669d454db6afce770cf7ba14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4135c9da18894dada28da43126372d26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41ef7cd86f044883b7af34c9f154e56e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "47290dc63ebc4a9cbd6e0410e2b18158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_31020ae3f78746158b4a8afc4638418c",
       "max": 497810400,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3c635664669d454db6afce770cf7ba14",
       "value": 497810400
      }
     },
     "5a77863eedd6402ea565bed5f9bfbae7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5d46d937c8ab46f6a954852b8a35b37a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a9c3302d90cc4c6bb500b662d2fe6060",
        "IPY_MODEL_47290dc63ebc4a9cbd6e0410e2b18158",
        "IPY_MODEL_a1a383ada06441d98fd8aea1a199b999"
       ],
       "layout": "IPY_MODEL_cf7bf1a935db4b1bb18965c86f976f76"
      }
     },
     "5fc7a3458db8408993e8d35e7bf22842": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "603ae1da10c344e68785fa99a033915a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6344bafefa29499ab14919aa87f5b885": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1b71c33998e44cd9d3c723089641823",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a5f8ec9b25e94556b3ccf37beff74be4",
       "value": "vocab.txt:â€‡100%"
      }
     },
     "682a0e560d964dc5aa897faaf93650a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "69ecb1dae6364928b328b445cfe7c8f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9428d06d1c4b4d738334156d6d7dcb56",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dbb7d28cf2ad41a0aa745d0da5252a86",
       "value": 112
      }
     },
     "6a377a88e75642bd8e7ba6a009915c50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_603ae1da10c344e68785fa99a033915a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b1febe0d0d3a4fde9d19c75a548546d6",
       "value": "â€‡112/112â€‡[00:00&lt;00:00,â€‡11.3kB/s]"
      }
     },
     "76643216374f406f8b6a2f330e0d6f64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7751aa99ea214141ac8a913524f60ee1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6344bafefa29499ab14919aa87f5b885",
        "IPY_MODEL_a741b84b9f4b4dd48ca77356d9922a66",
        "IPY_MODEL_ba1cb417c7ad4208a4cf864024b3ef46"
       ],
       "layout": "IPY_MODEL_12fe0f059a924143a7e88d99ef9a5cff"
      }
     },
     "7c97ff42c61e424f82e79fc25d48068e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80d2fda517d2414f8c344e392fcba3e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "88d6a4847cda4a7ca63bba193329d80a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9428d06d1c4b4d738334156d6d7dcb56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1a383ada06441d98fd8aea1a199b999": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de24854a68d24b57ab274f488e5eaf3e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e768d128eccf4927aa61b28b4beb63e6",
       "value": "â€‡498M/498Mâ€‡[00:02&lt;00:00,â€‡247MB/s]"
      }
     },
     "a59bb7d1d74748e481a99b992e742545": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07e60833544e4621928ba7ebaa951021",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ca075f0dcead4859b444bbe99072247e",
       "value": 1534
      }
     },
     "a5f8ec9b25e94556b3ccf37beff74be4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a741b84b9f4b4dd48ca77356d9922a66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b255d4fafc5946f686838ec163c9b116",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80d2fda517d2414f8c344e392fcba3e7",
       "value": 229167
      }
     },
     "a9c3302d90cc4c6bb500b662d2fe6060": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4135c9da18894dada28da43126372d26",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d275b0ed6bee4df4aff76a741503a801",
       "value": "pytorch_model.bin:â€‡100%"
      }
     },
     "ae97a0561fe6417086bf3eb4dc860066": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1febe0d0d3a4fde9d19c75a548546d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b255d4fafc5946f686838ec163c9b116": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b774bdc030cb43e1a99a276476b0b512": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba1cb417c7ad4208a4cf864024b3ef46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ecd9c30572a64b77bb54d735ab4a0103",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_dbfbc361834c4ac7a9deb61471089f54",
       "value": "â€‡229k/229kâ€‡[00:00&lt;00:00,â€‡5.18MB/s]"
      }
     },
     "ca075f0dcead4859b444bbe99072247e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cf7bf1a935db4b1bb18965c86f976f76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d1b71c33998e44cd9d3c723089641823": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d275b0ed6bee4df4aff76a741503a801": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d4ddbff15fb041369fa9dff3d210c1ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5c649ec41ca497592e7f528dac17f87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b774bdc030cb43e1a99a276476b0b512",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ec4d903de4dd4fba8138c5547383b85a",
       "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡120kB/s]"
      }
     },
     "d9c8638ce72b4a0da315906aea8e02a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_265163a2f2254831a33be75f586a9d19",
        "IPY_MODEL_a59bb7d1d74748e481a99b992e742545",
        "IPY_MODEL_d5c649ec41ca497592e7f528dac17f87"
       ],
       "layout": "IPY_MODEL_41ef7cd86f044883b7af34c9f154e56e"
      }
     },
     "dbb7d28cf2ad41a0aa745d0da5252a86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dbfbc361834c4ac7a9deb61471089f54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "de24854a68d24b57ab274f488e5eaf3e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e22278a73f7549e78ed44373d92feb35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae97a0561fe6417086bf3eb4dc860066",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5a77863eedd6402ea565bed5f9bfbae7",
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "e768d128eccf4927aa61b28b4beb63e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ec4d903de4dd4fba8138c5547383b85a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ecd9c30572a64b77bb54d735ab4a0103": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5d188d77577433eb2d2ec9680ff1350": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fe2575b389bf48d8bcc207e7442989ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_76643216374f406f8b6a2f330e0d6f64",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_88d6a4847cda4a7ca63bba193329d80a",
       "value": "â€‡2.00/2.00â€‡[00:00&lt;00:00,â€‡186B/s]"
      }
     },
     "fe9a1a5e3cf24b459469e54ac119f30d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
