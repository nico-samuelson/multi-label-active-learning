{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1046105d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:12.754196Z",
     "iopub.status.busy": "2024-12-22T14:33:12.753834Z",
     "iopub.status.idle": "2024-12-22T14:33:29.709565Z",
     "shell.execute_reply": "2024-12-22T14:33:29.708591Z"
    },
    "papermill": {
     "duration": 16.963672,
     "end_time": "2024-12-22T14:33:29.711419",
     "exception": false,
     "start_time": "2024-12-22T14:33:12.747747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification, BertPreTrainedModel, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from kaggle_secrets import UserSecretsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78e354c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:29.721629Z",
     "iopub.status.busy": "2024-12-22T14:33:29.721060Z",
     "iopub.status.idle": "2024-12-22T14:33:30.499874Z",
     "shell.execute_reply": "2024-12-22T14:33:30.498961Z"
    },
    "papermill": {
     "duration": 0.785237,
     "end_time": "2024-12-22T14:33:30.501415",
     "exception": false,
     "start_time": "2024-12-22T14:33:29.716178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicost918\u001b[0m (\u001b[33mnicost918-petra-christian-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb-key\")\n",
    "\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151aa13a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:30.511531Z",
     "iopub.status.busy": "2024-12-22T14:33:30.511270Z",
     "iopub.status.idle": "2024-12-22T14:33:30.514832Z",
     "shell.execute_reply": "2024-12-22T14:33:30.514023Z"
    },
    "papermill": {
     "duration": 0.009877,
     "end_time": "2024-12-22T14:33:30.516123",
     "exception": false,
     "start_time": "2024-12-22T14:33:30.506246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee11be7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:30.525790Z",
     "iopub.status.busy": "2024-12-22T14:33:30.525549Z",
     "iopub.status.idle": "2024-12-22T14:33:30.683097Z",
     "shell.execute_reply": "2024-12-22T14:33:30.682301Z"
    },
    "papermill": {
     "duration": 0.16374,
     "end_time": "2024-12-22T14:33:30.684442",
     "exception": false,
     "start_time": "2024-12-22T14:33:30.520702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7773, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/netifier-2/processed_train.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/netifier-2/processed_test.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d83320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:30.694464Z",
     "iopub.status.busy": "2024-12-22T14:33:30.694206Z",
     "iopub.status.idle": "2024-12-22T14:33:30.709528Z",
     "shell.execute_reply": "2024-12-22T14:33:30.708694Z"
    },
    "papermill": {
     "duration": 0.021676,
     "end_time": "2024-12-22T14:33:30.710876",
     "exception": false,
     "start_time": "2024-12-22T14:33:30.689200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>jabar memang provinsi barokah boleh juga dan n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@verosvante kita2 aja nitizen yang pada kepo,t...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>kita saja nitizen yang pada penasaran toh kelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"#SidangAhok smg sipenista agama n ateknya mat...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sidangahok semoga sipenista agama dan ateknya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@bolususulembang.jkt barusan baca undang2 ini....</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jakarta barusan baca undang ini tetap dibedaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bikin anak mulu lu nof \\nkaga mikir apa kasian...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>buat anak melulu kamu nof nkaga mikir apa kasi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text     source  pornografi  \\\n",
       "0  [QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...     kaskus           0   \n",
       "1  @verosvante kita2 aja nitizen yang pada kepo,t...  instagram           0   \n",
       "2  \"#SidangAhok smg sipenista agama n ateknya mat...    twitter           0   \n",
       "3  @bolususulembang.jkt barusan baca undang2 ini....  instagram           0   \n",
       "4  bikin anak mulu lu nof \\nkaga mikir apa kasian...     kaskus           0   \n",
       "\n",
       "   sara  radikalisme  pencemaran_nama_baik  \\\n",
       "0     0            0                     1   \n",
       "1     0            0                     0   \n",
       "2     1            1                     1   \n",
       "3     0            0                     0   \n",
       "4     0            0                     0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  jabar memang provinsi barokah boleh juga dan n...  \n",
       "1  kita saja nitizen yang pada penasaran toh kelu...  \n",
       "2  sidangahok semoga sipenista agama dan ateknya ...  \n",
       "3  jakarta barusan baca undang ini tetap dibedaka...  \n",
       "4  buat anak melulu kamu nof nkaga mikir apa kasi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f78a63e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:30.721926Z",
     "iopub.status.busy": "2024-12-22T14:33:30.721606Z",
     "iopub.status.idle": "2024-12-22T14:33:30.729792Z",
     "shell.execute_reply": "2024-12-22T14:33:30.729080Z"
    },
    "papermill": {
     "duration": 0.015474,
     "end_time": "2024-12-22T14:33:30.731431",
     "exception": false,
     "start_time": "2024-12-22T14:33:30.715957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3866a423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:30.743218Z",
     "iopub.status.busy": "2024-12-22T14:33:30.742952Z",
     "iopub.status.idle": "2024-12-22T14:33:30.754524Z",
     "shell.execute_reply": "2024-12-22T14:33:30.753531Z"
    },
    "papermill": {
     "duration": 0.019236,
     "end_time": "2024-12-22T14:33:30.756061",
     "exception": false,
     "start_time": "2024-12-22T14:33:30.736825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6218,) (6218, 4)\n",
      "(1555,) (1555, 4)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[2:6]\n",
    "val_labels = val_data.columns[2:6]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['processed_text'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['processed_text'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2741057f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:30.767287Z",
     "iopub.status.busy": "2024-12-22T14:33:30.767045Z",
     "iopub.status.idle": "2024-12-22T14:33:31.621970Z",
     "shell.execute_reply": "2024-12-22T14:33:31.620341Z"
    },
    "papermill": {
     "duration": 0.861949,
     "end_time": "2024-12-22T14:33:31.623458",
     "exception": false,
     "start_time": "2024-12-22T14:33:30.761509",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413ec48f69cc4f218537ef9c0ec23539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459f2f36014f407e91d2b1f529fb06e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ddaeb2634b491dac88ac955f6593a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523fdc6d17714cdab06c521b21a94a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define custom Dataset class\n",
    "class NetifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=96):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1057d9d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.635613Z",
     "iopub.status.busy": "2024-12-22T14:33:31.635270Z",
     "iopub.status.idle": "2024-12-22T14:33:31.641404Z",
     "shell.execute_reply": "2024-12-22T14:33:31.640548Z"
    },
    "papermill": {
     "duration": 0.013718,
     "end_time": "2024-12-22T14:33:31.642760",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.629042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics(p):\n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    a, b, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce948c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.655482Z",
     "iopub.status.busy": "2024-12-22T14:33:31.655095Z",
     "iopub.status.idle": "2024-12-22T14:33:31.661583Z",
     "shell.execute_reply": "2024-12-22T14:33:31.660644Z"
    },
    "papermill": {
     "duration": 0.014766,
     "end_time": "2024-12-22T14:33:31.663176",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.648410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define compute metrics for evaluation\n",
    "def compute_metrics_eval(p):\n",
    "    result = compute_metrics(p)\n",
    "    \n",
    "    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "    \n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['pornografi', 'sara', 'radikalisme', 'pencemaran_nama_baik'],\n",
    "        zero_division=0\n",
    "    )    \n",
    "    return {\n",
    "        'accuracy': result['accuracy'],\n",
    "        'precision': result['precision'],\n",
    "        'recall': result['recall'],\n",
    "        'f1_micro': result['f1_micro'],\n",
    "        'f1_macro': result['f1_macro'],\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7e28b",
   "metadata": {
    "papermill": {
     "duration": 0.005784,
     "end_time": "2024-12-22T14:33:31.675036",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.669252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ACTIVE LEARNING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ca358b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.688371Z",
     "iopub.status.busy": "2024-12-22T14:33:31.687954Z",
     "iopub.status.idle": "2024-12-22T14:33:31.692705Z",
     "shell.execute_reply": "2024-12-22T14:33:31.691737Z"
    },
    "papermill": {
     "duration": 0.013266,
     "end_time": "2024-12-22T14:33:31.694324",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.681058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_micros = []\n",
    "f1_macros = []\n",
    "sampling_dur = []\n",
    "data_used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa48b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.707081Z",
     "iopub.status.busy": "2024-12-22T14:33:31.706708Z",
     "iopub.status.idle": "2024-12-22T14:33:31.712154Z",
     "shell.execute_reply": "2024-12-22T14:33:31.711278Z"
    },
    "papermill": {
     "duration": 0.013353,
     "end_time": "2024-12-22T14:33:31.713580",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.700227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'netifier-mc'\n",
    "epochs = 10\n",
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5abdaea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.726422Z",
     "iopub.status.busy": "2024-12-22T14:33:31.726073Z",
     "iopub.status.idle": "2024-12-22T14:33:31.744726Z",
     "shell.execute_reply": "2024-12-22T14:33:31.743812Z"
    },
    "papermill": {
     "duration": 0.026676,
     "end_time": "2024-12-22T14:33:31.746106",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.719430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monte_carlo_dropout_sampling(model, X_pool, train_indices, remaining_indices, trials, mc_passes=3, n_samples=min_increment):\n",
    "    start_time = time.time()\n",
    "    current_train_size = len(train_indices)\n",
    "\n",
    "    model.train()  # Set model to train mode to activate dropout layers\n",
    "    confidences = []\n",
    "\n",
    "    dataset = NetifierDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=80)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    for data in dataloader:\n",
    "        # Collect multiple predictions to calculate uncertainty\n",
    "        batch_probs = []\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "        for _ in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()  # Shape: (batch_size, num_classes)\n",
    "            batch_probs.append(probs)\n",
    "\n",
    "        # Stack the probabilities from multiple MC passes\n",
    "        batch_probs = np.stack(batch_probs, axis=0)  # Shape: (mc_passes, batch_size, num_classes)\n",
    "\n",
    "        # Calculate mean probability and uncertainty for each sample in the batch\n",
    "        mean_probs = np.mean(batch_probs, axis=0)  # Shape: (batch_size, num_classes)\n",
    "        uncertainties = np.mean(np.var(batch_probs, axis=0), axis=1)  # Shape: (batch_size,)\n",
    "\n",
    "        # Append the uncertainties to the confidences list\n",
    "        confidences.extend(uncertainties)\n",
    "\n",
    "    # Select samples with highest uncertainty\n",
    "    uncertainties = np.array(confidences)\n",
    "    sorted = np.argsort(confidences)\n",
    "    sorted = sorted[::-1]\n",
    "\n",
    "    threshold = np.percentile(confidences, 90)\n",
    "    items_greater_than_average = uncertainties[confidences >= threshold]\n",
    "    num_of_candidates = len(items_greater_than_average)\n",
    "\n",
    "    # Check nearest checkpoint\n",
    "    nearest_cp = 0\n",
    "    for cp in checkpoints:\n",
    "        if cp > current_train_size:\n",
    "            nearest_cp = cp\n",
    "            break\n",
    "            \n",
    "    if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "        most_uncertain_indices = sorted[:n_samples]\n",
    "    elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "         most_uncertain_indices = sorted[:num_of_candidates]\n",
    "    else:\n",
    "        most_uncertain_indices = sorted[:nearest_cp - current_train_size]\n",
    "\n",
    "        temp = train_indices.copy()\n",
    "        temp.extend(most_uncertain_indices)\n",
    "        \n",
    "        # Save acquired data up to checkpoint\n",
    "        acquired_data = pd.DataFrame({\n",
    "            'processed_text': [X_train[i] for i in temp],\n",
    "            'pornografi': [y_train[i][0] for i in temp],\n",
    "            'sara': [y_train[i][1] for i in temp],\n",
    "            'radikalisme': [y_train[i][2] for i in temp],\n",
    "            'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "        })\n",
    "\n",
    "        acquired_data.to_csv(f'{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "    end_time = time.time()  # Record the end time\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    print(\"Nearest checkpoint:\", nearest_cp)\n",
    "    print(\"Threshold:\", threshold)\n",
    "    print(\"Samples above threshold:\", num_of_candidates)\n",
    "    print(\"Acquired samples:\", len(most_uncertain_indices))\n",
    "    print(f\"Sampling duration: {duration} seconds\")  # Print or return the runtime if needed\n",
    "    \n",
    "    sampling_dur.append(duration)\n",
    "\n",
    "    return [remaining_indices[i] for i in most_uncertain_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a1e95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.759325Z",
     "iopub.status.busy": "2024-12-22T14:33:31.758981Z",
     "iopub.status.idle": "2024-12-22T14:33:31.771471Z",
     "shell.execute_reply": "2024-12-22T14:33:31.770607Z"
    },
    "papermill": {
     "duration": 0.020513,
     "end_time": "2024-12-22T14:33:31.772775",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.752262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, trials, seed):\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        # Specify the layers you want to freeze (e.g., first 6 layers)\n",
    "        if \"encoder.layer\" in name:\n",
    "            # Extract the layer number safely\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                # Freeze only the first 6 layers\n",
    "                if int(layer_num) < 9:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                # Skip any parameter names that don’t follow the expected format\n",
    "                continue\n",
    "    \n",
    "    # Create Dataset with current training data\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_dataset = NetifierDataset(current_X_train, current_y_train, tokenizer, max_length=128)\n",
    "    val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=128)\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results/{filename}-{trials+1}',\n",
    "        eval_strategy=\"epoch\",                    # Evaluate after every epoch\n",
    "        save_strategy=\"epoch\",                    # Save model after every epoch\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_micro',\n",
    "        save_total_limit=1,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate after training\n",
    "    trainer.compute_metrics = compute_metrics_eval\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Iteration {current_train_size}: Accuracy: {eval_results['eval_accuracy']}, F1 Micro: {eval_results['eval_f1_micro']}, F1 Macro: {eval_results['eval_f1_macro']}\")\n",
    "    print(eval_results['eval_report'])\n",
    "\n",
    "    torch.save(model.state_dict(), f'{filename}-{trials+1}-model.pth')\n",
    "    model.config.to_json_file(f'{filename}-{trials+1}-config.json')\n",
    "\n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(eval_results['eval_accuracy'])\n",
    "    f1_micros.append(eval_results['eval_f1_micro'])\n",
    "    f1_macros.append(eval_results['eval_f1_macro'])\n",
    "    \n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09fd4ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.786002Z",
     "iopub.status.busy": "2024-12-22T14:33:31.785644Z",
     "iopub.status.idle": "2024-12-22T14:33:31.794292Z",
     "shell.execute_reply": "2024-12-22T14:33:31.793443Z"
    },
    "papermill": {
     "duration": 0.017073,
     "end_time": "2024-12-22T14:33:31.795684",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.778611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f79497d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.808937Z",
     "iopub.status.busy": "2024-12-22T14:33:31.808557Z",
     "iopub.status.idle": "2024-12-22T14:33:31.820139Z",
     "shell.execute_reply": "2024-12-22T14:33:31.819245Z"
    },
    "papermill": {
     "duration": 0.019879,
     "end_time": "2024-12-22T14:33:31.821616",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.801737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies.clear()\n",
    "    f1_micros.clear()\n",
    "    f1_macros.clear()\n",
    "    sampling_dur.clear()\n",
    "    data_used.clear()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = monte_carlo_dropout_sampling(\n",
    "            model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices,\n",
    "            remaining_indices,\n",
    "            trials=i, \n",
    "            mc_passes=3,\n",
    "        )\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model, trainer = train_model(current_train_size, train_indices, i, seed)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time  # Calculate the duration in seconds\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    sampling_dur.insert(0, 0)\n",
    "    \n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    \n",
    "    results.to_csv(f'{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd40657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.833537Z",
     "iopub.status.busy": "2024-12-22T14:33:31.833240Z",
     "iopub.status.idle": "2024-12-22T14:33:31.836857Z",
     "shell.execute_reply": "2024-12-22T14:33:31.836115Z"
    },
    "papermill": {
     "duration": 0.011069,
     "end_time": "2024-12-22T14:33:31.838289",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.827220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6fdb7",
   "metadata": {
    "papermill": {
     "duration": 0.004858,
     "end_time": "2024-12-22T14:33:31.848493",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.843635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "355220b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:33:31.859911Z",
     "iopub.status.busy": "2024-12-22T14:33:31.859584Z",
     "iopub.status.idle": "2024-12-22T17:48:19.934528Z",
     "shell.execute_reply": "2024-12-22T17:48:19.933617Z"
    },
    "papermill": {
     "duration": 11688.082401,
     "end_time": "2024-12-22T17:48:19.936100",
     "exception": false,
     "start_time": "2024-12-22T14:33:31.853699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a95d61e582841b3ba9f67c219d8eb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241222_143336-jx2b3vwh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-mc-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/jx2b3vwh\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.471070</td>\n",
       "      <td>0.441801</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.016121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408955</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.937743</td>\n",
       "      <td>0.181750</td>\n",
       "      <td>0.304485</td>\n",
       "      <td>0.212706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356134</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.760807</td>\n",
       "      <td>0.398190</td>\n",
       "      <td>0.522772</td>\n",
       "      <td>0.458811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.333005</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.745169</td>\n",
       "      <td>0.465309</td>\n",
       "      <td>0.572888</td>\n",
       "      <td>0.519570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328695</td>\n",
       "      <td>0.599357</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.493213</td>\n",
       "      <td>0.596443</td>\n",
       "      <td>0.562729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>0.602572</td>\n",
       "      <td>0.734064</td>\n",
       "      <td>0.555807</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.600391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.322708</td>\n",
       "      <td>0.605788</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.602180</td>\n",
       "      <td>0.576849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310757</td>\n",
       "      <td>0.618006</td>\n",
       "      <td>0.728030</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>0.632917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310798</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.731638</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.650754</td>\n",
       "      <td>0.631457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310642</td>\n",
       "      <td>0.616077</td>\n",
       "      <td>0.733840</td>\n",
       "      <td>0.582202</td>\n",
       "      <td>0.649285</td>\n",
       "      <td>0.630442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6180064308681672, F1 Micro: 0.653926049023681, F1 Macro: 0.6329171582051338\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.80      0.85       362\n",
      "                sara       0.62      0.32      0.42       237\n",
      "         radikalisme       0.69      0.66      0.68       235\n",
      "pencemaran_nama_baik       0.64      0.54      0.59       492\n",
      "\n",
      "           micro avg       0.73      0.59      0.65      1326\n",
      "           macro avg       0.71      0.58      0.63      1326\n",
      "        weighted avg       0.72      0.59      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0037122295238077646\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 42.75436043739319 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391411</td>\n",
       "      <td>0.571704</td>\n",
       "      <td>0.772321</td>\n",
       "      <td>0.391403</td>\n",
       "      <td>0.519520</td>\n",
       "      <td>0.448362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.325539</td>\n",
       "      <td>0.630225</td>\n",
       "      <td>0.720790</td>\n",
       "      <td>0.632730</td>\n",
       "      <td>0.673896</td>\n",
       "      <td>0.665184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.292547</td>\n",
       "      <td>0.660450</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.701546</td>\n",
       "      <td>0.702073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278147</td>\n",
       "      <td>0.671383</td>\n",
       "      <td>0.743039</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.723190</td>\n",
       "      <td>0.711355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274168</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.723711</td>\n",
       "      <td>0.714199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275583</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.734236</td>\n",
       "      <td>0.722357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278568</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.753510</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.740798</td>\n",
       "      <td>0.733156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277837</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.779029</td>\n",
       "      <td>0.677979</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.711583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.280387</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.768724</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.735144</td>\n",
       "      <td>0.725812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.280855</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.768163</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.737750</td>\n",
       "      <td>0.729150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.85      0.88       362\n",
      "                sara       0.66      0.57      0.61       237\n",
      "         radikalisme       0.69      0.80      0.74       235\n",
      "pencemaran_nama_baik       0.72      0.68      0.70       492\n",
      "\n",
      "           micro avg       0.75      0.73      0.74      1326\n",
      "           macro avg       0.74      0.73      0.73      1326\n",
      "        weighted avg       0.76      0.73      0.74      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.684887459807074, F1 Micro: 0.7407975460122699, F1 Macro: 0.7331556826031785\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.85      0.88       362\n",
      "                sara       0.66      0.57      0.61       237\n",
      "         radikalisme       0.69      0.80      0.74       235\n",
      "pencemaran_nama_baik       0.72      0.68      0.70       492\n",
      "\n",
      "           micro avg       0.75      0.73      0.74      1326\n",
      "           macro avg       0.74      0.73      0.73      1326\n",
      "        weighted avg       0.76      0.73      0.74      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0043843988329172155\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 38.81223487854004 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.358507</td>\n",
       "      <td>0.576206</td>\n",
       "      <td>0.771684</td>\n",
       "      <td>0.456259</td>\n",
       "      <td>0.573460</td>\n",
       "      <td>0.533854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302697</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.743151</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.696071</td>\n",
       "      <td>0.693881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268715</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.768781</td>\n",
       "      <td>0.694570</td>\n",
       "      <td>0.729794</td>\n",
       "      <td>0.722614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264375</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.752424</td>\n",
       "      <td>0.741818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263894</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.755788</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.759475</td>\n",
       "      <td>0.751821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.269437</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.787381</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.733790</td>\n",
       "      <td>0.724177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.272703</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.762646</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.750670</td>\n",
       "      <td>0.740594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.276778</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.756960</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.757815</td>\n",
       "      <td>0.748702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.276040</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.750861</td>\n",
       "      <td>0.741691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.278844</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.743168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.85      0.89       362\n",
      "                sara       0.66      0.61      0.64       237\n",
      "         radikalisme       0.69      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.76      0.76      1326\n",
      "           macro avg       0.75      0.76      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6990353697749196, F1 Micro: 0.7594746716697935, F1 Macro: 0.7518212187090552\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.85      0.89       362\n",
      "                sara       0.66      0.61      0.64       237\n",
      "         radikalisme       0.69      0.83      0.75       235\n",
      "pencemaran_nama_baik       0.72      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.76      0.76      1326\n",
      "           macro avg       0.75      0.76      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0029603261034935762\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 34.831881523132324 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341465</td>\n",
       "      <td>0.583280</td>\n",
       "      <td>0.819596</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.535297</td>\n",
       "      <td>0.485240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284544</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.771479</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.709572</td>\n",
       "      <td>0.697877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260159</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.758775</td>\n",
       "      <td>0.755772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250470</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.778391</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.760987</td>\n",
       "      <td>0.751888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.267137</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.724255</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.763026</td>\n",
       "      <td>0.759579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.252393</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.770706</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.764259</td>\n",
       "      <td>0.756059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.263822</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.758697</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.765783</td>\n",
       "      <td>0.758139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.263630</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.776368</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.756861</td>\n",
       "      <td>0.749055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.270349</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.764172</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.763307</td>\n",
       "      <td>0.752699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.269905</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.769946</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.759648</td>\n",
       "      <td>0.751123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.62      0.63      0.62       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.77      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.77      1326\n",
      "         samples avg       0.43      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.7054662379421222, F1 Micro: 0.7657825924542399, F1 Macro: 0.7581393056871597\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.62      0.63      0.62       237\n",
      "         radikalisme       0.73      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.77      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.77      1326\n",
      "         samples avg       0.43      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0037869513500481886\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 31.41926670074463 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.327614</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.739796</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.695444</td>\n",
       "      <td>0.680523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266465</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.726481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.762384</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.752483</td>\n",
       "      <td>0.749841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.248055</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.783388</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.753328</td>\n",
       "      <td>0.749014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.246390</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.800163</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.768809</td>\n",
       "      <td>0.757227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.260871</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.752696</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.770703</td>\n",
       "      <td>0.764647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.265592</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.775557</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.768177</td>\n",
       "      <td>0.759098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.266347</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.796540</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.761417</td>\n",
       "      <td>0.752298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>0.268857</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.781348</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.766334</td>\n",
       "      <td>0.757009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.141400</td>\n",
       "      <td>0.273417</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.770928</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.767424</td>\n",
       "      <td>0.758991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.62      0.65      0.64       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.79      0.76      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.7054662379421222, F1 Micro: 0.770702981229297, F1 Macro: 0.764647251433514\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.62      0.65      0.64       237\n",
      "         radikalisme       0.72      0.86      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.79      0.77      1326\n",
      "           macro avg       0.75      0.79      0.76      1326\n",
      "        weighted avg       0.76      0.79      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0025590402539819508\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 28.22708797454834 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316988</td>\n",
       "      <td>0.639228</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.649321</td>\n",
       "      <td>0.690180</td>\n",
       "      <td>0.669646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258468</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.758929</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.755652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.246291</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.768997</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.766086</td>\n",
       "      <td>0.752729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.243415</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.786806</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.761386</td>\n",
       "      <td>0.750260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.254059</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.751601</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.773343</td>\n",
       "      <td>0.770117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.253368</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.771527</td>\n",
       "      <td>0.764219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.255732</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.787855</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.770239</td>\n",
       "      <td>0.761804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.263284</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.786109</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.768222</td>\n",
       "      <td>0.759216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.271504</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.777182</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>0.763703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.272928</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.773828</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.772659</td>\n",
       "      <td>0.766601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.60      0.72      0.65       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7080385852090032, F1 Micro: 0.7733430977663859, F1 Macro: 0.7701166230482075\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.60      0.72      0.65       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.75      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.77      1326\n",
      "        weighted avg       0.76      0.80      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0014893494080752134\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 25.677059173583984 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300254</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.685972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250092</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.769290</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.760488</td>\n",
       "      <td>0.746204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.236040</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.774096</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.774680</td>\n",
       "      <td>0.767571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.242218</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.762111</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.778147</td>\n",
       "      <td>0.770255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.243840</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.783826</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.771822</td>\n",
       "      <td>0.766180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.269982</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.733016</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.771265</td>\n",
       "      <td>0.764508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.261978</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.799517</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.773364</td>\n",
       "      <td>0.763112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.268397</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.786770</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.774416</td>\n",
       "      <td>0.765599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.276032</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.767923</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.775663</td>\n",
       "      <td>0.770093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.160700</td>\n",
       "      <td>0.277394</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.775495</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.771970</td>\n",
       "      <td>0.763676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.69      0.62      0.65       237\n",
      "         radikalisme       0.73      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.715112540192926, F1 Micro: 0.7781469176818013, F1 Macro: 0.7702549304987261\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.69      0.62      0.65       237\n",
      "         radikalisme       0.73      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.001167353184428066\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 22.9654860496521 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.286482</td>\n",
       "      <td>0.666881</td>\n",
       "      <td>0.773486</td>\n",
       "      <td>0.664404</td>\n",
       "      <td>0.714807</td>\n",
       "      <td>0.707058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241898</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.776744</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.766055</td>\n",
       "      <td>0.755488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.232728</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.771261</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.782156</td>\n",
       "      <td>0.775084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.784285</td>\n",
       "      <td>0.778391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.240721</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.774701</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.777611</td>\n",
       "      <td>0.770235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.259368</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.745957</td>\n",
       "      <td>0.834842</td>\n",
       "      <td>0.787900</td>\n",
       "      <td>0.784118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.264938</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.766836</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.782416</td>\n",
       "      <td>0.774891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.264219</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.765926</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.772795</td>\n",
       "      <td>0.768552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.267896</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.771471</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.775235</td>\n",
       "      <td>0.769852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.271918</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.772218</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.775985</td>\n",
       "      <td>0.770541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.64      0.72      0.68       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.69      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.79      1326\n",
      "           macro avg       0.75      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7196141479099678, F1 Micro: 0.7879003558718861, F1 Macro: 0.7841183771686819\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.64      0.72      0.68       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.69      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.79      1326\n",
      "           macro avg       0.75      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.83      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0010396922007203102\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 20.733506441116333 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 08:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277083</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.744404</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.760605</td>\n",
       "      <td>0.754797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236592</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.766642</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.769808</td>\n",
       "      <td>0.762282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.231749</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.779970</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.777610</td>\n",
       "      <td>0.770484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.776946</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.779865</td>\n",
       "      <td>0.772104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.239476</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.777695</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.783227</td>\n",
       "      <td>0.778131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.242935</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.773960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.263023</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.764663</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>0.775175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.781457</td>\n",
       "      <td>0.778499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.273388</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.767054</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.781805</td>\n",
       "      <td>0.778595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.272519</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.771471</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.775235</td>\n",
       "      <td>0.771172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.68      0.65      0.66       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7209003215434083, F1 Micro: 0.7832272557094722, F1 Macro: 0.7781305200971759\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.68      0.65      0.66       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0004441057273652405\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 18.850395917892456 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273403</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.771064</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.724510</td>\n",
       "      <td>0.714418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240554</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.751089</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.765533</td>\n",
       "      <td>0.754707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.236182</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.750347</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.781792</td>\n",
       "      <td>0.774734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.232364</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.765512</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.782448</td>\n",
       "      <td>0.775927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.236299</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.769853</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.779598</td>\n",
       "      <td>0.772192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>0.247549</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.783308</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.777356</td>\n",
       "      <td>0.768516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.255522</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.777862</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.775803</td>\n",
       "      <td>0.768272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.262783</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.779061</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.771048</td>\n",
       "      <td>0.761807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.273988</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.760522</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.775148</td>\n",
       "      <td>0.771224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.272845</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.771364</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.766602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.71      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7228295819935692, F1 Micro: 0.782448377581121, F1 Macro: 0.7759266391580731\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.63      0.68      0.65       237\n",
      "         radikalisme       0.71      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0004839779634494341\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 17.428792238235474 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273321</td>\n",
       "      <td>0.661736</td>\n",
       "      <td>0.807613</td>\n",
       "      <td>0.592006</td>\n",
       "      <td>0.683203</td>\n",
       "      <td>0.666123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.370400</td>\n",
       "      <td>0.240362</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.785831</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.755677</td>\n",
       "      <td>0.741176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.370400</td>\n",
       "      <td>0.228986</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.790845</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.772850</td>\n",
       "      <td>0.764413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.232837</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.783763</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.770234</td>\n",
       "      <td>0.760931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.237882</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.803079</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.774219</td>\n",
       "      <td>0.765565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.244719</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.784095</td>\n",
       "      <td>0.775563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.255468</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.783077</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.775324</td>\n",
       "      <td>0.766674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.271263</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.762797</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.779948</td>\n",
       "      <td>0.775530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.273861</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.776444</td>\n",
       "      <td>0.769548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.273809</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.770896</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.774944</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.64      0.63      0.64       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7228295819935692, F1 Micro: 0.7840951319212188, F1 Macro: 0.7755633024626885\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.64      0.63      0.64       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.00019375621195649723\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 15.685022354125977 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265739</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.819939</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.698138</td>\n",
       "      <td>0.683209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.748043</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.769681</td>\n",
       "      <td>0.762714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.237475</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.751404</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.778182</td>\n",
       "      <td>0.774116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.790182</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.770954</td>\n",
       "      <td>0.762458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.247521</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.742373</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.774763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.266192</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.746021</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.778058</td>\n",
       "      <td>0.772831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.261367</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.783599</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.780931</td>\n",
       "      <td>0.768647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.266348</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.766230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.281848</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.759885</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.778064</td>\n",
       "      <td>0.770569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.775188</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.776355</td>\n",
       "      <td>0.768090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7138263665594855, F1 Micro: 0.7818636201356658, F1 Macro: 0.7747625683999938\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.72      0.85      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.83      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.83      0.78      1326\n",
      "           macro avg       0.74      0.81      0.77      1326\n",
      "        weighted avg       0.75      0.83      0.78      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0001965036077308468\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 14.082984685897827 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270178</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.831915</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.690203</td>\n",
       "      <td>0.671588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.232103</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.766176</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.775875</td>\n",
       "      <td>0.768269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.224454</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.806291</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.768745</td>\n",
       "      <td>0.755514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.226804</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.781687</td>\n",
       "      <td>0.773639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.770787</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.773393</td>\n",
       "      <td>0.760987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.246984</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.776847</td>\n",
       "      <td>0.767346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.257809</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.770528</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.781413</td>\n",
       "      <td>0.772746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.270831</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.771619</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779395</td>\n",
       "      <td>0.771328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.775112</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.777444</td>\n",
       "      <td>0.768114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.278245</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.777361</td>\n",
       "      <td>0.768723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7228295819935692, F1 Micro: 0.7816874763526296, F1 Macro: 0.7736390199113337\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0001278338924748823\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 12.73984694480896 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261679</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.736462</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.752490</td>\n",
       "      <td>0.739129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.236747</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.779908</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.773384</td>\n",
       "      <td>0.756532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.223803</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.772961</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783029</td>\n",
       "      <td>0.776036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.228910</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.787739</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.781452</td>\n",
       "      <td>0.774414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.240446</td>\n",
       "      <td>0.731833</td>\n",
       "      <td>0.791251</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.784329</td>\n",
       "      <td>0.778369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.256037</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.776361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.260420</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.778027</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.781532</td>\n",
       "      <td>0.772961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.274220</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.768390</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.781771</td>\n",
       "      <td>0.775113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.279582</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.770772</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.777113</td>\n",
       "      <td>0.770130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101100</td>\n",
       "      <td>0.284586</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.768053</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.780868</td>\n",
       "      <td>0.774687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.70      0.64      0.67       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.78      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7318327974276527, F1 Micro: 0.7843286420692278, F1 Macro: 0.7783688551097502\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.70      0.64      0.67       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.78      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 5.351502913981683e-05\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.698895692825317 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 10:06, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250214</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.755894</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.752745</td>\n",
       "      <td>0.748994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.232273</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.768072</td>\n",
       "      <td>0.758250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.777441</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.775973</td>\n",
       "      <td>0.768787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.236017</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.809643</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.770265</td>\n",
       "      <td>0.758807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.242056</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.773501</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.780725</td>\n",
       "      <td>0.775624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.253363</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.778111</td>\n",
       "      <td>0.767743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.271346</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.775120</td>\n",
       "      <td>0.767503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.278143</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.771218</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.779560</td>\n",
       "      <td>0.771119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.282765</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.778452</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.776097</td>\n",
       "      <td>0.766746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.289106</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.770022</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.780052</td>\n",
       "      <td>0.771818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7241157556270097, F1 Micro: 0.7807246918192006, F1 Macro: 0.7756244952048679\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.63      0.69      0.66       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 3.670621008495801e-05\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.203747510910034 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248484</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.752784</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.751144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.240131</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.737508</td>\n",
       "      <td>0.834842</td>\n",
       "      <td>0.783162</td>\n",
       "      <td>0.775318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.224970</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.793408</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.768093</td>\n",
       "      <td>0.753549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229100</td>\n",
       "      <td>0.229046</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.786525</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.785040</td>\n",
       "      <td>0.774258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.235071</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.799054</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.781503</td>\n",
       "      <td>0.773044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.266652</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.738015</td>\n",
       "      <td>0.824284</td>\n",
       "      <td>0.778767</td>\n",
       "      <td>0.774094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.273519</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.767153</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.779674</td>\n",
       "      <td>0.772701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.276379</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.774459</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.778236</td>\n",
       "      <td>0.770341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.289791</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.768668</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.780089</td>\n",
       "      <td>0.773058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.288569</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.774218</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.778861</td>\n",
       "      <td>0.770854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.70      0.58      0.64       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.727331189710611, F1 Micro: 0.7850396675481677, F1 Macro: 0.7742580072855096\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.70      0.58      0.64       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 3.357889800099656e-05\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.786638498306274 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256706</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.726958</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.757674</td>\n",
       "      <td>0.742675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.230135</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.800170</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.752198</td>\n",
       "      <td>0.737833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.226096</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.778116</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.775170</td>\n",
       "      <td>0.767583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.234105</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.766450</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.782577</td>\n",
       "      <td>0.779256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.250884</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.768452</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.784343</td>\n",
       "      <td>0.777060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>0.256293</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.773501</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.780725</td>\n",
       "      <td>0.772359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>0.264883</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.790285</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.781548</td>\n",
       "      <td>0.773291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.282150</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.785661</td>\n",
       "      <td>0.781106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>0.285137</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.778940</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.782739</td>\n",
       "      <td>0.774932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.294343</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.778506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7209003215434083, F1 Micro: 0.7856614929785662, F1 Macro: 0.7811064119120406\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 6.866228522994792e-06\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 7.435049772262573 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246344</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.809879</td>\n",
       "      <td>0.655354</td>\n",
       "      <td>0.724469</td>\n",
       "      <td>0.705090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.226440</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.785544</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.765184</td>\n",
       "      <td>0.754346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.226511</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.767988</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.778274</td>\n",
       "      <td>0.772414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.230125</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.778931</td>\n",
       "      <td>0.770285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>0.247796</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.773460</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.784387</td>\n",
       "      <td>0.772880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.263263</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.767699</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.776286</td>\n",
       "      <td>0.766782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.274916</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.777492</td>\n",
       "      <td>0.770766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.291460</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.750520</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.782232</td>\n",
       "      <td>0.777277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.289250</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.767595</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.778439</td>\n",
       "      <td>0.769468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.296412</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.763177</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.779786</td>\n",
       "      <td>0.772083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.65      0.59      0.62       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7202572347266881, F1 Micro: 0.7843866171003717, F1 Macro: 0.772879792928276\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.65      0.59      0.62       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.2177146527392322e-05\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.021714210510254 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245041</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.814423</td>\n",
       "      <td>0.638763</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.698760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315300</td>\n",
       "      <td>0.229728</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.754894</td>\n",
       "      <td>0.737280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.225773</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.776065</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.786458</td>\n",
       "      <td>0.778135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.234841</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.790133</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.775259</td>\n",
       "      <td>0.760935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.244683</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.782576</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.780801</td>\n",
       "      <td>0.770006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.261910</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.785332</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.780266</td>\n",
       "      <td>0.771984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.281370</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.784024</td>\n",
       "      <td>0.779528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.287688</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.782544</td>\n",
       "      <td>0.775949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.299157</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.765130</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.776538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.298529</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.773641</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.778569</td>\n",
       "      <td>0.771770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.65      0.66       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7234726688102894, F1 Micro: 0.7864583333333333, F1 Macro: 0.7781352094629377\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.65      0.66       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.634669533814303e-05\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.5112385749816895 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244893</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.770465</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.746501</td>\n",
       "      <td>0.744646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.226113</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.753923</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.774927</td>\n",
       "      <td>0.769993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.235534</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.740691</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.780592</td>\n",
       "      <td>0.776944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.238116</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.770182</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.784154</td>\n",
       "      <td>0.778985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.246318</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.786534</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.780858</td>\n",
       "      <td>0.773223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.275265</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.749315</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.785355</td>\n",
       "      <td>0.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.284702</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.763064</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.782960</td>\n",
       "      <td>0.775989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.287568</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.777198</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.781859</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072600</td>\n",
       "      <td>0.301997</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.769899</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.785820</td>\n",
       "      <td>0.779849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.304627</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.766094</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.780391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7196141479099678, F1 Micro: 0.7863436123348018, F1 Macro: 0.7803914170707311\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.64      0.68      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.6822546740513648e-06\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.047449827194214 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240792</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>0.737534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.224825</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.775798</td>\n",
       "      <td>0.768917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.223802</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.772761</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779978</td>\n",
       "      <td>0.768835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.230025</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.782012</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.777862</td>\n",
       "      <td>0.770075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.248208</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.785385</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.777609</td>\n",
       "      <td>0.768913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>0.264615</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.761733</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.778311</td>\n",
       "      <td>0.772475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.283172</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.765864</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.778643</td>\n",
       "      <td>0.771210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.289063</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.784652</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.769881</td>\n",
       "      <td>0.760670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.302766</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.763980</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.778394</td>\n",
       "      <td>0.770532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.300057</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.768084</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.772403</td>\n",
       "      <td>0.764066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.68      0.60      0.64       237\n",
      "         radikalisme       0.76      0.78      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7183279742765273, F1 Micro: 0.7799775868509525, F1 Macro: 0.7688349721607501\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.68      0.60      0.64       237\n",
      "         radikalisme       0.76      0.78      0.77       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.1806039947259708e-05\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.6972119808197021 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240263</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.738146</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.761592</td>\n",
       "      <td>0.759039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.221381</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.765269</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.774674</td>\n",
       "      <td>0.769882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.226021</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.769004</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.777322</td>\n",
       "      <td>0.770202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.231218</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.770541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.242245</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.772161</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>0.778090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.268904</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.754436</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.777331</td>\n",
       "      <td>0.768888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.278430</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.759312</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.778839</td>\n",
       "      <td>0.774020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.293993</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.757405</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.782799</td>\n",
       "      <td>0.778499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.300282</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.762079</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.773403</td>\n",
       "      <td>0.765863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.304965</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.769789</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.778248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.67      0.66       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7254019292604501, F1 Micro: 0.7843137254901962, F1 Macro: 0.7782476057385488\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.67      0.66       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 377.61 seconds\n",
      "Total runtime: 11687.252957105637 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4c5b01",
   "metadata": {
    "papermill": {
     "duration": 0.017965,
     "end_time": "2024-12-22T17:48:19.973196",
     "exception": false,
     "start_time": "2024-12-22T17:48:19.955231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c9ab66b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T17:48:20.010608Z",
     "iopub.status.busy": "2024-12-22T17:48:20.010271Z",
     "iopub.status.idle": "2024-12-22T21:01:43.194983Z",
     "shell.execute_reply": "2024-12-22T21:01:43.193960Z"
    },
    "papermill": {
     "duration": 11603.205338,
     "end_time": "2024-12-22T21:01:43.196387",
     "exception": false,
     "start_time": "2024-12-22T17:48:19.991049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460827</td>\n",
       "      <td>0.440514</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>0.044738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.398824</td>\n",
       "      <td>0.576849</td>\n",
       "      <td>0.872222</td>\n",
       "      <td>0.236802</td>\n",
       "      <td>0.372479</td>\n",
       "      <td>0.261927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353225</td>\n",
       "      <td>0.591640</td>\n",
       "      <td>0.830054</td>\n",
       "      <td>0.349925</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.420032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330393</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.429864</td>\n",
       "      <td>0.553130</td>\n",
       "      <td>0.459224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.761511</td>\n",
       "      <td>0.486425</td>\n",
       "      <td>0.593649</td>\n",
       "      <td>0.525215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.605145</td>\n",
       "      <td>0.788366</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0.597001</td>\n",
       "      <td>0.545943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299625</td>\n",
       "      <td>0.612862</td>\n",
       "      <td>0.739634</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.610205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297249</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.771834</td>\n",
       "      <td>0.533183</td>\n",
       "      <td>0.630687</td>\n",
       "      <td>0.596109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294833</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.772004</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.641692</td>\n",
       "      <td>0.603582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.774123</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.592582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6128617363344051, F1 Micro: 0.649174777824799, F1 Macro: 0.6102054118583491\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.79      0.84       362\n",
      "                sara       0.74      0.23      0.35       237\n",
      "         radikalisme       0.68      0.60      0.64       235\n",
      "pencemaran_nama_baik       0.65      0.58      0.62       492\n",
      "\n",
      "           micro avg       0.74      0.58      0.65      1326\n",
      "           macro avg       0.74      0.55      0.61      1326\n",
      "        weighted avg       0.74      0.58      0.63      1326\n",
      "         samples avg       0.38      0.34      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0023636298719793562\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 43.188647747039795 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.394753</td>\n",
       "      <td>0.544695</td>\n",
       "      <td>0.746647</td>\n",
       "      <td>0.377828</td>\n",
       "      <td>0.501753</td>\n",
       "      <td>0.442381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312152</td>\n",
       "      <td>0.637942</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.588989</td>\n",
       "      <td>0.668092</td>\n",
       "      <td>0.656634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284362</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.725480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266955</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.750383</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.733060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261938</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.764182</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.736719</td>\n",
       "      <td>0.723942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259349</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.696833</td>\n",
       "      <td>0.735084</td>\n",
       "      <td>0.727175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262174</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.766254</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.747850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268042</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.760968</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.759819</td>\n",
       "      <td>0.750443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.267012</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.753383</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.754518</td>\n",
       "      <td>0.747122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.265580</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.769473</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.753177</td>\n",
       "      <td>0.747164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.69      0.62      0.65       237\n",
      "         radikalisme       0.73      0.74      0.73       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.76      0.76      1326\n",
      "           macro avg       0.76      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6919614147909968, F1 Micro: 0.7598187311178248, F1 Macro: 0.7504425230025057\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.69      0.62      0.65       237\n",
      "         radikalisme       0.73      0.74      0.73       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.76      0.76      1326\n",
      "           macro avg       0.76      0.75      0.75      1326\n",
      "        weighted avg       0.76      0.76      0.76      1326\n",
      "         samples avg       0.42      0.42      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.004960259143263111\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 38.94581651687622 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.360506</td>\n",
       "      <td>0.563344</td>\n",
       "      <td>0.694577</td>\n",
       "      <td>0.550528</td>\n",
       "      <td>0.614220</td>\n",
       "      <td>0.599991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291184</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.760244</td>\n",
       "      <td>0.657617</td>\n",
       "      <td>0.705216</td>\n",
       "      <td>0.696254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.279365</td>\n",
       "      <td>0.659807</td>\n",
       "      <td>0.704197</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.747789</td>\n",
       "      <td>0.743708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255162</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.764479</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.755437</td>\n",
       "      <td>0.748749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254998</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.781276</td>\n",
       "      <td>0.711161</td>\n",
       "      <td>0.744572</td>\n",
       "      <td>0.736926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.260677</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.774167</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.745405</td>\n",
       "      <td>0.736133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.266670</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.752438</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.754419</td>\n",
       "      <td>0.747554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.269904</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.755948</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.749334</td>\n",
       "      <td>0.741645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.272734</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.750563</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.751976</td>\n",
       "      <td>0.744575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.751423</td>\n",
       "      <td>0.744334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.89       362\n",
      "                sara       0.67      0.61      0.64       237\n",
      "         radikalisme       0.72      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.71      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.75      0.76      1326\n",
      "           macro avg       0.76      0.74      0.75      1326\n",
      "        weighted avg       0.77      0.75      0.76      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6983922829581993, F1 Micro: 0.7554368561617703, F1 Macro: 0.7487486937772516\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.85      0.89       362\n",
      "                sara       0.67      0.61      0.64       237\n",
      "         radikalisme       0.72      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.71      0.73      0.72       492\n",
      "\n",
      "           micro avg       0.76      0.75      0.76      1326\n",
      "           macro avg       0.76      0.74      0.75      1326\n",
      "        weighted avg       0.77      0.75      0.76      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.002403522562235595\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 35.05343985557556 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.341628</td>\n",
       "      <td>0.616720</td>\n",
       "      <td>0.699357</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.677043</td>\n",
       "      <td>0.669571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278748</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.753521</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.739631</td>\n",
       "      <td>0.726456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.253964</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.786449</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.722378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251845</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.772836</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.752805</td>\n",
       "      <td>0.747517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.253449</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.762094</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.742945</td>\n",
       "      <td>0.730647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.265106</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.762045</td>\n",
       "      <td>0.755428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.266512</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.751101</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.761161</td>\n",
       "      <td>0.755057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.264874</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.764209</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.757230</td>\n",
       "      <td>0.751664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.271563</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.763240</td>\n",
       "      <td>0.739065</td>\n",
       "      <td>0.750958</td>\n",
       "      <td>0.744470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.272585</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.760337</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.754559</td>\n",
       "      <td>0.748060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.90      0.90       362\n",
      "                sara       0.66      0.63      0.64       237\n",
      "         radikalisme       0.73      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.74      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.78      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.690032154340836, F1 Micro: 0.7620448694372931, F1 Macro: 0.7554280656743667\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.90      0.90       362\n",
      "                sara       0.66      0.63      0.64       237\n",
      "         radikalisme       0.73      0.80      0.76       235\n",
      "pencemaran_nama_baik       0.69      0.76      0.72       492\n",
      "\n",
      "           micro avg       0.74      0.78      0.76      1326\n",
      "           macro avg       0.74      0.77      0.76      1326\n",
      "        weighted avg       0.75      0.78      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0036476409994065763\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 31.604849576950073 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316243</td>\n",
       "      <td>0.598714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.497738</td>\n",
       "      <td>0.609418</td>\n",
       "      <td>0.591113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.264348</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.787523</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.716283</td>\n",
       "      <td>0.693122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250348</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.768686</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.752407</td>\n",
       "      <td>0.744344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>0.250160</td>\n",
       "      <td>0.688103</td>\n",
       "      <td>0.781016</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.742382</td>\n",
       "      <td>0.729113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.789602</td>\n",
       "      <td>0.733032</td>\n",
       "      <td>0.760266</td>\n",
       "      <td>0.750222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.378100</td>\n",
       "      <td>0.258103</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.769953</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.755760</td>\n",
       "      <td>0.744100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.771558</td>\n",
       "      <td>0.765733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.267260</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.767952</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.767082</td>\n",
       "      <td>0.761656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.269351</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.769518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.269731</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.780125</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.765745</td>\n",
       "      <td>0.760511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.69      0.67      0.68       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.71      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.44      0.43      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.7093247588424437, F1 Micro: 0.7730015082956259, F1 Macro: 0.7695175937152525\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.69      0.67      0.68       237\n",
      "         radikalisme       0.73      0.83      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.71      0.72       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.77      0.77      0.77      1326\n",
      "         samples avg       0.44      0.43      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0037643912248313434\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 28.44988989830017 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319828</td>\n",
       "      <td>0.634084</td>\n",
       "      <td>0.692565</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.733593</td>\n",
       "      <td>0.729898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255891</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.768283</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.760381</td>\n",
       "      <td>0.743869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.240001</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.764264</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.756398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.237106</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.788766</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.769884</td>\n",
       "      <td>0.759303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>0.248506</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.759942</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.775932</td>\n",
       "      <td>0.770011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>0.249170</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.786794</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.765776</td>\n",
       "      <td>0.755667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>0.258309</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.784082</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.766859</td>\n",
       "      <td>0.759832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>0.264825</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.782574</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.759798</td>\n",
       "      <td>0.750613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.268392</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.770398</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.272103</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.775915</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.771797</td>\n",
       "      <td>0.765413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7144694533762058, F1 Micro: 0.7759320782576596, F1 Macro: 0.7700107428052048\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.66      0.65      0.65       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.79      0.78      1326\n",
      "           macro avg       0.75      0.79      0.77      1326\n",
      "        weighted avg       0.76      0.79      0.78      1326\n",
      "         samples avg       0.44      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0018189940601587296\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 25.65479612350464 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290923</td>\n",
       "      <td>0.635370</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.618977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247230</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.780640</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.767165</td>\n",
       "      <td>0.764129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.243571</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.756116</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.762617</td>\n",
       "      <td>0.753732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.237549</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.778201</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.774071</td>\n",
       "      <td>0.765548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.380400</td>\n",
       "      <td>0.242048</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.778452</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.776097</td>\n",
       "      <td>0.768236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.252185</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.773656</td>\n",
       "      <td>0.766976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.261662</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.766099</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.773254</td>\n",
       "      <td>0.766976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.266326</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.771772</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.773514</td>\n",
       "      <td>0.767246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.268410</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.763727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.271494</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.767012</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.774459</td>\n",
       "      <td>0.767966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.62      0.64       237\n",
      "         radikalisme       0.77      0.80      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.77      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.77      0.78      1326\n",
      "         samples avg       0.45      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7157556270096463, F1 Micro: 0.7760968229954615, F1 Macro: 0.7682364819623942\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.62      0.64       237\n",
      "         radikalisme       0.77      0.80      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.77      0.78      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.77      0.78      1326\n",
      "         samples avg       0.45      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0012707347050309181\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 23.096931219100952 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.282626</td>\n",
       "      <td>0.666238</td>\n",
       "      <td>0.828933</td>\n",
       "      <td>0.592006</td>\n",
       "      <td>0.690717</td>\n",
       "      <td>0.679179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244956</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.802236</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.749699</td>\n",
       "      <td>0.743935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.234929</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.776153</td>\n",
       "      <td>0.770749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.238988</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.786223</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.767092</td>\n",
       "      <td>0.751704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.252846</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.750173</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.781352</td>\n",
       "      <td>0.777327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.255257</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.760289</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.776835</td>\n",
       "      <td>0.773098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.263124</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.780469</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.778995</td>\n",
       "      <td>0.776080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.271492</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.792228</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.772323</td>\n",
       "      <td>0.761547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.274100</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.782041</td>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.775200</td>\n",
       "      <td>0.768470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.279673</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.774436</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.775602</td>\n",
       "      <td>0.770418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.92       362\n",
      "                sara       0.63      0.71      0.67       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7118971061093248, F1 Micro: 0.7813516443801951, F1 Macro: 0.7773273457943826\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.92       362\n",
      "                sara       0.63      0.71      0.67       237\n",
      "         radikalisme       0.74      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.69      0.81      0.75       492\n",
      "\n",
      "           micro avg       0.75      0.82      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.000875266152434051\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 20.826843976974487 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274777</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.736479</td>\n",
       "      <td>0.732566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248439</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.828767</td>\n",
       "      <td>0.638763</td>\n",
       "      <td>0.721465</td>\n",
       "      <td>0.698308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.234560</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.752125</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.775749</td>\n",
       "      <td>0.771938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>0.233009</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.774796</td>\n",
       "      <td>0.760427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.239846</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.773958</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.785741</td>\n",
       "      <td>0.775710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.260365</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.756852</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.783558</td>\n",
       "      <td>0.777838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.255379</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.778795</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.774365</td>\n",
       "      <td>0.767504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.271264</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.768607</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.777488</td>\n",
       "      <td>0.769454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.273974</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.776346</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.774291</td>\n",
       "      <td>0.765855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.126600</td>\n",
       "      <td>0.274235</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.776853</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.775680</td>\n",
       "      <td>0.768050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.61      0.63       237\n",
      "         radikalisme       0.76      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7196141479099678, F1 Micro: 0.785740809506127, F1 Macro: 0.7757099419845617\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.61      0.63       237\n",
      "         radikalisme       0.76      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0004513358406256888\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 18.922720909118652 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266520</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.800557</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.717970</td>\n",
       "      <td>0.710341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242445</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.763716</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.775343</td>\n",
       "      <td>0.766050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.228037</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.771341</td>\n",
       "      <td>0.762410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.234834</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.762040</td>\n",
       "      <td>0.811463</td>\n",
       "      <td>0.785975</td>\n",
       "      <td>0.780570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.237025</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.786898</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.787491</td>\n",
       "      <td>0.781297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243600</td>\n",
       "      <td>0.252683</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.782478</td>\n",
       "      <td>0.775318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.262824</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.766187</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.784242</td>\n",
       "      <td>0.777723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.266052</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.775056</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.774174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.268444</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.790335</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.777309</td>\n",
       "      <td>0.768665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.273589</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.780120</td>\n",
       "      <td>0.772447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.68      0.66      0.67       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7311897106109325, F1 Micro: 0.787490580256217, F1 Macro: 0.7812972080644348\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.68      0.66      0.67       237\n",
      "         radikalisme       0.75      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0002832115977071226\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 17.55895233154297 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263065</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.785411</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.739321</td>\n",
       "      <td>0.726965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.236239</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.750201</td>\n",
       "      <td>0.729886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.231391</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.797678</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.759874</td>\n",
       "      <td>0.749403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.229781</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.790396</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.786202</td>\n",
       "      <td>0.777157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.247670</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.753653</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.783931</td>\n",
       "      <td>0.777178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.255588</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.782080</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.779417</td>\n",
       "      <td>0.772939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172100</td>\n",
       "      <td>0.262360</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.791091</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.783866</td>\n",
       "      <td>0.776600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.272950</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.771555</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780470</td>\n",
       "      <td>0.775496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.279586</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.768444</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.780705</td>\n",
       "      <td>0.774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.279754</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.776779</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.779406</td>\n",
       "      <td>0.774472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.70      0.61      0.65       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7286173633440515, F1 Micro: 0.7862016679302501, F1 Macro: 0.7771573031220365\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.70      0.61      0.65       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0002595329511677846\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 15.72869324684143 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 09:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263412</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.750572</td>\n",
       "      <td>0.738062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.235258</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.802226</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.751403</td>\n",
       "      <td>0.743631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.227237</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.757017</td>\n",
       "      <td>0.746062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.229515</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.791766</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.772499</td>\n",
       "      <td>0.761176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.238518</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.809563</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.773533</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.262110</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.760979</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.778637</td>\n",
       "      <td>0.770242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.270749</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.759458</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.780345</td>\n",
       "      <td>0.772192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.270395</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.791217</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.782774</td>\n",
       "      <td>0.775342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.287248</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.763348</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.780236</td>\n",
       "      <td>0.772977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>0.284515</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.771787</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.773953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.77      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.76      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.77      0.78      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.77      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.729903536977492, F1 Micro: 0.7827743902439024, F1 Macro: 0.7753416889410738\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.67      0.62      0.65       237\n",
      "         radikalisme       0.77      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.76      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.77      0.78      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.77      0.78      1326\n",
      "         samples avg       0.45      0.44      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 8.157326374202963e-05\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 14.197447299957275 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271003</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.804926</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>0.697992</td>\n",
       "      <td>0.660585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.237881</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.786179</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.756651</td>\n",
       "      <td>0.736202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.227963</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.767414</td>\n",
       "      <td>0.753267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.237995</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.752249</td>\n",
       "      <td>0.819759</td>\n",
       "      <td>0.784554</td>\n",
       "      <td>0.777435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.247047</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.765759</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.785452</td>\n",
       "      <td>0.776133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.258374</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.772993</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.785608</td>\n",
       "      <td>0.775557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.266120</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.782998</td>\n",
       "      <td>0.778531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.272395</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.781061</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.779289</td>\n",
       "      <td>0.772386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.281986</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.763233</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.783407</td>\n",
       "      <td>0.776718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.282322</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.775165</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.785262</td>\n",
       "      <td>0.778691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.67      0.63      0.65       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7247588424437299, F1 Micro: 0.7856083086053413, F1 Macro: 0.7755570657342689\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.67      0.63      0.65       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 9.9244339071447e-05\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 12.728227615356445 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258551</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.762346</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.744959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>0.230169</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.762164</td>\n",
       "      <td>0.748888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.351800</td>\n",
       "      <td>0.224875</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.794707</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.770307</td>\n",
       "      <td>0.760275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.235932</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.796975</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.775368</td>\n",
       "      <td>0.764015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.247588</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.771555</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780470</td>\n",
       "      <td>0.769846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.254170</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.773792</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.785290</td>\n",
       "      <td>0.777306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.262755</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.782708</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.777060</td>\n",
       "      <td>0.767589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.785102</td>\n",
       "      <td>0.778376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.284389</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.773363</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.782868</td>\n",
       "      <td>0.775962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.287605</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.772394</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>0.775625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.63      0.65       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7247588424437299, F1 Micro: 0.7852897473997028, F1 Macro: 0.777305685518708\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.63      0.65       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 4.929464776068931e-05\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.750552654266357 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251019</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.758327</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.748185</td>\n",
       "      <td>0.743801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.227838</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.785328</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.776040</td>\n",
       "      <td>0.765634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.225576</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.814751</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.749896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.229261</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.786552</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.772361</td>\n",
       "      <td>0.758880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.243487</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.782929</td>\n",
       "      <td>0.774301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.248101</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.781557</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.780672</td>\n",
       "      <td>0.773806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.258823</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.796838</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.778078</td>\n",
       "      <td>0.769356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.282630</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.778739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>0.283966</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.767341</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.783764</td>\n",
       "      <td>0.778772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.282898</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.778439</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.783976</td>\n",
       "      <td>0.778720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.67      0.66       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7189710610932476, F1 Micro: 0.7839760389367278, F1 Macro: 0.7787195398519834\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.66      0.67      0.66       237\n",
      "         radikalisme       0.76      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 1.4783309961785574e-05\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.29879093170166 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249307</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.707526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.230873</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.780315</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.763482</td>\n",
       "      <td>0.760367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.227398</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.783425</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.769290</td>\n",
       "      <td>0.766955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.235710</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.786371</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.780395</td>\n",
       "      <td>0.773365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.238140</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.774854</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.786934</td>\n",
       "      <td>0.779039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.260329</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.771066</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.775403</td>\n",
       "      <td>0.766211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.772218</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.775985</td>\n",
       "      <td>0.769220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.278990</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.763939</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.771898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.281549</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.771237</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.769407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.288923</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.770818</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.779724</td>\n",
       "      <td>0.773950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.65      0.64      0.64       237\n",
      "         radikalisme       0.76      0.86      0.81       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7266881028938906, F1 Micro: 0.7869339272457313, F1 Macro: 0.7790392975809395\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.91       362\n",
      "                sara       0.65      0.64      0.64       237\n",
      "         radikalisme       0.76      0.86      0.81       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 2.945139167422896e-05\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.720850944519043 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256154</td>\n",
       "      <td>0.679743</td>\n",
       "      <td>0.806113</td>\n",
       "      <td>0.636501</td>\n",
       "      <td>0.711336</td>\n",
       "      <td>0.700579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.235974</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.834119</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.741517</td>\n",
       "      <td>0.722915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.228782</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.761632</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.781491</td>\n",
       "      <td>0.772922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.244810</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.784511</td>\n",
       "      <td>0.777317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.245304</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.783233</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>0.777721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.262102</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.761939</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.783437</td>\n",
       "      <td>0.776017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.269638</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.771505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.283973</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.777695</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.780616</td>\n",
       "      <td>0.772996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.294798</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779057</td>\n",
       "      <td>0.772618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.295018</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.772761</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779978</td>\n",
       "      <td>0.772883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.84      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.715112540192926, F1 Micro: 0.7845105772678379, F1 Macro: 0.7773172148053569\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.63      0.67      0.65       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.84      0.76       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.78      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 4.200385665171781e-05\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 7.376342058181763 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 11:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260092</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.824841</td>\n",
       "      <td>0.585973</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.659756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326100</td>\n",
       "      <td>0.223091</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.801495</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>0.749759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.221109</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.803586</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.772425</td>\n",
       "      <td>0.762274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.229485</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.778366</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.777190</td>\n",
       "      <td>0.767750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.237081</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.783692</td>\n",
       "      <td>0.772838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.254131</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.781627</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.782216</td>\n",
       "      <td>0.774750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.265688</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.801277</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.778596</td>\n",
       "      <td>0.767662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.282283</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.778029</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.778908</td>\n",
       "      <td>0.771009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.287365</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.779533</td>\n",
       "      <td>0.771194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.293603</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.775130</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.780067</td>\n",
       "      <td>0.772605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.58      0.62       237\n",
      "         radikalisme       0.75      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7247588424437299, F1 Micro: 0.7836919592298981, F1 Macro: 0.7728379773014296\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.89      0.91       362\n",
      "                sara       0.67      0.58      0.62       237\n",
      "         radikalisme       0.75      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.78      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.0256983478029717e-05\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.004159212112427 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240280</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.781533</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.746751</td>\n",
       "      <td>0.739770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.321300</td>\n",
       "      <td>0.226818</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.784223</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.774341</td>\n",
       "      <td>0.761915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>0.223205</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.775340</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.774169</td>\n",
       "      <td>0.759514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.219800</td>\n",
       "      <td>0.230893</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.789755</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.772281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.245394</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.768619</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.784791</td>\n",
       "      <td>0.774150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.250339</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.785004</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.779339</td>\n",
       "      <td>0.769617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.271338</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.778111</td>\n",
       "      <td>0.770015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.289593</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.752949</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>0.784243</td>\n",
       "      <td>0.776168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.287485</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.775321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.294700</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.769732</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.785371</td>\n",
       "      <td>0.778171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7247588424437299, F1 Micro: 0.7853712596970818, F1 Macro: 0.7781710349156302\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 2.176238558604382e-06\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.531265735626221 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243194</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.808394</td>\n",
       "      <td>0.668175</td>\n",
       "      <td>0.731627</td>\n",
       "      <td>0.711372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.310600</td>\n",
       "      <td>0.234670</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.736519</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>0.766818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.773998</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.773122</td>\n",
       "      <td>0.762218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212000</td>\n",
       "      <td>0.233969</td>\n",
       "      <td>0.734405</td>\n",
       "      <td>0.786567</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.781380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.240513</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.786202</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.773206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.262878</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.753684</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>0.773903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.281528</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.755889</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.776678</td>\n",
       "      <td>0.769624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.285079</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.778940</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.782739</td>\n",
       "      <td>0.775120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076500</td>\n",
       "      <td>0.299115</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.768275</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.780252</td>\n",
       "      <td>0.773396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.768452</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.784343</td>\n",
       "      <td>0.776444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7344051446945338, F1 Micro: 0.7906976744186046, F1 Macro: 0.781380128236674\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.75      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 7.761515371385032e-06\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0555014610290527 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 12:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241692</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.800530</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.737698</td>\n",
       "      <td>0.727896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.767669</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.768825</td>\n",
       "      <td>0.759478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.223925</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.778603</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.784431</td>\n",
       "      <td>0.772716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.239137</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.753715</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.777656</td>\n",
       "      <td>0.768491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.242983</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.789976</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.768873</td>\n",
       "      <td>0.754914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.269746</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.762248</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.771771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.267571</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.792786</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.785850</td>\n",
       "      <td>0.778381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.297680</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.752268</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.781443</td>\n",
       "      <td>0.777566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>0.294823</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.785130</td>\n",
       "      <td>0.780286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.302018</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.782383</td>\n",
       "      <td>0.776598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.78      0.80      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7286173633440515, F1 Micro: 0.7858501331304679, F1 Macro: 0.7783807819363775\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.68      0.64      0.66       237\n",
      "         radikalisme       0.78      0.80      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.73      0.74       492\n",
      "\n",
      "           micro avg       0.79      0.78      0.79      1326\n",
      "           macro avg       0.78      0.77      0.78      1326\n",
      "        weighted avg       0.79      0.78      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.3562551885115684e-06\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.7022590637207031 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237551</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.756211</td>\n",
       "      <td>0.746600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.218964</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.789266</td>\n",
       "      <td>0.754148</td>\n",
       "      <td>0.771307</td>\n",
       "      <td>0.764185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.220005</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.781157</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.787584</td>\n",
       "      <td>0.774291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.234292</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.765277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.257346</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.758693</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.789436</td>\n",
       "      <td>0.780517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.265043</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.788253</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.770445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.275489</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.777444</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.778614</td>\n",
       "      <td>0.769419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.293470</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.775526</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.777276</td>\n",
       "      <td>0.770183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.301912</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.771852</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.778774</td>\n",
       "      <td>0.772625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.306704</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>0.772765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.93      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.76      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.81      0.77       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7221864951768489, F1 Micro: 0.7894356005788713, F1 Macro: 0.7805173721579128\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.93      0.91       362\n",
      "                sara       0.62      0.68      0.65       237\n",
      "         radikalisme       0.76      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.81      0.77       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.75      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n",
      "Total sampling time: 379.4 seconds\n",
      "Total runtime: 11602.418340682983 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5648cca",
   "metadata": {
    "papermill": {
     "duration": 0.032559,
     "end_time": "2024-12-22T21:01:43.263624",
     "exception": false,
     "start_time": "2024-12-22T21:01:43.231065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c347bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T21:01:43.332241Z",
     "iopub.status.busy": "2024-12-22T21:01:43.331845Z",
     "iopub.status.idle": "2024-12-23T00:12:51.171136Z",
     "shell.execute_reply": "2024-12-23T00:12:51.170224Z"
    },
    "papermill": {
     "duration": 11467.875127,
     "end_time": "2024-12-23T00:12:51.172561",
     "exception": false,
     "start_time": "2024-12-22T21:01:43.297434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466312</td>\n",
       "      <td>0.447588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392322</td>\n",
       "      <td>0.554984</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.191554</td>\n",
       "      <td>0.317104</td>\n",
       "      <td>0.211713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349551</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.319759</td>\n",
       "      <td>0.462377</td>\n",
       "      <td>0.381456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331326</td>\n",
       "      <td>0.586495</td>\n",
       "      <td>0.799035</td>\n",
       "      <td>0.374811</td>\n",
       "      <td>0.510267</td>\n",
       "      <td>0.438305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317812</td>\n",
       "      <td>0.590997</td>\n",
       "      <td>0.812303</td>\n",
       "      <td>0.388386</td>\n",
       "      <td>0.525510</td>\n",
       "      <td>0.465296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312626</td>\n",
       "      <td>0.603859</td>\n",
       "      <td>0.802213</td>\n",
       "      <td>0.437406</td>\n",
       "      <td>0.566130</td>\n",
       "      <td>0.506563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301693</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.758030</td>\n",
       "      <td>0.533937</td>\n",
       "      <td>0.626549</td>\n",
       "      <td>0.600378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300017</td>\n",
       "      <td>0.610932</td>\n",
       "      <td>0.759957</td>\n",
       "      <td>0.532428</td>\n",
       "      <td>0.626164</td>\n",
       "      <td>0.598342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301048</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.765419</td>\n",
       "      <td>0.524133</td>\n",
       "      <td>0.622202</td>\n",
       "      <td>0.587982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300751</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.768632</td>\n",
       "      <td>0.521116</td>\n",
       "      <td>0.621124</td>\n",
       "      <td>0.587391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6102893890675242, F1 Micro: 0.6265486725663717, F1 Macro: 0.6003779383425171\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.81      0.86       362\n",
      "                sara       0.64      0.25      0.36       237\n",
      "         radikalisme       0.68      0.66      0.67       235\n",
      "pencemaran_nama_baik       0.69      0.41      0.51       492\n",
      "\n",
      "           micro avg       0.76      0.53      0.63      1326\n",
      "           macro avg       0.73      0.53      0.60      1326\n",
      "        weighted avg       0.74      0.53      0.61      1326\n",
      "         samples avg       0.35      0.31      0.32      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.002649796381592751\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 43.25934314727783 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.401846</td>\n",
       "      <td>0.543408</td>\n",
       "      <td>0.810507</td>\n",
       "      <td>0.325792</td>\n",
       "      <td>0.464766</td>\n",
       "      <td>0.443674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335444</td>\n",
       "      <td>0.571061</td>\n",
       "      <td>0.843806</td>\n",
       "      <td>0.354449</td>\n",
       "      <td>0.499203</td>\n",
       "      <td>0.439800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288346</td>\n",
       "      <td>0.655949</td>\n",
       "      <td>0.784798</td>\n",
       "      <td>0.599548</td>\n",
       "      <td>0.679778</td>\n",
       "      <td>0.664004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274632</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>0.751252</td>\n",
       "      <td>0.678733</td>\n",
       "      <td>0.713154</td>\n",
       "      <td>0.703889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271129</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.768893</td>\n",
       "      <td>0.659879</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.701775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270576</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.724901</td>\n",
       "      <td>0.716709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275180</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.759380</td>\n",
       "      <td>0.702112</td>\n",
       "      <td>0.729624</td>\n",
       "      <td>0.723697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278518</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.746501</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.735069</td>\n",
       "      <td>0.730316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.276634</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.687783</td>\n",
       "      <td>0.722949</td>\n",
       "      <td>0.717162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.279137</td>\n",
       "      <td>0.664952</td>\n",
       "      <td>0.753659</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.719445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.85      0.88       362\n",
      "                sara       0.65      0.58      0.61       237\n",
      "         radikalisme       0.73      0.76      0.74       235\n",
      "pencemaran_nama_baik       0.68      0.68      0.68       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.74      1326\n",
      "           macro avg       0.74      0.72      0.73      1326\n",
      "        weighted avg       0.75      0.72      0.74      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6733118971061093, F1 Micro: 0.7350689127105665, F1 Macro: 0.7303157837986083\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.85      0.88       362\n",
      "                sara       0.65      0.58      0.61       237\n",
      "         radikalisme       0.73      0.76      0.74       235\n",
      "pencemaran_nama_baik       0.68      0.68      0.68       492\n",
      "\n",
      "           micro avg       0.75      0.72      0.74      1326\n",
      "           macro avg       0.74      0.72      0.73      1326\n",
      "        weighted avg       0.75      0.72      0.74      1326\n",
      "         samples avg       0.40      0.40      0.39      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.005382639821618795\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 38.919211626052856 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.366467</td>\n",
       "      <td>0.564630</td>\n",
       "      <td>0.700382</td>\n",
       "      <td>0.553544</td>\n",
       "      <td>0.618366</td>\n",
       "      <td>0.614019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304276</td>\n",
       "      <td>0.632154</td>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.588989</td>\n",
       "      <td>0.669237</td>\n",
       "      <td>0.629820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267855</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.752739</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.738863</td>\n",
       "      <td>0.730076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.263009</td>\n",
       "      <td>0.676527</td>\n",
       "      <td>0.744586</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.748218</td>\n",
       "      <td>0.736141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257556</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.804945</td>\n",
       "      <td>0.662896</td>\n",
       "      <td>0.727047</td>\n",
       "      <td>0.711506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.260644</td>\n",
       "      <td>0.683601</td>\n",
       "      <td>0.753645</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.747052</td>\n",
       "      <td>0.743786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.261032</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.771036</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.743950</td>\n",
       "      <td>0.735798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.266211</td>\n",
       "      <td>0.684244</td>\n",
       "      <td>0.764799</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.747397</td>\n",
       "      <td>0.742150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.268555</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.770716</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.745815</td>\n",
       "      <td>0.737667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.686817</td>\n",
       "      <td>0.769968</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.747867</td>\n",
       "      <td>0.740912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.68      0.51      0.58       237\n",
      "         radikalisme       0.75      0.77      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.75      0.71       492\n",
      "\n",
      "           micro avg       0.74      0.75      0.75      1326\n",
      "           macro avg       0.75      0.73      0.74      1326\n",
      "        weighted avg       0.75      0.75      0.75      1326\n",
      "         samples avg       0.43      0.42      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6765273311897106, F1 Micro: 0.7482176360225141, F1 Macro: 0.7361408996065582\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.89      0.89       362\n",
      "                sara       0.68      0.51      0.58       237\n",
      "         radikalisme       0.75      0.77      0.76       235\n",
      "pencemaran_nama_baik       0.67      0.75      0.71       492\n",
      "\n",
      "           micro avg       0.74      0.75      0.75      1326\n",
      "           macro avg       0.75      0.73      0.74      1326\n",
      "        weighted avg       0.75      0.75      0.75      1326\n",
      "         samples avg       0.43      0.42      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0026822858024388584\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 35.11684226989746 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.350694</td>\n",
       "      <td>0.572347</td>\n",
       "      <td>0.757030</td>\n",
       "      <td>0.507541</td>\n",
       "      <td>0.607675</td>\n",
       "      <td>0.596166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.288478</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.758506</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.722244</td>\n",
       "      <td>0.703022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256175</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.770505</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.753277</td>\n",
       "      <td>0.744971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270462</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.710336</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.758524</td>\n",
       "      <td>0.756823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.253824</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.759522</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.763227</td>\n",
       "      <td>0.759147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.256704</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.796392</td>\n",
       "      <td>0.699095</td>\n",
       "      <td>0.744578</td>\n",
       "      <td>0.735477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.782470</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.760945</td>\n",
       "      <td>0.757701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.262251</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.763168</td>\n",
       "      <td>0.758591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.268066</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.768582</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.762448</td>\n",
       "      <td>0.758278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.267591</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.757568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.67      0.61      0.64       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.71      0.71       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.76      0.77      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6971061093247588, F1 Micro: 0.7632270168855536, F1 Macro: 0.7591474285772731\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.90      0.90       362\n",
      "                sara       0.67      0.61      0.64       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.71      0.71       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.76      0.77      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.76      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0028828650712966948\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 31.62633466720581 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.321511</td>\n",
       "      <td>0.605145</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>0.610694</td>\n",
       "      <td>0.598677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266468</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.759055</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.742681</td>\n",
       "      <td>0.741380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.663650</td>\n",
       "      <td>0.730290</td>\n",
       "      <td>0.715548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.806649</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.746861</td>\n",
       "      <td>0.737420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.244678</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.749623</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.759687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.252443</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.770167</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.763581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.256504</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.764402</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.769527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.262012</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.763704</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.770553</td>\n",
       "      <td>0.767525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.267392</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.768821</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.765619</td>\n",
       "      <td>0.758303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.265576</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.777519</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.766820</td>\n",
       "      <td>0.759002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.7093247588424437, F1 Micro: 0.7723880597014925, F1 Macro: 0.769527482139984\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.78      0.77      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.77      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.003223154786974196\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 28.4896240234375 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316019</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.776089</td>\n",
       "      <td>0.577677</td>\n",
       "      <td>0.662343</td>\n",
       "      <td>0.625237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258053</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.776167</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.750779</td>\n",
       "      <td>0.745673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.251799</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.740896</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.768337</td>\n",
       "      <td>0.764980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.243646</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.753060</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.770534</td>\n",
       "      <td>0.764007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.248709</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.740947</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.770456</td>\n",
       "      <td>0.768597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.770228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.251937</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.778972</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.772157</td>\n",
       "      <td>0.761951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.258108</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.755991</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.770255</td>\n",
       "      <td>0.764780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.262399</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.770504</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.771375</td>\n",
       "      <td>0.763038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.262898</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.769288</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.771890</td>\n",
       "      <td>0.764539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.88      0.90       362\n",
      "                sara       0.66      0.65      0.66       237\n",
      "         radikalisme       0.77      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.77      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7131832797427653, F1 Micro: 0.7745098039215687, F1 Macro: 0.770228286363165\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.88      0.90       362\n",
      "                sara       0.66      0.65      0.66       237\n",
      "         radikalisme       0.77      0.81      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.77      0.77      1326\n",
      "           macro avg       0.77      0.77      0.77      1326\n",
      "        weighted avg       0.78      0.77      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.00177869014441967\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 25.666548490524292 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300945</td>\n",
       "      <td>0.609646</td>\n",
       "      <td>0.784205</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.633708</td>\n",
       "      <td>0.602230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254106</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.780570</td>\n",
       "      <td>0.702866</td>\n",
       "      <td>0.739683</td>\n",
       "      <td>0.722504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.237228</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.785542</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.760793</td>\n",
       "      <td>0.748787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.243563</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.744976</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.776454</td>\n",
       "      <td>0.772465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.238171</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.763930</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.774721</td>\n",
       "      <td>0.768535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.244443</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.796340</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.775068</td>\n",
       "      <td>0.765968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.253047</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.782542</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.776596</td>\n",
       "      <td>0.771289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.257735</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.798232</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.772763</td>\n",
       "      <td>0.766381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.262352</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.776346</td>\n",
       "      <td>0.771173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.266127</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.776524</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.777401</td>\n",
       "      <td>0.773022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.77      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.72      0.72       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.715112540192926, F1 Micro: 0.777401129943503, F1 Macro: 0.7730216706884161\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.77      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.72      0.72       492\n",
      "\n",
      "           micro avg       0.78      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0013196833315305412\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 22.880383729934692 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289789</td>\n",
       "      <td>0.672669</td>\n",
       "      <td>0.751403</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>0.715773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247760</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.782114</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.752739</td>\n",
       "      <td>0.730178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.242740</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.737526</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.773754</td>\n",
       "      <td>0.769949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.229802</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.814626</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.765787</td>\n",
       "      <td>0.757157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.241691</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.770696</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>0.776378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.243503</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.801292</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.773791</td>\n",
       "      <td>0.766139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.257375</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.773414</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.772830</td>\n",
       "      <td>0.767108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.265104</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.770818</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.779724</td>\n",
       "      <td>0.775657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.270044</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.783474</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.777820</td>\n",
       "      <td>0.770574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.269476</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.787855</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.780358</td>\n",
       "      <td>0.775712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.68      0.66      0.67       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7196141479099678, F1 Micro: 0.7818654775176515, F1 Macro: 0.7763779516678719\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.68      0.66      0.67       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.71      0.77      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.000825527764391154\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 20.719524383544922 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284227</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.779174</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.711475</td>\n",
       "      <td>0.689309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250540</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.778776</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.747942</td>\n",
       "      <td>0.732069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.232922</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.760838</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.777122</td>\n",
       "      <td>0.770662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.225536</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.780916</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.776176</td>\n",
       "      <td>0.769441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.234403</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.777194</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.779240</td>\n",
       "      <td>0.773091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.241261</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.778735</td>\n",
       "      <td>0.773876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.249783</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.785986</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.782114</td>\n",
       "      <td>0.772193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.257481</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.787102</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.775354</td>\n",
       "      <td>0.766918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.265923</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.782478</td>\n",
       "      <td>0.774261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.266645</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.776866</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.780945</td>\n",
       "      <td>0.773521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.68      0.63      0.65       237\n",
      "         radikalisme       0.73      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7215434083601286, F1 Micro: 0.7824784724822164, F1 Macro: 0.7742608436575753\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.68      0.63      0.65       237\n",
      "         radikalisme       0.73      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.00029403340304270416\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 18.729446172714233 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274818</td>\n",
       "      <td>0.662379</td>\n",
       "      <td>0.744240</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.737443</td>\n",
       "      <td>0.726971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.772122</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.757587</td>\n",
       "      <td>0.756391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.228915</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.799028</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.770312</td>\n",
       "      <td>0.759388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.227718</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.797600</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.774068</td>\n",
       "      <td>0.765671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.236853</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.766691</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.785583</td>\n",
       "      <td>0.778822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.246500</td>\n",
       "      <td>0.244640</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.790297</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.775730</td>\n",
       "      <td>0.768067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.252738</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.782510</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.779250</td>\n",
       "      <td>0.769279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.263848</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.769622</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.783864</td>\n",
       "      <td>0.776965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.264705</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.780169</td>\n",
       "      <td>0.774035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.268068</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.785011</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>0.776677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7221864951768489, F1 Micro: 0.7855829349025377, F1 Macro: 0.778821974768431\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.00036072772636543967\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 17.31388282775879 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266737</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.740105</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.743715</td>\n",
       "      <td>0.739989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.237196</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.778988</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.766756</td>\n",
       "      <td>0.754127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.234381</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.778219</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.757740</td>\n",
       "      <td>0.745531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.237127</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.764490</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.775009</td>\n",
       "      <td>0.764782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.240275</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.776006</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.773364</td>\n",
       "      <td>0.764094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.248567</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.796340</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.775068</td>\n",
       "      <td>0.765630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>0.262625</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.771577</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.776779</td>\n",
       "      <td>0.770151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.276657</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.775964</td>\n",
       "      <td>0.768846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.283199</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.776021</td>\n",
       "      <td>0.770987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.099300</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.773712</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.772008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.66      0.66       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7183279742765273, F1 Micro: 0.777485928705441, F1 Macro: 0.7720083092903627\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.66      0.66       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.73      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.78      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.78      0.78      1326\n",
      "         samples avg       0.44      0.44      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0001093305050744675\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 15.596034288406372 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262977</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.785838</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.732689</td>\n",
       "      <td>0.720543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.231201</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.770732</td>\n",
       "      <td>0.764668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.228580</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.835945</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.752385</td>\n",
       "      <td>0.735808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.239200</td>\n",
       "      <td>0.230488</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.833037</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.765090</td>\n",
       "      <td>0.750409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.239200</td>\n",
       "      <td>0.239745</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.778932</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>0.777406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.245893</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.782140</td>\n",
       "      <td>0.773826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.265372</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.771866</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.785026</td>\n",
       "      <td>0.776676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.265654</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.790895</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.781846</td>\n",
       "      <td>0.772278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.274148</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.781764</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.785285</td>\n",
       "      <td>0.776636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.275052</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.789177</td>\n",
       "      <td>0.781932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.77      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7305466237942122, F1 Micro: 0.7891770011273957, F1 Macro: 0.7819322562923477\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.77      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.79      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 4.8079117914312495e-05\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 14.07624077796936 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262296</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.674208</td>\n",
       "      <td>0.726829</td>\n",
       "      <td>0.721477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.238252</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.766629</td>\n",
       "      <td>0.753771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.225712</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.762838</td>\n",
       "      <td>0.750024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.241693</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.751911</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.782640</td>\n",
       "      <td>0.778248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.239658</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.793538</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.776108</td>\n",
       "      <td>0.768021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.252547</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.792468</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.768454</td>\n",
       "      <td>0.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>0.272458</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.776968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.127200</td>\n",
       "      <td>0.278245</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.764198</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.782481</td>\n",
       "      <td>0.776373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.281528</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.776053</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.783875</td>\n",
       "      <td>0.776911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.283662</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.779926</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.785474</td>\n",
       "      <td>0.777586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.75      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7247588424437299, F1 Micro: 0.7854736053912391, F1 Macro: 0.7775864614840142\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.75      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 2.94038638458005e-05\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 12.682311058044434 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252444</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.761610</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.751719</td>\n",
       "      <td>0.745570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.238810</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.775809</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.767530</td>\n",
       "      <td>0.755859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.240835</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.738241</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.770211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.228585</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.786848</td>\n",
       "      <td>0.776705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.236904</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.772795</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>0.770894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.251015</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.765557</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781388</td>\n",
       "      <td>0.774221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.263282</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.773654</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.787407</td>\n",
       "      <td>0.780706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.275247</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.763989</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.783088</td>\n",
       "      <td>0.775808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.276440</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.775389</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.782056</td>\n",
       "      <td>0.775773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.277639</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.775223</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.781601</td>\n",
       "      <td>0.774802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7311897106109325, F1 Micro: 0.7874074074074074, F1 Macro: 0.7807057537247999\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 3.363400974194526e-05\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.67770791053772 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251835</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.764196</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.747109</td>\n",
       "      <td>0.736426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.235584</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.814414</td>\n",
       "      <td>0.681750</td>\n",
       "      <td>0.742200</td>\n",
       "      <td>0.724978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.233059</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.756565</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.779525</td>\n",
       "      <td>0.773376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.230982</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.776612</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.769702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.240886</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.789961</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.780618</td>\n",
       "      <td>0.772614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172700</td>\n",
       "      <td>0.247905</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.791217</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.782774</td>\n",
       "      <td>0.775595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.268745</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>0.822021</td>\n",
       "      <td>0.791863</td>\n",
       "      <td>0.785421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.269215</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.786466</td>\n",
       "      <td>0.778413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.282650</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.771137</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.784285</td>\n",
       "      <td>0.778122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.281723</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.773529</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.777240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.65      0.71      0.68       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7286173633440515, F1 Micro: 0.7918634217217579, F1 Macro: 0.7854209311299433\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.65      0.71      0.68       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 3.3604213967919356e-05\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.167858123779297 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250093</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.774167</td>\n",
       "      <td>0.700603</td>\n",
       "      <td>0.735550</td>\n",
       "      <td>0.713940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.228768</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.795868</td>\n",
       "      <td>0.726244</td>\n",
       "      <td>0.759464</td>\n",
       "      <td>0.743904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.222326</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.784329</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.773231</td>\n",
       "      <td>0.767583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.231050</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779686</td>\n",
       "      <td>0.772330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.237944</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.785332</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.780266</td>\n",
       "      <td>0.771838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169400</td>\n",
       "      <td>0.255359</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.791732</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.778374</td>\n",
       "      <td>0.769008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.261871</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.789275</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.781504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.279882</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.767960</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.786608</td>\n",
       "      <td>0.780333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>0.287904</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.773888</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.786800</td>\n",
       "      <td>0.782496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.286518</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.781687</td>\n",
       "      <td>0.775366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.68      0.65      0.67       237\n",
      "         radikalisme       0.77      0.80      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.727331189710611, F1 Micro: 0.7886792452830188, F1 Macro: 0.7815044390709627\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.68      0.65      0.67       237\n",
      "         radikalisme       0.77      0.80      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 9.862107435765233e-06\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.751190423965454 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247969</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.755234</td>\n",
       "      <td>0.741709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>0.227730</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.768833</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.776866</td>\n",
       "      <td>0.764046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>0.226575</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.773091</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.787116</td>\n",
       "      <td>0.777294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.231562</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.765591</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.785006</td>\n",
       "      <td>0.777110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.250601</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.782576</td>\n",
       "      <td>0.773424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.260230</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.763518</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.780686</td>\n",
       "      <td>0.772075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.273795</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.781846</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.777399</td>\n",
       "      <td>0.771093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.282618</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.784095</td>\n",
       "      <td>0.777468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.295617</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.773460</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.784387</td>\n",
       "      <td>0.777811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.293814</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.781413</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.786971</td>\n",
       "      <td>0.779512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7247588424437299, F1 Micro: 0.787115883006294, F1 Macro: 0.7772941525796254\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.64      0.65       237\n",
      "         radikalisme       0.73      0.84      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 4.5198604493634785e-05\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 7.322348594665527 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.258782</td>\n",
       "      <td>0.681672</td>\n",
       "      <td>0.708279</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.762535</td>\n",
       "      <td>0.759636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.229621</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.789909</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.753452</td>\n",
       "      <td>0.748909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.227139</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.774849</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.775433</td>\n",
       "      <td>0.769713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.235383</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.782344</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.769541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.790938</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.770124</td>\n",
       "      <td>0.756059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.255961</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.810544</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.774803</td>\n",
       "      <td>0.761798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.284046</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.757962</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.782037</td>\n",
       "      <td>0.774766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.285642</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.778853</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.783814</td>\n",
       "      <td>0.775427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.289046</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.782510</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.779250</td>\n",
       "      <td>0.770878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.297460</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.779940</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>0.776113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7241157556270097, F1 Micro: 0.7838141626077183, F1 Macro: 0.7754272190947258\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.67      0.64      0.66       237\n",
      "         radikalisme       0.75      0.82      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 4.335823268775129e-06\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.992175340652466 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244937</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.783531</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.737220</td>\n",
       "      <td>0.730819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.223090</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.769568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.226365</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.779938</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.767994</td>\n",
       "      <td>0.761774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.235582</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.786987</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.776462</td>\n",
       "      <td>0.767528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.252004</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.768284</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.783894</td>\n",
       "      <td>0.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.270374</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.757254</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.781307</td>\n",
       "      <td>0.773975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.279146</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.776765</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.774120</td>\n",
       "      <td>0.767204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.287827</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.772590</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.773173</td>\n",
       "      <td>0.765389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.298858</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.770757</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.780796</td>\n",
       "      <td>0.774555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.301133</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>0.777328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.63      0.71      0.67       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7202572347266881, F1 Micro: 0.7838936091614334, F1 Macro: 0.7799992253795074\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.63      0.71      0.67       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 5.798357597086578e-06\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.481413841247559 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241686</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.771497</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.735593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.224271</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.769970</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.777446</td>\n",
       "      <td>0.768753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.236834</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.729084</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.775424</td>\n",
       "      <td>0.767980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.231116</td>\n",
       "      <td>0.736334</td>\n",
       "      <td>0.806147</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.788439</td>\n",
       "      <td>0.777349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.237064</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.812908</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.780392</td>\n",
       "      <td>0.767917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.254776</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.786787</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.788563</td>\n",
       "      <td>0.779131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.275681</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.775964</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.782349</td>\n",
       "      <td>0.774395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.292749</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.766215</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.787834</td>\n",
       "      <td>0.782098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.297570</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.785661</td>\n",
       "      <td>0.777996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.298902</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.775256</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.786776</td>\n",
       "      <td>0.778238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.66      0.60      0.63       237\n",
      "         radikalisme       0.78      0.83      0.81       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7254019292604501, F1 Micro: 0.7885628291948833, F1 Macro: 0.7791307897631552\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.91      0.92       362\n",
      "                sara       0.66      0.60      0.63       237\n",
      "         radikalisme       0.78      0.83      0.81       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 2.688477616175078e-06\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.05415940284729 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.744236</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.761238</td>\n",
       "      <td>0.755097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.244465</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.720493</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>0.774756</td>\n",
       "      <td>0.771790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205800</td>\n",
       "      <td>0.232686</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.796583</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.766341</td>\n",
       "      <td>0.755606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.239421</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.761665</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.780434</td>\n",
       "      <td>0.773492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161300</td>\n",
       "      <td>0.247603</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.798737</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.780563</td>\n",
       "      <td>0.768938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.267331</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.770349</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.784604</td>\n",
       "      <td>0.778472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.274838</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.787414</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.780525</td>\n",
       "      <td>0.771031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.781749</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.778493</td>\n",
       "      <td>0.770077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.307439</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.772627</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.775663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.771555</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780470</td>\n",
       "      <td>0.773108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.67      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7266881028938906, F1 Micro: 0.7846039970392302, F1 Macro: 0.7784721049391167\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.67      0.66       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.9114851511403697e-06\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.6702980995178223 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248374</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.845756</td>\n",
       "      <td>0.616139</td>\n",
       "      <td>0.712914</td>\n",
       "      <td>0.688868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.228043</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.776727</td>\n",
       "      <td>0.769257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>0.232241</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.738781</td>\n",
       "      <td>0.831825</td>\n",
       "      <td>0.782547</td>\n",
       "      <td>0.777184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.231086</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.251731</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.762074</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.784931</td>\n",
       "      <td>0.777074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120900</td>\n",
       "      <td>0.265391</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.774339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.273217</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.803543</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.777259</td>\n",
       "      <td>0.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.288632</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.778529</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.780286</td>\n",
       "      <td>0.773537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.306937</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.757426</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.781752</td>\n",
       "      <td>0.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.302274</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.776532</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.780030</td>\n",
       "      <td>0.772537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7215434083601286, F1 Micro: 0.784930504754938, F1 Macro: 0.7770739820900597\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.67      0.65       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 378.19 seconds\n",
      "Total runtime: 11467.06394481659 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63bbd5",
   "metadata": {},
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad57f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1078d017ec450b93859be5b10d8d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnicost918\u001b[0m (\u001b[33mnicost918-petra-christian-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241222_142614-w7l031ps\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./results/netifier-mc-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nicost918-petra-christian-university/huggingface/runs/w7l031ps\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.463594</td>\n",
       "      <td>0.462379</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.049751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.391793</td>\n",
       "      <td>0.568489</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.278281</td>\n",
       "      <td>0.416949</td>\n",
       "      <td>0.340929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357158</td>\n",
       "      <td>0.562701</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.250377</td>\n",
       "      <td>0.389215</td>\n",
       "      <td>0.305181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.331397</td>\n",
       "      <td>0.590354</td>\n",
       "      <td>0.783858</td>\n",
       "      <td>0.432127</td>\n",
       "      <td>0.557122</td>\n",
       "      <td>0.487882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.317543</td>\n",
       "      <td>0.603215</td>\n",
       "      <td>0.790637</td>\n",
       "      <td>0.458522</td>\n",
       "      <td>0.580430</td>\n",
       "      <td>0.516101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307228</td>\n",
       "      <td>0.619293</td>\n",
       "      <td>0.780571</td>\n",
       "      <td>0.515083</td>\n",
       "      <td>0.620627</td>\n",
       "      <td>0.590389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304412</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.775442</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.586116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301726</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.763407</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.605725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302151</td>\n",
       "      <td>0.625723</td>\n",
       "      <td>0.764644</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.640666</td>\n",
       "      <td>0.610989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.300772</td>\n",
       "      <td>0.628939</td>\n",
       "      <td>0.751984</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.649529</td>\n",
       "      <td>0.626356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.6289389067524116, F1 Micro: 0.6495287060839761, F1 Macro: 0.626355645176144\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.76      0.84       362\n",
      "                sara       0.70      0.31      0.43       237\n",
      "         radikalisme       0.65      0.62      0.63       235\n",
      "pencemaran_nama_baik       0.68      0.53      0.60       492\n",
      "\n",
      "           micro avg       0.75      0.57      0.65      1326\n",
      "           macro avg       0.74      0.56      0.63      1326\n",
      "        weighted avg       0.75      0.57      0.64      1326\n",
      "         samples avg       0.35      0.33      0.33      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.003258097870275382\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 42.63621258735657 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.393320</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.813592</td>\n",
       "      <td>0.315988</td>\n",
       "      <td>0.455187</td>\n",
       "      <td>0.363160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.320124</td>\n",
       "      <td>0.606431</td>\n",
       "      <td>0.825352</td>\n",
       "      <td>0.441931</td>\n",
       "      <td>0.575639</td>\n",
       "      <td>0.532272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284241</td>\n",
       "      <td>0.654662</td>\n",
       "      <td>0.788650</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.686542</td>\n",
       "      <td>0.667491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271769</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.768486</td>\n",
       "      <td>0.658371</td>\n",
       "      <td>0.709180</td>\n",
       "      <td>0.696748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274218</td>\n",
       "      <td>0.670740</td>\n",
       "      <td>0.759046</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.713626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.269784</td>\n",
       "      <td>0.679100</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.725329</td>\n",
       "      <td>0.711193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.273490</td>\n",
       "      <td>0.681029</td>\n",
       "      <td>0.799443</td>\n",
       "      <td>0.649321</td>\n",
       "      <td>0.716604</td>\n",
       "      <td>0.702167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275738</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.733696</td>\n",
       "      <td>0.724812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.273213</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.786449</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.728033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.275060</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.786022</td>\n",
       "      <td>0.687029</td>\n",
       "      <td>0.733199</td>\n",
       "      <td>0.724803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.83      0.88       362\n",
      "                sara       0.70      0.55      0.61       237\n",
      "         radikalisme       0.75      0.72      0.73       235\n",
      "pencemaran_nama_baik       0.74      0.64      0.69       492\n",
      "\n",
      "           micro avg       0.79      0.69      0.74      1326\n",
      "           macro avg       0.78      0.69      0.73      1326\n",
      "        weighted avg       0.78      0.69      0.73      1326\n",
      "         samples avg       0.39      0.39      0.38      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6887459807073955, F1 Micro: 0.7359550561797753, F1 Macro: 0.7280334269266118\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.83      0.88       362\n",
      "                sara       0.70      0.55      0.61       237\n",
      "         radikalisme       0.75      0.72      0.73       235\n",
      "pencemaran_nama_baik       0.74      0.64      0.69       492\n",
      "\n",
      "           micro avg       0.79      0.69      0.74      1326\n",
      "           macro avg       0.78      0.69      0.73      1326\n",
      "        weighted avg       0.78      0.69      0.73      1326\n",
      "         samples avg       0.39      0.39      0.38      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.004801036417484285\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 38.44659185409546 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355195</td>\n",
       "      <td>0.571061</td>\n",
       "      <td>0.765568</td>\n",
       "      <td>0.472851</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.580131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294770</td>\n",
       "      <td>0.649518</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.681178</td>\n",
       "      <td>0.671248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266388</td>\n",
       "      <td>0.691318</td>\n",
       "      <td>0.773849</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.740362</td>\n",
       "      <td>0.730483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256333</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.729064</td>\n",
       "      <td>0.715989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256766</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.691554</td>\n",
       "      <td>0.739218</td>\n",
       "      <td>0.732190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.261408</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.776500</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.743217</td>\n",
       "      <td>0.737718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.260898</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.782430</td>\n",
       "      <td>0.718703</td>\n",
       "      <td>0.749214</td>\n",
       "      <td>0.739316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.269244</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.778682</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.749119</td>\n",
       "      <td>0.741263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.267458</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.779592</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.748726</td>\n",
       "      <td>0.740549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.269810</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.782465</td>\n",
       "      <td>0.713424</td>\n",
       "      <td>0.746351</td>\n",
       "      <td>0.737831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.86      0.89       362\n",
      "                sara       0.69      0.55      0.61       237\n",
      "         radikalisme       0.73      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.75      0.67      0.71       492\n",
      "\n",
      "           micro avg       0.78      0.72      0.75      1326\n",
      "           macro avg       0.77      0.71      0.74      1326\n",
      "        weighted avg       0.78      0.72      0.75      1326\n",
      "         samples avg       0.41      0.40      0.40      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.6983922829581993, F1 Micro: 0.7492138364779874, F1 Macro: 0.7393164423073333\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.86      0.89       362\n",
      "                sara       0.69      0.55      0.61       237\n",
      "         radikalisme       0.73      0.77      0.75       235\n",
      "pencemaran_nama_baik       0.75      0.67      0.71       492\n",
      "\n",
      "           micro avg       0.78      0.72      0.75      1326\n",
      "           macro avg       0.77      0.71      0.74      1326\n",
      "        weighted avg       0.78      0.72      0.75      1326\n",
      "         samples avg       0.41      0.40      0.40      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0042204767931252754\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 34.659520864486694 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.350931</td>\n",
       "      <td>0.551125</td>\n",
       "      <td>0.660741</td>\n",
       "      <td>0.672700</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280679</td>\n",
       "      <td>0.673955</td>\n",
       "      <td>0.775493</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.726033</td>\n",
       "      <td>0.709343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255332</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.783182</td>\n",
       "      <td>0.716440</td>\n",
       "      <td>0.748326</td>\n",
       "      <td>0.739424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250572</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.773555</td>\n",
       "      <td>0.736802</td>\n",
       "      <td>0.754732</td>\n",
       "      <td>0.747824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.251539</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.781863</td>\n",
       "      <td>0.721719</td>\n",
       "      <td>0.750588</td>\n",
       "      <td>0.739344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.258395</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.812444</td>\n",
       "      <td>0.689291</td>\n",
       "      <td>0.745818</td>\n",
       "      <td>0.732774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.256937</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.795130</td>\n",
       "      <td>0.714178</td>\n",
       "      <td>0.752483</td>\n",
       "      <td>0.744707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.265222</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.795262</td>\n",
       "      <td>0.708899</td>\n",
       "      <td>0.749601</td>\n",
       "      <td>0.740041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.271837</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.779023</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>0.747605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.271042</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.754894</td>\n",
       "      <td>0.748443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.68      0.56      0.62       237\n",
      "         radikalisme       0.74      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.67      0.70       492\n",
      "\n",
      "           micro avg       0.78      0.73      0.76      1326\n",
      "           macro avg       0.77      0.73      0.75      1326\n",
      "        weighted avg       0.78      0.73      0.75      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.7054662379421222, F1 Micro: 0.7557281553398058, F1 Macro: 0.7476045247385581\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.88      0.90       362\n",
      "                sara       0.68      0.56      0.62       237\n",
      "         radikalisme       0.74      0.80      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.67      0.70       492\n",
      "\n",
      "           micro avg       0.78      0.73      0.76      1326\n",
      "           macro avg       0.77      0.73      0.75      1326\n",
      "        weighted avg       0.78      0.73      0.75      1326\n",
      "         samples avg       0.42      0.41      0.41      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.003375271242111922\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 31.188051223754883 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329938</td>\n",
       "      <td>0.583923</td>\n",
       "      <td>0.679160</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.681203</td>\n",
       "      <td>0.679583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266333</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.795556</td>\n",
       "      <td>0.674962</td>\n",
       "      <td>0.730314</td>\n",
       "      <td>0.721450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244125</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.788003</td>\n",
       "      <td>0.723228</td>\n",
       "      <td>0.754227</td>\n",
       "      <td>0.743792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.240491</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.789819</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.756289</td>\n",
       "      <td>0.746676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.246403</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.796327</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.755943</td>\n",
       "      <td>0.750561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.250973</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.753215</td>\n",
       "      <td>0.744916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.257275</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.758301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.262434</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.780715</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.768760</td>\n",
       "      <td>0.759534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.264534</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.798195</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.764637</td>\n",
       "      <td>0.756876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.266918</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.784640</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.765547</td>\n",
       "      <td>0.758294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.89      0.90       362\n",
      "                sara       0.68      0.57      0.62       237\n",
      "         radikalisme       0.77      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.72      0.73       492\n",
      "\n",
      "           micro avg       0.78      0.76      0.77      1326\n",
      "           macro avg       0.77      0.75      0.76      1326\n",
      "        weighted avg       0.78      0.76      0.77      1326\n",
      "         samples avg       0.44      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.7163987138263666, F1 Micro: 0.7687595712098009, F1 Macro: 0.7595343819886143\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.89      0.90       362\n",
      "                sara       0.68      0.57      0.62       237\n",
      "         radikalisme       0.77      0.83      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.72      0.73       492\n",
      "\n",
      "           micro avg       0.78      0.76      0.77      1326\n",
      "           macro avg       0.77      0.75      0.76      1326\n",
      "        weighted avg       0.78      0.76      0.77      1326\n",
      "         samples avg       0.44      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0026530363131314514\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 28.17506432533264 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312185</td>\n",
       "      <td>0.641801</td>\n",
       "      <td>0.742834</td>\n",
       "      <td>0.684012</td>\n",
       "      <td>0.712210</td>\n",
       "      <td>0.699933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256220</td>\n",
       "      <td>0.698392</td>\n",
       "      <td>0.759822</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.759818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.241103</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.777609</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.773778</td>\n",
       "      <td>0.767124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.238192</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.759050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.388200</td>\n",
       "      <td>0.240199</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.808456</td>\n",
       "      <td>0.706637</td>\n",
       "      <td>0.754125</td>\n",
       "      <td>0.737838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.247020</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.807047</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.764098</td>\n",
       "      <td>0.755999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.258695</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770132</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.781575</td>\n",
       "      <td>0.775991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.261166</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.774096</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.774680</td>\n",
       "      <td>0.767323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.265413</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.777104</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.775047</td>\n",
       "      <td>0.766627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.267597</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.774606</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.776063</td>\n",
       "      <td>0.768632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7209003215434083, F1 Micro: 0.7815750371471024, F1 Macro: 0.7759907597120708\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.74      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.00169987918343395\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 25.360082149505615 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.292959</td>\n",
       "      <td>0.667524</td>\n",
       "      <td>0.758590</td>\n",
       "      <td>0.649321</td>\n",
       "      <td>0.699716</td>\n",
       "      <td>0.700099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249490</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.802867</td>\n",
       "      <td>0.675716</td>\n",
       "      <td>0.733825</td>\n",
       "      <td>0.721602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.238880</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.763464</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.777037</td>\n",
       "      <td>0.773221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.234604</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.779357</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.782576</td>\n",
       "      <td>0.774268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.235389</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.784463</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.780599</td>\n",
       "      <td>0.772018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.247423</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.805099</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.770260</td>\n",
       "      <td>0.761087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.775416</td>\n",
       "      <td>0.766035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.262064</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.786105</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.772535</td>\n",
       "      <td>0.767392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.264190</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.788776</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.775776</td>\n",
       "      <td>0.769297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.267255</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.773065</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.778277</td>\n",
       "      <td>0.773972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.68      0.63      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7209003215434083, F1 Micro: 0.7825760420578295, F1 Macro: 0.7742676299727903\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.68      0.63      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.77      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0010258442489430308\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 22.85179352760315 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285629</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>0.796829</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.688651</td>\n",
       "      <td>0.681516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243789</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.794093</td>\n",
       "      <td>0.709653</td>\n",
       "      <td>0.749502</td>\n",
       "      <td>0.738096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.803787</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.750804</td>\n",
       "      <td>0.739224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.753613</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.788053</td>\n",
       "      <td>0.780901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.234589</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.783908</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.777651</td>\n",
       "      <td>0.767172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.243836</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.784897</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.780432</td>\n",
       "      <td>0.770630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.249409</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.786708</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.777099</td>\n",
       "      <td>0.768273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.251537</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.777361</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.779699</td>\n",
       "      <td>0.772135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.259557</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.776165</td>\n",
       "      <td>0.767619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.261898</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.784848</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.776965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.81      0.77       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.79      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.7196141479099678, F1 Micro: 0.7880532565671104, F1 Macro: 0.7809011453327289\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.89      0.91      0.90       362\n",
      "                sara       0.63      0.70      0.66       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.81      0.77       492\n",
      "\n",
      "           micro avg       0.75      0.83      0.79      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.47      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0009325450519099832\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 20.599200963974 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274535</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>0.800391</td>\n",
       "      <td>0.616893</td>\n",
       "      <td>0.696763</td>\n",
       "      <td>0.670383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246330</td>\n",
       "      <td>0.697749</td>\n",
       "      <td>0.806625</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.737618</td>\n",
       "      <td>0.721940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.230601</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.757695</td>\n",
       "      <td>0.744669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.229243</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.784781</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.777313</td>\n",
       "      <td>0.769532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.231020</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.790845</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.772850</td>\n",
       "      <td>0.762870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.244037</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.779123</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.777946</td>\n",
       "      <td>0.770093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.251165</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.786212</td>\n",
       "      <td>0.765460</td>\n",
       "      <td>0.775697</td>\n",
       "      <td>0.768661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>0.259003</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.790461</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.776200</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.267954</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.780343</td>\n",
       "      <td>0.776227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.268875</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.773134</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.777194</td>\n",
       "      <td>0.771545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.66      0.67       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7189710610932476, F1 Micro: 0.7803425167535368, F1 Macro: 0.7762267191674295\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.66      0.67       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.00030444273143075454\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 18.637320518493652 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:09, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267492</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.791923</td>\n",
       "      <td>0.680241</td>\n",
       "      <td>0.731846</td>\n",
       "      <td>0.725494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.234885</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.778462</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>0.761515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.239936</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.751067</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.769430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.233251</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.799174</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.762618</td>\n",
       "      <td>0.757762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.243962</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.749826</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.780470</td>\n",
       "      <td>0.774883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.246056</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.776731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.249728</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.778534</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.777652</td>\n",
       "      <td>0.769512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>0.270287</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.758790</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.785298</td>\n",
       "      <td>0.780213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.274649</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.765299</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.783057</td>\n",
       "      <td>0.777472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.271684</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.774074</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.781016</td>\n",
       "      <td>0.775193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7241157556270097, F1 Micro: 0.7852983988355168, F1 Macro: 0.7802130540660148\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.91       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.79      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.00027628550305962583\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 17.257524967193604 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268493</td>\n",
       "      <td>0.691961</td>\n",
       "      <td>0.747727</td>\n",
       "      <td>0.744344</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.744013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.233021</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.779701</td>\n",
       "      <td>0.747360</td>\n",
       "      <td>0.763188</td>\n",
       "      <td>0.757145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.368200</td>\n",
       "      <td>0.232219</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.803404</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.754898</td>\n",
       "      <td>0.745381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.232924</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.773766</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.782706</td>\n",
       "      <td>0.773437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.769062</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779926</td>\n",
       "      <td>0.770637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.243199</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.781687</td>\n",
       "      <td>0.771842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.259166</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.799523</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.778165</td>\n",
       "      <td>0.768453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.271280</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.766094</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.786344</td>\n",
       "      <td>0.780665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.272764</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.776053</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.783875</td>\n",
       "      <td>0.778025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.277078</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.779686</td>\n",
       "      <td>0.772476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7311897106109325, F1 Micro: 0.7863436123348018, F1 Macro: 0.7806649816228883\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.65      0.69      0.67       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0001234992145327851\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 15.552795648574829 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265850</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.809100</td>\n",
       "      <td>0.616893</td>\n",
       "      <td>0.700043</td>\n",
       "      <td>0.691838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.236543</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.767407</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.774290</td>\n",
       "      <td>0.769032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.224267</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.773739</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.780105</td>\n",
       "      <td>0.771894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.238763</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.770649</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.779269</td>\n",
       "      <td>0.770447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.230444</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.789069</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.770579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.759233</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.782004</td>\n",
       "      <td>0.773985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.253448</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.770338</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.788214</td>\n",
       "      <td>0.783848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.262037</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.769899</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.785820</td>\n",
       "      <td>0.777868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.272072</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.762894</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.782513</td>\n",
       "      <td>0.773892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.270260</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.770941</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.777570</td>\n",
       "      <td>0.770180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.729903536977492, F1 Micro: 0.7882136279926336, F1 Macro: 0.7838482451932203\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.75      0.85      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 7.186958464444614e-05\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 14.041863679885864 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256112</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.741974</td>\n",
       "      <td>0.733774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.230410</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.790507</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>0.750008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.223917</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.773517</td>\n",
       "      <td>0.806184</td>\n",
       "      <td>0.789513</td>\n",
       "      <td>0.782450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.235155</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.749471</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.774335</td>\n",
       "      <td>0.767416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.234272</td>\n",
       "      <td>0.731833</td>\n",
       "      <td>0.782836</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.786947</td>\n",
       "      <td>0.780504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.257729</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.753492</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.782451</td>\n",
       "      <td>0.775564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.260359</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.771408</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.786243</td>\n",
       "      <td>0.780695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.126100</td>\n",
       "      <td>0.270004</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.776897</td>\n",
       "      <td>0.768879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.274341</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.780061</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.770139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.276553</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.774584</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.773414</td>\n",
       "      <td>0.767463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.68      0.68      0.68       237\n",
      "         radikalisme       0.76      0.80      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.729903536977492, F1 Micro: 0.7895125553914327, F1 Macro: 0.7824500439710769\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.90      0.91       362\n",
      "                sara       0.68      0.68      0.68       237\n",
      "         radikalisme       0.76      0.80      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.00017884326080093153\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 12.670927286148071 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.255779</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.781638</td>\n",
       "      <td>0.712670</td>\n",
       "      <td>0.745562</td>\n",
       "      <td>0.730115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.232453</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.778462</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.770754</td>\n",
       "      <td>0.756324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.224102</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.769633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.234501</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.757429</td>\n",
       "      <td>0.826546</td>\n",
       "      <td>0.790480</td>\n",
       "      <td>0.784538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.239941</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.771904</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.787588</td>\n",
       "      <td>0.780496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.788593</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.785309</td>\n",
       "      <td>0.774578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.262594</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.766548</td>\n",
       "      <td>0.812217</td>\n",
       "      <td>0.788722</td>\n",
       "      <td>0.782688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.268635</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.767459</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>0.781364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.272924</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.784547</td>\n",
       "      <td>0.779681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.277119</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.773932</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.783159</td>\n",
       "      <td>0.777974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.62      0.71      0.66       237\n",
      "         radikalisme       0.74      0.87      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.83      0.79      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.7241157556270097, F1 Micro: 0.7904796249549224, F1 Macro: 0.7845379125488983\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.91      0.91       362\n",
      "                sara       0.62      0.71      0.66       237\n",
      "         radikalisme       0.74      0.87      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.83      0.79      1326\n",
      "           macro avg       0.75      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.83      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 0.00010263406002195563\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.5855393409729 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262179</td>\n",
       "      <td>0.677170</td>\n",
       "      <td>0.752680</td>\n",
       "      <td>0.741327</td>\n",
       "      <td>0.746960</td>\n",
       "      <td>0.721665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>0.226590</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.783048</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.771057</td>\n",
       "      <td>0.766277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>0.228536</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.764792</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.776994</td>\n",
       "      <td>0.771082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.248513</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.751223</td>\n",
       "      <td>0.810709</td>\n",
       "      <td>0.779833</td>\n",
       "      <td>0.772675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.237660</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.786787</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.788563</td>\n",
       "      <td>0.780191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.248137</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.784791</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.781522</td>\n",
       "      <td>0.777485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.254591</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.806295</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.771487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.272199</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.776208</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.781730</td>\n",
       "      <td>0.776179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.279455</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.778609</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.781825</td>\n",
       "      <td>0.776117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.286825</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.772993</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.785608</td>\n",
       "      <td>0.780146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       362\n",
      "                sara       0.67      0.61      0.64       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7286173633440515, F1 Micro: 0.7885628291948833, F1 Macro: 0.7801914831002827\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.90      0.92       362\n",
      "                sara       0.67      0.61      0.64       237\n",
      "         radikalisme       0.76      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.79      0.79      0.79      1326\n",
      "           macro avg       0.78      0.78      0.78      1326\n",
      "        weighted avg       0.79      0.79      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 3.536934964358809e-05\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.171801567077637 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249396</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.693816</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.727459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.229005</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.761043</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.776505</td>\n",
       "      <td>0.767132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.223879</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.786846</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.767388</td>\n",
       "      <td>0.756712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>0.234902</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.794002</td>\n",
       "      <td>0.758673</td>\n",
       "      <td>0.775935</td>\n",
       "      <td>0.766362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.243946</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.776276</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>0.778029</td>\n",
       "      <td>0.772448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.265706</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.744235</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.772579</td>\n",
       "      <td>0.766155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>0.275895</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.781966</td>\n",
       "      <td>0.774216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.285387</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.768782</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.776205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.094200</td>\n",
       "      <td>0.289828</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.780433</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.784240</td>\n",
       "      <td>0.776605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.292350</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.771093</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.781703</td>\n",
       "      <td>0.774813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.66      0.63      0.65       237\n",
      "         radikalisme       0.75      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7254019292604501, F1 Micro: 0.7842401500938087, F1 Macro: 0.7766052206817713\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.66      0.63      0.65       237\n",
      "         radikalisme       0.75      0.84      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.78      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 7.215645382530059e-06\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.746212482452393 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245443</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>0.723982</td>\n",
       "      <td>0.750293</td>\n",
       "      <td>0.732426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.231220</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.805604</td>\n",
       "      <td>0.693816</td>\n",
       "      <td>0.745543</td>\n",
       "      <td>0.741349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.237396</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.733555</td>\n",
       "      <td>0.832579</td>\n",
       "      <td>0.779936</td>\n",
       "      <td>0.776129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.238642</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.761735</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.784041</td>\n",
       "      <td>0.777451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.237165</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.778416</td>\n",
       "      <td>0.769991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.258395</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.771304</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.784735</td>\n",
       "      <td>0.777530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.264410</td>\n",
       "      <td>0.731190</td>\n",
       "      <td>0.784580</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.783692</td>\n",
       "      <td>0.777835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.280947</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.787809</td>\n",
       "      <td>0.769985</td>\n",
       "      <td>0.778795</td>\n",
       "      <td>0.772902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.288363</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.781392</td>\n",
       "      <td>0.779035</td>\n",
       "      <td>0.780211</td>\n",
       "      <td>0.774004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.295871</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.770015</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.783704</td>\n",
       "      <td>0.778171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7260450160771704, F1 Micro: 0.784735087069285, F1 Macro: 0.7775303603379391\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.75      0.81      0.78       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 8.408731810050086e-06\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 7.352232933044434 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244210</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.787573</td>\n",
       "      <td>0.707391</td>\n",
       "      <td>0.745332</td>\n",
       "      <td>0.729785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.222479</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.803691</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.760921</td>\n",
       "      <td>0.747130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.228974</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.740242</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.782361</td>\n",
       "      <td>0.775881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.229184</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.779367</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.779955</td>\n",
       "      <td>0.772699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.253041</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.744870</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.781205</td>\n",
       "      <td>0.774960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.253662</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.780578</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.787290</td>\n",
       "      <td>0.780633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.270348</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.782902</td>\n",
       "      <td>0.771968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.277645</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.775570</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.785102</td>\n",
       "      <td>0.780214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.287532</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.760462</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.777286</td>\n",
       "      <td>0.770814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.293972</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.764663</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.780199</td>\n",
       "      <td>0.774909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7292604501607717, F1 Micro: 0.7872897196261682, F1 Macro: 0.7806328707680644\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.75      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 5.083678297523874e-06\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.937952041625977 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243474</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>0.759287</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.764970</td>\n",
       "      <td>0.754986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312400</td>\n",
       "      <td>0.226080</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.776053</td>\n",
       "      <td>0.771855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.235770</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.777520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.787451</td>\n",
       "      <td>0.757164</td>\n",
       "      <td>0.772011</td>\n",
       "      <td>0.767582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.251630</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.744139</td>\n",
       "      <td>0.837858</td>\n",
       "      <td>0.788223</td>\n",
       "      <td>0.783895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.253232</td>\n",
       "      <td>0.738264</td>\n",
       "      <td>0.804107</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.785494</td>\n",
       "      <td>0.774507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.267643</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.768727</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.782673</td>\n",
       "      <td>0.778728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.291770</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.761804</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.787614</td>\n",
       "      <td>0.783623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.290033</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.780290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.294652</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.773818</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.787856</td>\n",
       "      <td>0.782715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.47      0.48      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7221864951768489, F1 Micro: 0.7882227740333452, F1 Macro: 0.7838951366116051\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.93      0.92       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.69      0.82      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.47      0.48      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 7.5129848482902155e-06\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.501275539398193 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241169</td>\n",
       "      <td>0.690032</td>\n",
       "      <td>0.787361</td>\n",
       "      <td>0.695324</td>\n",
       "      <td>0.738486</td>\n",
       "      <td>0.722506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.226472</td>\n",
       "      <td>0.710611</td>\n",
       "      <td>0.750532</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.773840</td>\n",
       "      <td>0.768485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.230116</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.768231</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.784950</td>\n",
       "      <td>0.776813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.242649</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.749134</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.780787</td>\n",
       "      <td>0.778267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.250743</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.781216</td>\n",
       "      <td>0.776111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.262821</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.774834</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.784358</td>\n",
       "      <td>0.776219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.274547</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.776897</td>\n",
       "      <td>0.766481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.293748</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.758133</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.777277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.300775</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.755289</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>0.775719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.297912</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.772794</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.782576</td>\n",
       "      <td>0.774758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7234726688102894, F1 Micro: 0.7849502028771672, F1 Macro: 0.776813016002606\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.90      0.92      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.7789124103728682e-05\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.1178781986236572 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>0.693248</td>\n",
       "      <td>0.748364</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.761940</td>\n",
       "      <td>0.751971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.305500</td>\n",
       "      <td>0.227109</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.821109</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.751227</td>\n",
       "      <td>0.736457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.231777</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.756833</td>\n",
       "      <td>0.814480</td>\n",
       "      <td>0.784599</td>\n",
       "      <td>0.780086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.227701</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.790930</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.783403</td>\n",
       "      <td>0.772769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163500</td>\n",
       "      <td>0.253035</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.754888</td>\n",
       "      <td>0.815234</td>\n",
       "      <td>0.783901</td>\n",
       "      <td>0.774456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124300</td>\n",
       "      <td>0.266052</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.763456</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.787436</td>\n",
       "      <td>0.783318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.274796</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.777194</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.779240</td>\n",
       "      <td>0.771620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.276722</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.795597</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.779061</td>\n",
       "      <td>0.769911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.296019</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.773065</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.778277</td>\n",
       "      <td>0.772068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.299537</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.775708</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.780360</td>\n",
       "      <td>0.773027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.73      0.89      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7254019292604501, F1 Micro: 0.7874360847333819, F1 Macro: 0.7833184445925154\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.65      0.68      0.67       237\n",
      "         radikalisme       0.73      0.89      0.80       235\n",
      "pencemaran_nama_baik       0.72      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.6261067457890023e-06\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.6775310039520264 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242782</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.707266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.223671</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.765796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.223187</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.799028</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.770312</td>\n",
       "      <td>0.756137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.233570</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.770818</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.779724</td>\n",
       "      <td>0.769039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.241760</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.784839</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.778875</td>\n",
       "      <td>0.769504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.273671</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.747748</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.779343</td>\n",
       "      <td>0.774110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.282365</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.749648</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.775837</td>\n",
       "      <td>0.770347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.291199</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.763043</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.778271</td>\n",
       "      <td>0.772235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.301761</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.767976</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.774579</td>\n",
       "      <td>0.767968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.310122</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.757684</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>0.772144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.65      0.61      0.63       237\n",
      "         radikalisme       0.75      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7183279742765273, F1 Micro: 0.7797241893402908, F1 Macro: 0.7690388543149508\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.92      0.92       362\n",
      "                sara       0.65      0.61      0.63       237\n",
      "         radikalisme       0.75      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.78      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n",
      "Total sampling time: 375.17 seconds\n",
      "Total runtime: 11431.20928478241 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c805f58",
   "metadata": {},
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530db6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 02:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.458386</td>\n",
       "      <td>0.505466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.149337</td>\n",
       "      <td>0.114072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.384749</td>\n",
       "      <td>0.584566</td>\n",
       "      <td>0.914454</td>\n",
       "      <td>0.233786</td>\n",
       "      <td>0.372372</td>\n",
       "      <td>0.251831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.356113</td>\n",
       "      <td>0.571704</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.348416</td>\n",
       "      <td>0.475798</td>\n",
       "      <td>0.347973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330139</td>\n",
       "      <td>0.593569</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.416290</td>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.453938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.312512</td>\n",
       "      <td>0.608360</td>\n",
       "      <td>0.758850</td>\n",
       "      <td>0.517345</td>\n",
       "      <td>0.615247</td>\n",
       "      <td>0.548237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.303364</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.745247</td>\n",
       "      <td>0.591252</td>\n",
       "      <td>0.659378</td>\n",
       "      <td>0.634356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.297518</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.737660</td>\n",
       "      <td>0.608597</td>\n",
       "      <td>0.666942</td>\n",
       "      <td>0.633439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.296958</td>\n",
       "      <td>0.624437</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.567119</td>\n",
       "      <td>0.646604</td>\n",
       "      <td>0.609105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293293</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.743662</td>\n",
       "      <td>0.597285</td>\n",
       "      <td>0.662484</td>\n",
       "      <td>0.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293404</td>\n",
       "      <td>0.627653</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.629208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 388: Accuracy: 0.62508038585209, F1 Micro: 0.6669421487603305, F1 Macro: 0.6334393870554681\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.83      0.85      0.84       362\n",
      "                sara       0.72      0.29      0.41       237\n",
      "         radikalisme       0.72      0.61      0.66       235\n",
      "pencemaran_nama_baik       0.67      0.59      0.63       492\n",
      "\n",
      "           micro avg       0.74      0.61      0.67      1326\n",
      "           macro avg       0.73      0.58      0.63      1326\n",
      "        weighted avg       0.73      0.61      0.65      1326\n",
      "         samples avg       0.38      0.35      0.35      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.00233133723959327\n",
      "Samples above threshold: 583\n",
      "Acquired samples: 583\n",
      "Sampling duration: 42.747541427612305 seconds\n",
      "New train size: 971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='610' max='610' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [610/610 03:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.383095</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.413273</td>\n",
       "      <td>0.545002</td>\n",
       "      <td>0.496891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310498</td>\n",
       "      <td>0.643730</td>\n",
       "      <td>0.786735</td>\n",
       "      <td>0.581448</td>\n",
       "      <td>0.668690</td>\n",
       "      <td>0.655849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.290935</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.707232</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.735890</td>\n",
       "      <td>0.733469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.275142</td>\n",
       "      <td>0.675884</td>\n",
       "      <td>0.716851</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.748378</td>\n",
       "      <td>0.741287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274385</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.726579</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.756776</td>\n",
       "      <td>0.751094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265277</td>\n",
       "      <td>0.688746</td>\n",
       "      <td>0.760317</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.740913</td>\n",
       "      <td>0.735448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266958</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.739067</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.751668</td>\n",
       "      <td>0.743786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.757716</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.749047</td>\n",
       "      <td>0.741255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.266339</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.771817</td>\n",
       "      <td>0.726998</td>\n",
       "      <td>0.748738</td>\n",
       "      <td>0.742051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.267747</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.756839</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.753974</td>\n",
       "      <td>0.745865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.87      0.89       362\n",
      "                sara       0.60      0.67      0.63       237\n",
      "         radikalisme       0.68      0.86      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.79      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.73      0.79      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 971: Accuracy: 0.6829581993569132, F1 Micro: 0.7567762920130106, F1 Macro: 0.7510935971908632\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.87      0.89       362\n",
      "                sara       0.60      0.67      0.63       237\n",
      "         radikalisme       0.68      0.86      0.76       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.73      0.79      0.76      1326\n",
      "           macro avg       0.72      0.79      0.75      1326\n",
      "        weighted avg       0.73      0.79      0.76      1326\n",
      "         samples avg       0.43      0.44      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0033084240742027766\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 38.46542191505432 seconds\n",
      "New train size: 1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 04:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359282</td>\n",
       "      <td>0.601929</td>\n",
       "      <td>0.731550</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.658091</td>\n",
       "      <td>0.654213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.295099</td>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.731873</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.731321</td>\n",
       "      <td>0.723616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.766453</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.742613</td>\n",
       "      <td>0.731268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257084</td>\n",
       "      <td>0.677814</td>\n",
       "      <td>0.736351</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.754231</td>\n",
       "      <td>0.748690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.251849</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.760574</td>\n",
       "      <td>0.759427</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.756906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.255744</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.750916</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.761799</td>\n",
       "      <td>0.755452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.259139</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.750367</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.756166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.262958</td>\n",
       "      <td>0.695177</td>\n",
       "      <td>0.747093</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.760918</td>\n",
       "      <td>0.753465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.262749</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.759910</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.763049</td>\n",
       "      <td>0.758703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.264973</td>\n",
       "      <td>0.702251</td>\n",
       "      <td>0.755523</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.764531</td>\n",
       "      <td>0.757840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.71      0.79      0.75       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.77      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1496: Accuracy: 0.7022508038585209, F1 Micro: 0.7645305514157974, F1 Macro: 0.7578396563248103\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.91      0.89      0.90       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.71      0.79      0.75       235\n",
      "pencemaran_nama_baik       0.71      0.74      0.73       492\n",
      "\n",
      "           micro avg       0.76      0.77      0.76      1326\n",
      "           macro avg       0.75      0.77      0.76      1326\n",
      "        weighted avg       0.76      0.77      0.77      1326\n",
      "         samples avg       0.43      0.43      0.42      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0053020420018583545\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 34.8545401096344 seconds\n",
      "New train size: 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1240' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1240/1240 04:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340304</td>\n",
       "      <td>0.610289</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.689332</td>\n",
       "      <td>0.661978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.277711</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.784843</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.728375</td>\n",
       "      <td>0.721322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257278</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.738077</td>\n",
       "      <td>0.727403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249401</td>\n",
       "      <td>0.695820</td>\n",
       "      <td>0.756152</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.760405</td>\n",
       "      <td>0.754091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.258568</td>\n",
       "      <td>0.692605</td>\n",
       "      <td>0.739929</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.763955</td>\n",
       "      <td>0.757706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.264382</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.741234</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.768169</td>\n",
       "      <td>0.763300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.258909</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.765337</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.758935</td>\n",
       "      <td>0.753367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.261321</td>\n",
       "      <td>0.699678</td>\n",
       "      <td>0.767732</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.755079</td>\n",
       "      <td>0.745798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.265661</td>\n",
       "      <td>0.699035</td>\n",
       "      <td>0.763037</td>\n",
       "      <td>0.750377</td>\n",
       "      <td>0.756654</td>\n",
       "      <td>0.748832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>0.268474</td>\n",
       "      <td>0.700965</td>\n",
       "      <td>0.757485</td>\n",
       "      <td>0.763198</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.752211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.69      0.87      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1969: Accuracy: 0.6990353697749196, F1 Micro: 0.7681686046511628, F1 Macro: 0.7633000399215057\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.89      0.91       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.69      0.87      0.77       235\n",
      "pencemaran_nama_baik       0.70      0.76      0.73       492\n",
      "\n",
      "           micro avg       0.74      0.80      0.77      1326\n",
      "           macro avg       0.74      0.80      0.76      1326\n",
      "        weighted avg       0.75      0.80      0.77      1326\n",
      "         samples avg       0.44      0.45      0.43      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0031351923476904647\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 425\n",
      "Sampling duration: 31.29958939552307 seconds\n",
      "New train size: 2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 05:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.324751</td>\n",
       "      <td>0.634727</td>\n",
       "      <td>0.741117</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>0.698565</td>\n",
       "      <td>0.678790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.265267</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.792287</td>\n",
       "      <td>0.681750</td>\n",
       "      <td>0.732874</td>\n",
       "      <td>0.702236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243119</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.777864</td>\n",
       "      <td>0.757919</td>\n",
       "      <td>0.767762</td>\n",
       "      <td>0.760455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.239671</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.810206</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.740892</td>\n",
       "      <td>0.722964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.247303</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.764020</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.777325</td>\n",
       "      <td>0.771886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.246186</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.778539</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.767920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.256583</td>\n",
       "      <td>0.711897</td>\n",
       "      <td>0.780660</td>\n",
       "      <td>0.748869</td>\n",
       "      <td>0.764434</td>\n",
       "      <td>0.750541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.256642</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.771558</td>\n",
       "      <td>0.763902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.263944</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.767988</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.778274</td>\n",
       "      <td>0.773305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.265656</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.768833</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.776866</td>\n",
       "      <td>0.770885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2394: Accuracy: 0.7202572347266881, F1 Micro: 0.7782738095238096, F1 Macro: 0.7733048284255238\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.67      0.65      0.66       237\n",
      "         radikalisme       0.74      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.75      0.73       492\n",
      "\n",
      "           micro avg       0.77      0.79      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.003186435322277249\n",
      "Samples above threshold: 383\n",
      "Acquired samples: 383\n",
      "Sampling duration: 28.26558804512024 seconds\n",
      "New train size: 2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1740' max='1740' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1740/1740 06:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.311793</td>\n",
       "      <td>0.639228</td>\n",
       "      <td>0.738424</td>\n",
       "      <td>0.685520</td>\n",
       "      <td>0.710989</td>\n",
       "      <td>0.711271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254038</td>\n",
       "      <td>0.696463</td>\n",
       "      <td>0.792631</td>\n",
       "      <td>0.697587</td>\n",
       "      <td>0.742078</td>\n",
       "      <td>0.725909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.386500</td>\n",
       "      <td>0.242375</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.778839</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.758033</td>\n",
       "      <td>0.744563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.386500</td>\n",
       "      <td>0.237082</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.803156</td>\n",
       "      <td>0.729261</td>\n",
       "      <td>0.764427</td>\n",
       "      <td>0.756730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.386500</td>\n",
       "      <td>0.236536</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.795638</td>\n",
       "      <td>0.742836</td>\n",
       "      <td>0.768331</td>\n",
       "      <td>0.761523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.248807</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.771408</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.786243</td>\n",
       "      <td>0.781435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.255927</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.778195</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.779367</td>\n",
       "      <td>0.772056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.257109</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.784195</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.781226</td>\n",
       "      <td>0.772453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.264671</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.777694</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.777987</td>\n",
       "      <td>0.770570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.267085</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.777944</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.779992</td>\n",
       "      <td>0.772107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.75      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2777: Accuracy: 0.7254019292604501, F1 Micro: 0.786242603550296, F1 Macro: 0.7814348086194319\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.92       362\n",
      "                sara       0.65      0.68      0.66       237\n",
      "         radikalisme       0.75      0.86      0.80       235\n",
      "pencemaran_nama_baik       0.73      0.77      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.001955565996468067\n",
      "Samples above threshold: 345\n",
      "Acquired samples: 345\n",
      "Sampling duration: 25.492600679397583 seconds\n",
      "New train size: 3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1960' max='1960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1960/1960 06:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.289915</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.783229</td>\n",
       "      <td>0.662142</td>\n",
       "      <td>0.717613</td>\n",
       "      <td>0.699333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.705466</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.767722</td>\n",
       "      <td>0.758455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.233459</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.787597</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.776758</td>\n",
       "      <td>0.770185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.232575</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.788506</td>\n",
       "      <td>0.776018</td>\n",
       "      <td>0.782212</td>\n",
       "      <td>0.776957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.385400</td>\n",
       "      <td>0.233180</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.788984</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.777820</td>\n",
       "      <td>0.771153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.241065</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.796863</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.781238</td>\n",
       "      <td>0.775584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>0.251043</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.791469</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.773148</td>\n",
       "      <td>0.765737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.264335</td>\n",
       "      <td>0.729260</td>\n",
       "      <td>0.779434</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>0.778611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.267587</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.782478</td>\n",
       "      <td>0.776053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.268398</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.776620</td>\n",
       "      <td>0.786576</td>\n",
       "      <td>0.781566</td>\n",
       "      <td>0.776095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.68      0.65      0.66       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3122: Accuracy: 0.7292604501607717, F1 Micro: 0.7841079460269864, F1 Macro: 0.7786114073501155\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.88      0.91       362\n",
      "                sara       0.68      0.65      0.66       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.75      0.74       492\n",
      "\n",
      "           micro avg       0.78      0.79      0.78      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.79      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.001265982340555638\n",
      "Samples above threshold: 310\n",
      "Acquired samples: 310\n",
      "Sampling duration: 22.94605851173401 seconds\n",
      "New train size: 3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2150' max='2150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2150/2150 07:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.301113</td>\n",
       "      <td>0.578135</td>\n",
       "      <td>0.682671</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.684468</td>\n",
       "      <td>0.679247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246052</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.748115</td>\n",
       "      <td>0.763958</td>\n",
       "      <td>0.755301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.238832</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.758941</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.779001</td>\n",
       "      <td>0.772373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.231744</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.798374</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.768388</td>\n",
       "      <td>0.759072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.779378</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.777316</td>\n",
       "      <td>0.773236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.245118</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.781565</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.771112</td>\n",
       "      <td>0.762383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.262055</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.775771</td>\n",
       "      <td>0.777526</td>\n",
       "      <td>0.776648</td>\n",
       "      <td>0.768973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.263879</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.787666</td>\n",
       "      <td>0.760935</td>\n",
       "      <td>0.774070</td>\n",
       "      <td>0.768027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.269663</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.784344</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.777482</td>\n",
       "      <td>0.772178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.274236</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.772491</td>\n",
       "      <td>0.783560</td>\n",
       "      <td>0.777986</td>\n",
       "      <td>0.773254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3432: Accuracy: 0.715112540192926, F1 Micro: 0.7790014684287813, F1 Macro: 0.7723726091668268\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.88      0.91       362\n",
      "                sara       0.66      0.62      0.64       237\n",
      "         radikalisme       0.72      0.88      0.79       235\n",
      "pencemaran_nama_baik       0.70      0.79      0.74       492\n",
      "\n",
      "           micro avg       0.76      0.80      0.78      1326\n",
      "           macro avg       0.76      0.79      0.77      1326\n",
      "        weighted avg       0.77      0.80      0.78      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0009066810889635235\n",
      "Samples above threshold: 279\n",
      "Acquired samples: 279\n",
      "Sampling duration: 20.726665496826172 seconds\n",
      "New train size: 3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2320' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2320/2320 07:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274727</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.800567</td>\n",
       "      <td>0.638763</td>\n",
       "      <td>0.710570</td>\n",
       "      <td>0.687081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243330</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.791493</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.751683</td>\n",
       "      <td>0.734299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.229927</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.777022</td>\n",
       "      <td>0.775264</td>\n",
       "      <td>0.776142</td>\n",
       "      <td>0.767037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.241090</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.758840</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.783212</td>\n",
       "      <td>0.776439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.240775</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.768126</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.787054</td>\n",
       "      <td>0.781236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.247698</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.766715</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.780903</td>\n",
       "      <td>0.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.256057</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.780061</td>\n",
       "      <td>0.773002</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.770005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.268671</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.757511</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.777533</td>\n",
       "      <td>0.772608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.274089</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.759393</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>0.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.274494</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.759622</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.773955</td>\n",
       "      <td>0.769430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.73      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3711: Accuracy: 0.7209003215434083, F1 Micro: 0.7870540639941155, F1 Macro: 0.7812361896427678\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.90      0.91       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.73      0.85      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.45      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 3886\n",
      "Threshold: 0.0005491747288033367\n",
      "Samples above threshold: 251\n",
      "Acquired samples: 175\n",
      "Sampling duration: 18.73076891899109 seconds\n",
      "New train size: 3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2430' max='2430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2430/2430 08:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278571</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.730296</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>0.745663</td>\n",
       "      <td>0.737058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.765799</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.771247</td>\n",
       "      <td>0.763380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.225901</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.784195</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.781226</td>\n",
       "      <td>0.773839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.374900</td>\n",
       "      <td>0.233147</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.775436</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.789785</td>\n",
       "      <td>0.782823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.230240</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.802400</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.778727</td>\n",
       "      <td>0.769098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.243887</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.762108</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.783883</td>\n",
       "      <td>0.779677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.249256</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.790199</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.784195</td>\n",
       "      <td>0.777493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.261959</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.778781</td>\n",
       "      <td>0.780543</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.771052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.264579</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.777612</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.781695</td>\n",
       "      <td>0.777077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>0.270334</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.771956</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.780306</td>\n",
       "      <td>0.775212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.72      0.89      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3886: Accuracy: 0.7279742765273312, F1 Micro: 0.7897853441894892, F1 Macro: 0.7828226676380157\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.66      0.66      0.66       237\n",
      "         radikalisme       0.72      0.89      0.80       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0004039371822727845\n",
      "Samples above threshold: 234\n",
      "Acquired samples: 234\n",
      "Sampling duration: 17.397790908813477 seconds\n",
      "New train size: 4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 08:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>0.686174</td>\n",
       "      <td>0.782161</td>\n",
       "      <td>0.687783</td>\n",
       "      <td>0.731942</td>\n",
       "      <td>0.726353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>0.706752</td>\n",
       "      <td>0.767976</td>\n",
       "      <td>0.781297</td>\n",
       "      <td>0.774579</td>\n",
       "      <td>0.764838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.230470</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.816609</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>0.760677</td>\n",
       "      <td>0.750575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.224641</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.810273</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.772207</td>\n",
       "      <td>0.758148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.235293</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.812759</td>\n",
       "      <td>0.739819</td>\n",
       "      <td>0.774576</td>\n",
       "      <td>0.765856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.249980</td>\n",
       "      <td>0.717042</td>\n",
       "      <td>0.781417</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.777567</td>\n",
       "      <td>0.770440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.262246</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.780995</td>\n",
       "      <td>0.776962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.269366</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.758133</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.778526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.269171</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.776524</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.777401</td>\n",
       "      <td>0.771390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.275128</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.769514</td>\n",
       "      <td>0.788084</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.773210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.63      0.70      0.67       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4120: Accuracy: 0.7196141479099678, F1 Micro: 0.7824817518248176, F1 Macro: 0.7785261774432123\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.63      0.70      0.67       237\n",
      "         radikalisme       0.74      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.78      0.75       492\n",
      "\n",
      "           micro avg       0.76      0.81      0.78      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.76      0.81      0.78      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.0001618126538232899\n",
      "Samples above threshold: 210\n",
      "Acquired samples: 210\n",
      "Sampling duration: 15.669125080108643 seconds\n",
      "New train size: 4330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2710' max='2710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2710/2710 08:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262659</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.768322</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.751445</td>\n",
       "      <td>0.737702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362600</td>\n",
       "      <td>0.233594</td>\n",
       "      <td>0.715756</td>\n",
       "      <td>0.776336</td>\n",
       "      <td>0.766968</td>\n",
       "      <td>0.771624</td>\n",
       "      <td>0.764227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362600</td>\n",
       "      <td>0.229549</td>\n",
       "      <td>0.713826</td>\n",
       "      <td>0.751220</td>\n",
       "      <td>0.812971</td>\n",
       "      <td>0.780876</td>\n",
       "      <td>0.775944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.226611</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.781643</td>\n",
       "      <td>0.775744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.234690</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.783804</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.778748</td>\n",
       "      <td>0.771904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.256297</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.756184</td>\n",
       "      <td>0.806938</td>\n",
       "      <td>0.780737</td>\n",
       "      <td>0.777475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.254962</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.768837</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.780542</td>\n",
       "      <td>0.775627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.268937</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780179</td>\n",
       "      <td>0.775837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.268604</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.778032</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.773606</td>\n",
       "      <td>0.766534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.274866</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.763292</td>\n",
       "      <td>0.790347</td>\n",
       "      <td>0.776584</td>\n",
       "      <td>0.771294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.61      0.71      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4330: Accuracy: 0.7228295819935692, F1 Micro: 0.7816432272390822, F1 Macro: 0.7757437401862228\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.61      0.71      0.66       237\n",
      "         radikalisme       0.74      0.83      0.78       235\n",
      "pencemaran_nama_baik       0.75      0.75      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.78      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.78      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 0.00018710049189394332\n",
      "Samples above threshold: 189\n",
      "Acquired samples: 200\n",
      "Sampling duration: 14.133525609970093 seconds\n",
      "New train size: 4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2840' max='2840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2840/2840 09:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257583</td>\n",
       "      <td>0.690675</td>\n",
       "      <td>0.793488</td>\n",
       "      <td>0.698341</td>\n",
       "      <td>0.742880</td>\n",
       "      <td>0.720829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.232623</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.798822</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.754972</td>\n",
       "      <td>0.736369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.219439</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.797600</td>\n",
       "      <td>0.751885</td>\n",
       "      <td>0.774068</td>\n",
       "      <td>0.766604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>0.236373</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.821267</td>\n",
       "      <td>0.780925</td>\n",
       "      <td>0.774536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>0.237918</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.769398</td>\n",
       "      <td>0.800151</td>\n",
       "      <td>0.784473</td>\n",
       "      <td>0.776768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.245525</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.769120</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.786136</td>\n",
       "      <td>0.779981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.259434</td>\n",
       "      <td>0.713183</td>\n",
       "      <td>0.761183</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.778024</td>\n",
       "      <td>0.769340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.274713</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.790731</td>\n",
       "      <td>0.785778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.271791</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.779558</td>\n",
       "      <td>0.770739</td>\n",
       "      <td>0.775123</td>\n",
       "      <td>0.766195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.273801</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.774146</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.779940</td>\n",
       "      <td>0.772509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4530: Accuracy: 0.7241157556270097, F1 Micro: 0.7907313540912383, F1 Macro: 0.7857775751344447\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.64      0.71      0.67       237\n",
      "         radikalisme       0.74      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.79      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 4663\n",
      "Threshold: 6.622194341616703e-05\n",
      "Samples above threshold: 169\n",
      "Acquired samples: 133\n",
      "Sampling duration: 12.81667947769165 seconds\n",
      "New train size: 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 09:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266439</td>\n",
       "      <td>0.661093</td>\n",
       "      <td>0.815846</td>\n",
       "      <td>0.574661</td>\n",
       "      <td>0.674336</td>\n",
       "      <td>0.652469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.230297</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.771536</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.774145</td>\n",
       "      <td>0.768041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.220059</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>0.794992</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.780338</td>\n",
       "      <td>0.773149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.226724</td>\n",
       "      <td>0.729904</td>\n",
       "      <td>0.779173</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.787313</td>\n",
       "      <td>0.781448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.751374</td>\n",
       "      <td>0.825038</td>\n",
       "      <td>0.786485</td>\n",
       "      <td>0.782682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.247740</td>\n",
       "      <td>0.734405</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.786466</td>\n",
       "      <td>0.779611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.258446</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.774627</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.778695</td>\n",
       "      <td>0.771091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.268124</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770987</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.780179</td>\n",
       "      <td>0.774047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>0.277025</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.758993</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.776878</td>\n",
       "      <td>0.772897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>0.280434</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.763139</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.775343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.72      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4663: Accuracy: 0.729903536977492, F1 Micro: 0.7873134328358208, F1 Macro: 0.7814482542639912\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.89      0.91       362\n",
      "                sara       0.66      0.69      0.67       237\n",
      "         radikalisme       0.72      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.76      0.74      0.75       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.45      0.45      0.44      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 8.803500386420647e-05\n",
      "Samples above threshold: 156\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.664193391799927 seconds\n",
      "New train size: 4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3040' max='3040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3040/3040 09:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249357</td>\n",
       "      <td>0.693891</td>\n",
       "      <td>0.757154</td>\n",
       "      <td>0.738311</td>\n",
       "      <td>0.747614</td>\n",
       "      <td>0.738454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.229188</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.752155</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.770419</td>\n",
       "      <td>0.766215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.224572</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.770575</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.783994</td>\n",
       "      <td>0.777418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.232272</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.759221</td>\n",
       "      <td>0.822775</td>\n",
       "      <td>0.789721</td>\n",
       "      <td>0.783761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.238273</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.780228</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>0.772703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>0.250826</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.769400</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.780832</td>\n",
       "      <td>0.773369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>0.265461</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.764451</td>\n",
       "      <td>0.797888</td>\n",
       "      <td>0.780812</td>\n",
       "      <td>0.775848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>0.276992</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.803167</td>\n",
       "      <td>0.782800</td>\n",
       "      <td>0.778740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.278566</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.772961</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.783029</td>\n",
       "      <td>0.778163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.766376</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.775025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.70      0.68       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.81      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4863: Accuracy: 0.7286173633440515, F1 Micro: 0.7897213174086136, F1 Macro: 0.7837610708965264\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.90      0.91       362\n",
      "                sara       0.66      0.70      0.68       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.72      0.81      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.82      0.78      1326\n",
      "        weighted avg       0.76      0.82      0.79      1326\n",
      "         samples avg       0.46      0.47      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 6.732545589329676e-05\n",
      "Samples above threshold: 136\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.148961305618286 seconds\n",
      "New train size: 5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3170' max='3170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3170/3170 10:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.246567</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.772977</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.757214</td>\n",
       "      <td>0.751376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.234707</td>\n",
       "      <td>0.709968</td>\n",
       "      <td>0.741781</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.777459</td>\n",
       "      <td>0.773447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.223921</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.788820</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.777353</td>\n",
       "      <td>0.771160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.228692</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.770636</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.782931</td>\n",
       "      <td>0.776244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.248203</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.754178</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.784214</td>\n",
       "      <td>0.776139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172600</td>\n",
       "      <td>0.251033</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.775298</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.780524</td>\n",
       "      <td>0.772676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.263259</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.767626</td>\n",
       "      <td>0.804676</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.776582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.269304</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.791183</td>\n",
       "      <td>0.771493</td>\n",
       "      <td>0.781214</td>\n",
       "      <td>0.772879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.280159</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.775056</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.774954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.285859</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.782022</td>\n",
       "      <td>0.774282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.73      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5063: Accuracy: 0.7221864951768489, F1 Micro: 0.7857142857142857, F1 Macro: 0.776581592525865\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.91      0.92       362\n",
      "                sara       0.64      0.66      0.65       237\n",
      "         radikalisme       0.73      0.81      0.77       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.79      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 1.4846789599687378e-05\n",
      "Samples above threshold: 116\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.714919805526733 seconds\n",
      "New train size: 5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3290/3290 10:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249363</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.827552</td>\n",
       "      <td>0.629713</td>\n",
       "      <td>0.715203</td>\n",
       "      <td>0.697657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.227029</td>\n",
       "      <td>0.707395</td>\n",
       "      <td>0.806751</td>\n",
       "      <td>0.720965</td>\n",
       "      <td>0.761450</td>\n",
       "      <td>0.741793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.222255</td>\n",
       "      <td>0.732476</td>\n",
       "      <td>0.783096</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.786331</td>\n",
       "      <td>0.779260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.236552</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.743624</td>\n",
       "      <td>0.835596</td>\n",
       "      <td>0.786932</td>\n",
       "      <td>0.783551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.238627</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.814212</td>\n",
       "      <td>0.717195</td>\n",
       "      <td>0.762630</td>\n",
       "      <td>0.753358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.253218</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.763952</td>\n",
       "      <td>0.778931</td>\n",
       "      <td>0.770374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.275699</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.777358</td>\n",
       "      <td>0.776772</td>\n",
       "      <td>0.777065</td>\n",
       "      <td>0.770627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.282969</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.766836</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.782416</td>\n",
       "      <td>0.774805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.291111</td>\n",
       "      <td>0.723473</td>\n",
       "      <td>0.765896</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.782288</td>\n",
       "      <td>0.774906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.296249</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.782929</td>\n",
       "      <td>0.776597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.61      0.75      0.67       237\n",
      "         radikalisme       0.72      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5263: Accuracy: 0.7189710610932476, F1 Micro: 0.786931818181818, F1 Macro: 0.7835509998336216\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.91      0.92       362\n",
      "                sara       0.61      0.75      0.67       237\n",
      "         radikalisme       0.72      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.75       492\n",
      "\n",
      "           micro avg       0.74      0.84      0.79      1326\n",
      "           macro avg       0.74      0.83      0.78      1326\n",
      "        weighted avg       0.75      0.84      0.79      1326\n",
      "         samples avg       0.46      0.47      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 5441\n",
      "Threshold: 2.601460728328675e-05\n",
      "Samples above threshold: 96\n",
      "Acquired samples: 178\n",
      "Sampling duration: 7.344995498657227 seconds\n",
      "New train size: 5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3410' max='3410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3410/3410 10:52, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.249431</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.753811</td>\n",
       "      <td>0.745852</td>\n",
       "      <td>0.749810</td>\n",
       "      <td>0.746074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.220749</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.807850</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.775206</td>\n",
       "      <td>0.762766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.225838</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.753394</td>\n",
       "      <td>0.775320</td>\n",
       "      <td>0.772613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.230549</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.748971</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.779597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.236075</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.810855</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.775767</td>\n",
       "      <td>0.766288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.769899</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.785820</td>\n",
       "      <td>0.780117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.277621</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.759104</td>\n",
       "      <td>0.817496</td>\n",
       "      <td>0.787219</td>\n",
       "      <td>0.782486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>0.282978</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>0.791855</td>\n",
       "      <td>0.783290</td>\n",
       "      <td>0.777982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.289307</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.774481</td>\n",
       "      <td>0.787330</td>\n",
       "      <td>0.780853</td>\n",
       "      <td>0.775321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.293502</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.774170</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.782544</td>\n",
       "      <td>0.776011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.46      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5441: Accuracy: 0.7176848874598071, F1 Micro: 0.7872185911401597, F1 Macro: 0.7824859610130522\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.95      0.89      0.92       362\n",
      "                sara       0.64      0.70      0.67       237\n",
      "         radikalisme       0.73      0.86      0.79       235\n",
      "pencemaran_nama_baik       0.71      0.80      0.76       492\n",
      "\n",
      "           micro avg       0.76      0.82      0.79      1326\n",
      "           macro avg       0.76      0.81      0.78      1326\n",
      "        weighted avg       0.77      0.82      0.79      1326\n",
      "         samples avg       0.46      0.46      0.46      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 6.307755575107876e-06\n",
      "Samples above threshold: 78\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.95184063911438 seconds\n",
      "New train size: 5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3530' max='3530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3530/3530 11:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241245</td>\n",
       "      <td>0.703537</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.720717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.220550</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.783804</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.778748</td>\n",
       "      <td>0.771076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.220763</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.783410</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.769501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.216200</td>\n",
       "      <td>0.239593</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.766906</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.784978</td>\n",
       "      <td>0.777172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.237616</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.778193</td>\n",
       "      <td>0.785822</td>\n",
       "      <td>0.781989</td>\n",
       "      <td>0.772906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.249353</td>\n",
       "      <td>0.727331</td>\n",
       "      <td>0.782119</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.783591</td>\n",
       "      <td>0.776266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.268138</td>\n",
       "      <td>0.728617</td>\n",
       "      <td>0.774689</td>\n",
       "      <td>0.798643</td>\n",
       "      <td>0.786483</td>\n",
       "      <td>0.778992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.285896</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.770456</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.786110</td>\n",
       "      <td>0.778361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.303603</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.754704</td>\n",
       "      <td>0.816742</td>\n",
       "      <td>0.784498</td>\n",
       "      <td>0.778917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.299128</td>\n",
       "      <td>0.717685</td>\n",
       "      <td>0.767374</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.779057</td>\n",
       "      <td>0.770955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.76      0.79      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5641: Accuracy: 0.7286173633440515, F1 Micro: 0.7864834756776828, F1 Macro: 0.778991688274083\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.94      0.90      0.92       362\n",
      "                sara       0.65      0.67      0.66       237\n",
      "         radikalisme       0.76      0.79      0.78       235\n",
      "pencemaran_nama_baik       0.73      0.79      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.77      0.79      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 2.9212543267931324e-06\n",
      "Samples above threshold: 58\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.512352228164673 seconds\n",
      "New train size: 5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 11:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238072</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>0.755041</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.758724</td>\n",
       "      <td>0.750035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308100</td>\n",
       "      <td>0.219507</td>\n",
       "      <td>0.712540</td>\n",
       "      <td>0.809037</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.759504</td>\n",
       "      <td>0.747353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.226021</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.812075</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.763389</td>\n",
       "      <td>0.750894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.234815</td>\n",
       "      <td>0.727974</td>\n",
       "      <td>0.769727</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.788971</td>\n",
       "      <td>0.779278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.245228</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.792320</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.777095</td>\n",
       "      <td>0.760156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.257304</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.776792</td>\n",
       "      <td>0.792609</td>\n",
       "      <td>0.784621</td>\n",
       "      <td>0.777754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.277338</td>\n",
       "      <td>0.722186</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.781737</td>\n",
       "      <td>0.772858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.289513</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.777446</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.781238</td>\n",
       "      <td>0.774353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.296149</td>\n",
       "      <td>0.719614</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>0.788839</td>\n",
       "      <td>0.778853</td>\n",
       "      <td>0.772292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.304194</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.764748</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.782769</td>\n",
       "      <td>0.776916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.93      0.93       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5841: Accuracy: 0.7279742765273312, F1 Micro: 0.7889705882352941, F1 Macro: 0.7792784157276708\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.93      0.93      0.93       362\n",
      "                sara       0.67      0.62      0.64       237\n",
      "         radikalisme       0.73      0.87      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.78      0.76       492\n",
      "\n",
      "           micro avg       0.77      0.81      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.81      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 9.904439866659239e-06\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0420515537261963 seconds\n",
      "New train size: 6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3780' max='3780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3780/3780 11:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236963</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>0.771518</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.757296</td>\n",
       "      <td>0.747273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.224814</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.799397</td>\n",
       "      <td>0.784894</td>\n",
       "      <td>0.778217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.229427</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.763869</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.786237</td>\n",
       "      <td>0.778904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.234171</td>\n",
       "      <td>0.722830</td>\n",
       "      <td>0.767908</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.787656</td>\n",
       "      <td>0.782442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.249888</td>\n",
       "      <td>0.724759</td>\n",
       "      <td>0.758380</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.787527</td>\n",
       "      <td>0.781912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.259309</td>\n",
       "      <td>0.730547</td>\n",
       "      <td>0.781204</td>\n",
       "      <td>0.802413</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.784361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.278558</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.771324</td>\n",
       "      <td>0.791101</td>\n",
       "      <td>0.781087</td>\n",
       "      <td>0.774353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.295880</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>0.765942</td>\n",
       "      <td>0.797134</td>\n",
       "      <td>0.781227</td>\n",
       "      <td>0.774225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.298278</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.777361</td>\n",
       "      <td>0.772866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.304550</td>\n",
       "      <td>0.718971</td>\n",
       "      <td>0.767831</td>\n",
       "      <td>0.795626</td>\n",
       "      <td>0.781481</td>\n",
       "      <td>0.775362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.69      0.66      0.67       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6041: Accuracy: 0.7305466237942122, F1 Micro: 0.7916666666666666, F1 Macro: 0.7843609741594786\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.92      0.92       362\n",
      "                sara       0.69      0.66      0.67       237\n",
      "         radikalisme       0.75      0.84      0.79       235\n",
      "pencemaran_nama_baik       0.74      0.77      0.76       492\n",
      "\n",
      "           micro avg       0.78      0.80      0.79      1326\n",
      "           macro avg       0.77      0.80      0.78      1326\n",
      "        weighted avg       0.78      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest checkpoint: 6218\n",
      "Threshold: 1.7780582311388575e-06\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 177\n",
      "Sampling duration: 1.6832330226898193 seconds\n",
      "New train size: 6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3890/3890 12:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Micro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243943</td>\n",
       "      <td>0.687460</td>\n",
       "      <td>0.817308</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.718512</td>\n",
       "      <td>0.692413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>0.223037</td>\n",
       "      <td>0.708039</td>\n",
       "      <td>0.766467</td>\n",
       "      <td>0.772247</td>\n",
       "      <td>0.769346</td>\n",
       "      <td>0.754958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.226229</td>\n",
       "      <td>0.711254</td>\n",
       "      <td>0.747754</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.780382</td>\n",
       "      <td>0.774834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.229225</td>\n",
       "      <td>0.726045</td>\n",
       "      <td>0.800475</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.780997</td>\n",
       "      <td>0.765584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.245243</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.796063</td>\n",
       "      <td>0.762443</td>\n",
       "      <td>0.778891</td>\n",
       "      <td>0.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.270055</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.766205</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.779548</td>\n",
       "      <td>0.771074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.269738</td>\n",
       "      <td>0.726688</td>\n",
       "      <td>0.787994</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.785011</td>\n",
       "      <td>0.777412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.295335</td>\n",
       "      <td>0.720257</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.801659</td>\n",
       "      <td>0.785661</td>\n",
       "      <td>0.778028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.301274</td>\n",
       "      <td>0.716399</td>\n",
       "      <td>0.770419</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.779888</td>\n",
       "      <td>0.772292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.305702</td>\n",
       "      <td>0.718328</td>\n",
       "      <td>0.770682</td>\n",
       "      <td>0.800905</td>\n",
       "      <td>0.785503</td>\n",
       "      <td>0.780398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [98/98 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.93      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\" of type <class 'str'> for key \"eval/report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6218: Accuracy: 0.7202572347266881, F1 Micro: 0.7856614929785662, F1 Macro: 0.7780284983850922\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          pornografi       0.92      0.93      0.92       362\n",
      "                sara       0.65      0.65      0.65       237\n",
      "         radikalisme       0.75      0.83      0.79       235\n",
      "pencemaran_nama_baik       0.73      0.76      0.75       492\n",
      "\n",
      "           micro avg       0.77      0.80      0.79      1326\n",
      "           macro avg       0.76      0.80      0.78      1326\n",
      "        weighted avg       0.77      0.80      0.79      1326\n",
      "         samples avg       0.46      0.46      0.45      1326\n",
      "\n",
      "Total sampling time: 376.61 seconds\n",
      "Total runtime: 11469.731705665588 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6053344,
     "sourceId": 9862714,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34784.451754,
   "end_time": "2024-12-23T00:12:54.906801",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-22T14:33:10.455047",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0453feeb99da44eb8f6f6abf4b339d99": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9014633107334f18b4794f17b76dd362",
       "placeholder": "​",
       "style": "IPY_MODEL_cfb26521de574ae48ddaa64a94a73f9e",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.17MB/s]"
      }
     },
     "05997f985b88486e8e7d2515ae99c85a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "07227da25f6746cfa1766795efde4137": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0967b04334884315823377fdcfad9d6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2f8714a9622042e49eeb71f00f2bcdfd",
       "placeholder": "​",
       "style": "IPY_MODEL_a7e906ba61024d98a600ff0512ff67fc",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "0eeec41e29e649eba93cf63cdb32b362": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e6d17d44fa084f3fa06dd5c009872500",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d00f606833084a608d759b3660af1e95",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "141828585de44039b0cd6615e7315eae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "17bccbff5c004f9f8be308221aa9c36e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a4d0a42da5043e0af6f65db2f406726": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_141828585de44039b0cd6615e7315eae",
       "placeholder": "​",
       "style": "IPY_MODEL_4effb2f35a54451488048fb630e3375a",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "21552ff97cdc471fb48a0057e8afc1a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2532c3792d864fd19a27dc19d2f90844": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "25d77fb96a914ba3b5b56393a604db39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f8714a9622042e49eeb71f00f2bcdfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "375a84cd65dd4df5ad56fd3a801b1ab8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3af1a99963c24f33a926d06419c10f58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5153aa5bbfad413299bbe673427f50be",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2532c3792d864fd19a27dc19d2f90844",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "40ddaeb2634b491dac88ac955f6593a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0967b04334884315823377fdcfad9d6d",
        "IPY_MODEL_6c565868ce054c048d924ae90e37a51f",
        "IPY_MODEL_85db632148cb4b2180c65399e67d4f7b"
       ],
       "layout": "IPY_MODEL_9c7a0f57e2304e1ea741b9b9256f7263",
       "tabbable": null,
       "tooltip": null
      }
     },
     "413ec48f69cc4f218537ef9c0ec23539": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fb0d4167f1e14811923625d16b765a0c",
        "IPY_MODEL_7c1c937a4c41428ead44ba2d4fc3ef15",
        "IPY_MODEL_ea6a4b1f53964805a6db6aa205ae490c"
       ],
       "layout": "IPY_MODEL_cababe246c0e44678c0307a299dd63fa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "44467ba09f2a43e5a0d1a7a7a1621d17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44e6a4bf00b84675a1458db7a7ce8239": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "459f2f36014f407e91d2b1f529fb06e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fc144b9cc25b4372b7ad3b33d10894a0",
        "IPY_MODEL_3af1a99963c24f33a926d06419c10f58",
        "IPY_MODEL_0453feeb99da44eb8f6f6abf4b339d99"
       ],
       "layout": "IPY_MODEL_44e6a4bf00b84675a1458db7a7ce8239",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4b3dda780faa4185a74e23a6a3bc8a87": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4c190ea93b7f4dc79369681d08dddf44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c9c1c1615974a3c86b5a882123f4748": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4effb2f35a54451488048fb630e3375a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5153aa5bbfad413299bbe673427f50be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "523fdc6d17714cdab06c521b21a94a2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f4a82c4f3d4242289a1fc9edabb71157",
        "IPY_MODEL_0eeec41e29e649eba93cf63cdb32b362",
        "IPY_MODEL_f9aa22817dac4a2da4a47e8240826387"
       ],
       "layout": "IPY_MODEL_ebf9167e17e3486bbfe26c38d097b2c4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "55f55dda6a364a568e8c61875327a161": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60146b65f937497aa0390cff0d8622e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6a95d61e582841b3ba9f67c219d8eb30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a4d0a42da5043e0af6f65db2f406726",
        "IPY_MODEL_f5de21c2a0994833b9531869d4baed62",
        "IPY_MODEL_a2fb0c73d1a04093876b8d01250b718f"
       ],
       "layout": "IPY_MODEL_25d77fb96a914ba3b5b56393a604db39",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6c565868ce054c048d924ae90e37a51f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d5110f2a2fd4356a2182a1e91f27b7e",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8fec173b12754c5eb183ab663431ff29",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "75363ea9f8164a9ca052ad16824d4997": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c1c937a4c41428ead44ba2d4fc3ef15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_44467ba09f2a43e5a0d1a7a7a1621d17",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60146b65f937497aa0390cff0d8622e3",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "82345917c175471287c81ee2cc44a1f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "85db632148cb4b2180c65399e67d4f7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c411e9f825f64758896c875cd86141fb",
       "placeholder": "​",
       "style": "IPY_MODEL_a18c6649ed41405bbded8a14451375e1",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 10.1kB/s]"
      }
     },
     "8fec173b12754c5eb183ab663431ff29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9014633107334f18b4794f17b76dd362": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c7a0f57e2304e1ea741b9b9256f7263": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d5110f2a2fd4356a2182a1e91f27b7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a18c6649ed41405bbded8a14451375e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2fb0c73d1a04093876b8d01250b718f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a6df0d4e39654ade8a5101492992fc8f",
       "placeholder": "​",
       "style": "IPY_MODEL_82345917c175471287c81ee2cc44a1f0",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 222MB/s]"
      }
     },
     "a6df0d4e39654ade8a5101492992fc8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7e906ba61024d98a600ff0512ff67fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c411e9f825f64758896c875cd86141fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cababe246c0e44678c0307a299dd63fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfb26521de574ae48ddaa64a94a73f9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d00f606833084a608d759b3660af1e95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d3de6482bf9643a4b25537b4a3e6046a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d95703beb1fb416db66dcfb50f8ca50b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e6d17d44fa084f3fa06dd5c009872500": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea6a4b1f53964805a6db6aa205ae490c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c190ea93b7f4dc79369681d08dddf44",
       "placeholder": "​",
       "style": "IPY_MODEL_4b3dda780faa4185a74e23a6a3bc8a87",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 182B/s]"
      }
     },
     "ebf9167e17e3486bbfe26c38d097b2c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4a82c4f3d4242289a1fc9edabb71157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_55f55dda6a364a568e8c61875327a161",
       "placeholder": "​",
       "style": "IPY_MODEL_d3de6482bf9643a4b25537b4a3e6046a",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "f5de21c2a0994833b9531869d4baed62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_17bccbff5c004f9f8be308221aa9c36e",
       "max": 497810400,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4c9c1c1615974a3c86b5a882123f4748",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400
      }
     },
     "f9aa22817dac4a2da4a47e8240826387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_07227da25f6746cfa1766795efde4137",
       "placeholder": "​",
       "style": "IPY_MODEL_05997f985b88486e8e7d2515ae99c85a",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 150kB/s]"
      }
     },
     "fb0d4167f1e14811923625d16b765a0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_21552ff97cdc471fb48a0057e8afc1a4",
       "placeholder": "​",
       "style": "IPY_MODEL_375a84cd65dd4df5ad56fd3a801b1ab8",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "fc144b9cc25b4372b7ad3b33d10894a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_75363ea9f8164a9ca052ad16824d4997",
       "placeholder": "​",
       "style": "IPY_MODEL_d95703beb1fb416db66dcfb50f8ca50b",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
