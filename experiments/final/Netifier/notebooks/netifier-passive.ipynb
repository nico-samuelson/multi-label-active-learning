{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9896348,"sourceType":"datasetVersion","datasetId":6078649}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport wandb\nimport torch\nimport itertools\nimport torch.nn as nn\nfrom transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification, BertPreTrainedModel, Trainer, TrainingArguments\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:35.880721Z","iopub.execute_input":"2024-12-17T08:48:35.881421Z","iopub.status.idle":"2024-12-17T08:48:48.768303Z","shell.execute_reply.started":"2024-12-17T08:48:35.881377Z","shell.execute_reply":"2024-12-17T08:48:48.767608Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb-key\")","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:48.769635Z","iopub.execute_input":"2024-12-17T08:48:48.770172Z","iopub.status.idle":"2024-12-17T08:48:49.068961Z","shell.execute_reply.started":"2024-12-17T08:48:48.770144Z","shell.execute_reply":"2024-12-17T08:48:49.068042Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"wandb.login(key=secret_value_0)","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:49.070061Z","iopub.execute_input":"2024-12-17T08:48:49.070300Z","iopub.status.idle":"2024-12-17T08:48:50.982014Z","shell.execute_reply.started":"2024-12-17T08:48:49.070276Z","shell.execute_reply":"2024-12-17T08:48:50.981160Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def set_seed(seed):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:48:50.984310Z","iopub.execute_input":"2024-12-17T08:48:50.985288Z","iopub.status.idle":"2024-12-17T08:48:50.993090Z","shell.execute_reply.started":"2024-12-17T08:48:50.985259Z","shell.execute_reply":"2024-12-17T08:48:50.992317Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/netifier-2/processed_train.csv', encoding='latin-1')\nval_data = pd.read_csv('/kaggle/input/netifier-2/processed_test.csv', encoding='latin-1')\n\ndata = pd.concat([train_data, val_data], ignore_index=True)\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:50.994053Z","iopub.execute_input":"2024-12-17T08:48:50.994318Z","iopub.status.idle":"2024-12-17T08:48:51.136959Z","shell.execute_reply.started":"2024-12-17T08:48:50.994278Z","shell.execute_reply":"2024-12-17T08:48:51.136110Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                       original_text     source  pornografi  \\\n0  [QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...     kaskus           0   \n1  @verosvante kita2 aja nitizen yang pada kepo,t...  instagram           0   \n2  \"#SidangAhok smg sipenista agama n ateknya mat...    twitter           0   \n3  @bolususulembang.jkt barusan baca undang2 ini....  instagram           0   \n4  bikin anak mulu lu nof \\nkaga mikir apa kasian...     kaskus           0   \n\n   sara  radikalisme  pencemaran_nama_baik  \\\n0     0            0                     1   \n1     0            0                     0   \n2     1            1                     1   \n3     0            0                     0   \n4     0            0                     0   \n\n                                      processed_text  \n0  jabar memang provinsi barokah boleh juga dan n...  \n1  kita saja nitizen yang pada penasaran toh kelu...  \n2  sidangahok semoga sipenista agama dan ateknya ...  \n3  jakarta barusan baca undang ini tetap dibedaka...  \n4  buat anak melulu kamu nof nkaga mikir apa kasi...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_text</th>\n      <th>source</th>\n      <th>pornografi</th>\n      <th>sara</th>\n      <th>radikalisme</th>\n      <th>pencemaran_nama_baik</th>\n      <th>processed_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[QUOTE=jessepinkman16;5a50ac34d89b093f368b456e...</td>\n      <td>kaskus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>jabar memang provinsi barokah boleh juga dan n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@verosvante kita2 aja nitizen yang pada kepo,t...</td>\n      <td>instagram</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>kita saja nitizen yang pada penasaran toh kelu...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"#SidangAhok smg sipenista agama n ateknya mat...</td>\n      <td>twitter</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>sidangahok semoga sipenista agama dan ateknya ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@bolususulembang.jkt barusan baca undang2 ini....</td>\n      <td>instagram</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>jakarta barusan baca undang ini tetap dibedaka...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bikin anak mulu lu nof \\nkaga mikir apa kasian...</td>\n      <td>kaskus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>buat anak melulu kamu nof nkaga mikir apa kasi...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:48:51.137995Z","iopub.execute_input":"2024-12-17T08:48:51.138322Z","iopub.status.idle":"2024-12-17T08:48:51.147361Z","shell.execute_reply.started":"2024-12-17T08:48:51.138293Z","shell.execute_reply":"2024-12-17T08:48:51.146585Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_labels = train_data.columns[2:6]\nval_labels = val_data.columns[2:6]\n\n# Extract features and labels for training and validation\nX_train = train_data['processed_text'].values\ny_train = train_data[train_labels].values\nX_val = val_data['processed_text'].values\ny_val = val_data[val_labels].values\n\nprint(X_train.shape, y_train.shape)\nprint(X_val.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:51.148364Z","iopub.execute_input":"2024-12-17T08:48:51.148651Z","iopub.status.idle":"2024-12-17T08:48:51.159576Z","shell.execute_reply.started":"2024-12-17T08:48:51.148626Z","shell.execute_reply":"2024-12-17T08:48:51.158635Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(6218,) (6218, 4)\n(1555,) (1555, 4)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"EPOCHS = 10\nBATCH_SIZE = 16\nLEARNING_RATE = 2e-5","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:51.160694Z","iopub.execute_input":"2024-12-17T08:48:51.160942Z","iopub.status.idle":"2024-12-17T08:48:51.170970Z","shell.execute_reply.started":"2024-12-17T08:48:51.160918Z","shell.execute_reply":"2024-12-17T08:48:51.170103Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\nimport numpy as np\nimport torch\n\n# Define custom Dataset class\nclass NetifierDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=96, use_float=True):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.use_float = use_float\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        labels = self.labels[idx]\n        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n        item = {key: val.squeeze() for key, val in encoding.items()}\n        item['labels'] = torch.tensor(labels, dtype=torch.float if self.use_float else torch.long)\n        return item\n\n# Initialize BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-12-17T08:48:51.171942Z","iopub.execute_input":"2024-12-17T08:48:51.172214Z","iopub.status.idle":"2024-12-17T08:48:53.705528Z","shell.execute_reply.started":"2024-12-17T08:48:51.172172Z","shell.execute_reply":"2024-12-17T08:48:53.704854Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe93d18f4bff494f83ced2d1be991b2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a79b9edd874c75a63496168a33f1ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a047178eab904e47ae8ddf182e8159b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9f842c161c428db6914573812cff57"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"class BertForMultiLabelClassification(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        self.num_labels = [2,2,2,2]\n\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifiers = nn.ModuleList([nn.Linear(config.hidden_size, i) for i in self.num_labels])\n\n        self.init_weights()\n\n    def forward(\n        self,\n        input_ids=None,\n        subword_to_word_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        labels=None,\n    ):\n\n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n        )\n\n        sequence_output = self.dropout(outputs[1])\n        logits = []\n        for classifier in self.classifiers:\n            logit = classifier(sequence_output)\n            logits.append(logit)\n\n        \n        logits = [torch.sigmoid(logit) for logit in logits]\n        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n        \n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            total_loss = 0\n            for i, (logit, num_label) in enumerate(zip(logits, self.num_labels)):\n                label = labels[:, i]\n                loss = loss_fct(logit.view(-1, num_label), label.view(-1))\n                total_loss += loss\n\n            outputs = (total_loss,) + outputs\n\n        return outputs  # (loss), scores, (hidden_states), (attentions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:48:53.708503Z","iopub.execute_input":"2024-12-17T08:48:53.708889Z","iopub.status.idle":"2024-12-17T08:48:53.717307Z","shell.execute_reply.started":"2024-12-17T08:48:53.708851Z","shell.execute_reply":"2024-12-17T08:48:53.716395Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Define compute metrics for evaluation\ndef compute_metrics_multi(p):\n    logits = p.predictions # logits list<tensor(bs, num_label)> ~ list of batch prediction per class \n    label_batch = p.label_ids\n\n    # print(p.predictions)\n    # generate prediction & label list\n    list_hyp = []\n    list_label = []\n    hyp = [torch.topk(torch.tensor(logit, dtype=torch.float), 1)[1] for logit in logits] # list<tensor(bs)>\n    batch_size = label_batch.shape[0]\n    num_label = len(hyp)\n    for i in range(batch_size):\n        hyps = []\n        labels = torch.tensor(label_batch[i,:], dtype=torch.float)\n        for j in range(num_label):\n            hyps.append(hyp[j][i].item())\n\n        hyps = torch.tensor(hyps, dtype=torch.float)\n        list_hyp.append(hyps)\n        list_label.append(labels)\n    \n    accuracy = accuracy_score(list_label, list_hyp)\n    # print(accuracy)\n\n    # Standard multi-label precision, recall, and F1 metrics\n    precision, recall, f1_micro, _ = precision_recall_fscore_support(list_label, list_hyp, average='micro', zero_division=0)\n    f1_macro = f1_score(list_label, list_hyp, average='macro', zero_division=0)\n\n    # print(classification_report(list_label, list_hyp, zero_division=0, target_names=['pornografi', 'sara', 'radikalisme', 'pencemaran_nama_baik']))\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro\n    }","metadata":{"execution":{"iopub.status.busy":"2024-12-17T08:48:53.718330Z","iopub.execute_input":"2024-12-17T08:48:53.718606Z","iopub.status.idle":"2024-12-17T08:48:53.732360Z","shell.execute_reply.started":"2024-12-17T08:48:53.718567Z","shell.execute_reply":"2024-12-17T08:48:53.731593Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Define compute metrics for evaluation\ndef compute_metrics_single(p):\n    preds = torch.sigmoid(torch.tensor(p.predictions)).round()  # Sigmoid and threshold for multi-label\n    labels = torch.tensor(p.label_ids)\n    \n    accuracy = accuracy_score(labels, preds)\n\n    # Standard multi-label precision, recall, and F1 metrics\n    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n    a, b, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_micro': f1_micro,\n        'f1_macro': f1_macro\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:48:53.733262Z","iopub.execute_input":"2024-12-17T08:48:53.733594Z","iopub.status.idle":"2024-12-17T08:48:53.745325Z","shell.execute_reply.started":"2024-12-17T08:48:53.733543Z","shell.execute_reply":"2024-12-17T08:48:53.744510Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_model(sequence_length, model_name, seed=42, multi_classifier=False, layers_freezed=6):\n    if multi_classifier:\n        config = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\n        config.num_labels = 4\n        config.num_labels_list = [2,2,2,2]\n        model = BertForMultiLabelClassification.from_pretrained(\n            model_name,\n            config=config\n        )\n        train_dataset = NetifierDataset(X_train, y_train, tokenizer, max_length=sequence_length, use_float=False)\n        val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=sequence_length, use_float=False)\n    else:\n        model = BertForSequenceClassification.from_pretrained(\n            'indobenchmark/indobert-base-p1',\n            num_labels=len(train_labels),\n            problem_type=\"multi_label_classification\"\n        )\n        train_dataset = NetifierDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n        val_dataset = NetifierDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n\n    # Freeze the first few layers of the encoder\n    for name, param in model.named_parameters():\n        # Specify the layers you want to freeze (e.g., first 6 layers)\n        if \"encoder.layer\" in name:\n            # Extract the layer number safely\n            layer_num = name.split(\".\")[3]\n            try:\n                # Freeze only the first 6 layers\n                if int(layer_num) < layers_freezed:\n                    param.requires_grad = False\n            except ValueError:\n                # Skip any parameter names that donâ€™t follow the expected format\n                continue\n\n    model.to(device)\n    \n    # Define training arguments\n    training_args = TrainingArguments(\n        output_dir='./results/netifier-passive',\n        eval_strategy=\"epoch\",                    # Evaluate after every epoch\n        save_strategy=\"epoch\",                    # Save model after every epoch\n        learning_rate=LEARNING_RATE,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        num_train_epochs=EPOCHS,\n        load_best_model_at_end=True,\n        metric_for_best_model='f1_micro',\n        save_total_limit=1,\n        seed=seed\n    )\n\n    # Initialize Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics_multi if multi_classifier else compute_metrics_single\n    )\n\n    # Train the model\n    trainer.train()\n\n    # Evaluate after training\n    eval_results = trainer.evaluate()\n    \n    print(eval_results)","metadata":{"execution":{"iopub.status.busy":"2024-12-17T09:18:59.110381Z","iopub.execute_input":"2024-12-17T09:18:59.111194Z","iopub.status.idle":"2024-12-17T09:18:59.120822Z","shell.execute_reply.started":"2024-12-17T09:18:59.111160Z","shell.execute_reply":"2024-12-17T09:18:59.119892Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# ABLATION: CLASSIFIER TYPE","metadata":{}},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T08:51:29.073486Z","iopub.execute_input":"2024-12-17T08:51:29.073847Z","iopub.status.idle":"2024-12-17T09:05:01.843997Z","shell.execute_reply.started":"2024-12-17T08:51:29.073816Z","shell.execute_reply":"2024-12-17T09:05:01.843077Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForMultiLabelClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifiers.0.bias', 'classifiers.0.weight', 'classifiers.1.bias', 'classifiers.1.weight', 'classifiers.2.bias', 'classifiers.2.weight', 'classifiers.3.bias', 'classifiers.3.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:23, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.688252</td>\n      <td>0.708039</td>\n      <td>0.779951</td>\n      <td>0.721719</td>\n      <td>0.749706</td>\n      <td>0.729169</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.795300</td>\n      <td>1.650742</td>\n      <td>0.708682</td>\n      <td>0.801047</td>\n      <td>0.692308</td>\n      <td>0.742718</td>\n      <td>0.734598</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.601700</td>\n      <td>1.620241</td>\n      <td>0.735048</td>\n      <td>0.783159</td>\n      <td>0.792609</td>\n      <td>0.787856</td>\n      <td>0.775630</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.516600</td>\n      <td>1.619463</td>\n      <td>0.732476</td>\n      <td>0.785174</td>\n      <td>0.782805</td>\n      <td>0.783988</td>\n      <td>0.770321</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.516600</td>\n      <td>1.610909</td>\n      <td>0.738907</td>\n      <td>0.770982</td>\n      <td>0.817496</td>\n      <td>0.793558</td>\n      <td>0.790683</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.454400</td>\n      <td>1.610939</td>\n      <td>0.726688</td>\n      <td>0.766335</td>\n      <td>0.813725</td>\n      <td>0.789320</td>\n      <td>0.785547</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.418100</td>\n      <td>1.605002</td>\n      <td>0.735691</td>\n      <td>0.795682</td>\n      <td>0.778281</td>\n      <td>0.786885</td>\n      <td>0.780578</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.384000</td>\n      <td>1.606041</td>\n      <td>0.737621</td>\n      <td>0.787155</td>\n      <td>0.794872</td>\n      <td>0.790994</td>\n      <td>0.785077</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.371700</td>\n      <td>1.604208</td>\n      <td>0.735691</td>\n      <td>0.796154</td>\n      <td>0.780543</td>\n      <td>0.788271</td>\n      <td>0.781361</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.371700</td>\n      <td>1.606190</td>\n      <td>0.732476</td>\n      <td>0.783905</td>\n      <td>0.793363</td>\n      <td>0.788606</td>\n      <td>0.782412</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 1.61090886592865, 'eval_accuracy': 0.7389067524115756, 'eval_precision': 0.7709815078236131, 'eval_recall': 0.8174962292609351, 'eval_f1_micro': 0.7935578330893118, 'eval_f1_macro': 0.790683366269395, 'eval_runtime': 7.3802, 'eval_samples_per_second': 210.699, 'eval_steps_per_second': 13.279, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:05:01.845325Z","iopub.execute_input":"2024-12-17T09:05:01.845690Z","iopub.status.idle":"2024-12-17T09:18:32.085404Z","shell.execute_reply.started":"2024-12-17T09:05:01.845661Z","shell.execute_reply":"2024-12-17T09:18:32.084588Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:21, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.238067</td>\n      <td>0.707395</td>\n      <td>0.755427</td>\n      <td>0.787330</td>\n      <td>0.771049</td>\n      <td>0.761168</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.276500</td>\n      <td>0.224573</td>\n      <td>0.727974</td>\n      <td>0.776692</td>\n      <td>0.779035</td>\n      <td>0.777861</td>\n      <td>0.777041</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.177600</td>\n      <td>0.227681</td>\n      <td>0.735048</td>\n      <td>0.777616</td>\n      <td>0.806938</td>\n      <td>0.792006</td>\n      <td>0.785877</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.123100</td>\n      <td>0.265755</td>\n      <td>0.704823</td>\n      <td>0.749827</td>\n      <td>0.815988</td>\n      <td>0.781510</td>\n      <td>0.776815</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.123100</td>\n      <td>0.285083</td>\n      <td>0.731190</td>\n      <td>0.778024</td>\n      <td>0.795626</td>\n      <td>0.786726</td>\n      <td>0.783565</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.077300</td>\n      <td>0.334047</td>\n      <td>0.702251</td>\n      <td>0.733813</td>\n      <td>0.846154</td>\n      <td>0.785989</td>\n      <td>0.786090</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.048000</td>\n      <td>0.343496</td>\n      <td>0.729904</td>\n      <td>0.803543</td>\n      <td>0.752640</td>\n      <td>0.777259</td>\n      <td>0.771024</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.034400</td>\n      <td>0.360888</td>\n      <td>0.721543</td>\n      <td>0.764164</td>\n      <td>0.813725</td>\n      <td>0.788167</td>\n      <td>0.785740</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024800</td>\n      <td>0.373670</td>\n      <td>0.720900</td>\n      <td>0.758741</td>\n      <td>0.818250</td>\n      <td>0.787373</td>\n      <td>0.784322</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024800</td>\n      <td>0.365624</td>\n      <td>0.722186</td>\n      <td>0.773654</td>\n      <td>0.801659</td>\n      <td>0.787407</td>\n      <td>0.784818</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22768056392669678, 'eval_accuracy': 0.735048231511254, 'eval_precision': 0.7776162790697675, 'eval_recall': 0.8069381598793364, 'eval_f1_micro': 0.7920059215396003, 'eval_f1_macro': 0.7858773563449808, 'eval_runtime': 7.0962, 'eval_samples_per_second': 219.13, 'eval_steps_per_second': 13.81, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# ABLATION - FREEZE LAYERS","metadata":{}},{"cell_type":"markdown","source":"## NO FREEZE","metadata":{}},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=False, layers_freezed=0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:54:57.372965Z","iopub.execute_input":"2024-12-17T09:54:57.373247Z","iopub.status.idle":"2024-12-17T10:10:51.049929Z","shell.execute_reply.started":"2024-12-17T09:54:57.373217Z","shell.execute_reply":"2024-12-17T10:10:51.049143Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 15:44, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.221049</td>\n      <td>0.742122</td>\n      <td>0.782229</td>\n      <td>0.809955</td>\n      <td>0.795850</td>\n      <td>0.789748</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.262200</td>\n      <td>0.222378</td>\n      <td>0.733762</td>\n      <td>0.791125</td>\n      <td>0.779789</td>\n      <td>0.785416</td>\n      <td>0.782453</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.160400</td>\n      <td>0.240119</td>\n      <td>0.729260</td>\n      <td>0.772292</td>\n      <td>0.790347</td>\n      <td>0.781215</td>\n      <td>0.775450</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.095500</td>\n      <td>0.283501</td>\n      <td>0.733119</td>\n      <td>0.776462</td>\n      <td>0.791101</td>\n      <td>0.783713</td>\n      <td>0.775090</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.095500</td>\n      <td>0.307281</td>\n      <td>0.729260</td>\n      <td>0.793103</td>\n      <td>0.763198</td>\n      <td>0.777863</td>\n      <td>0.767594</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.049000</td>\n      <td>0.338608</td>\n      <td>0.734405</td>\n      <td>0.782738</td>\n      <td>0.793363</td>\n      <td>0.788015</td>\n      <td>0.780291</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.026500</td>\n      <td>0.375820</td>\n      <td>0.737621</td>\n      <td>0.805071</td>\n      <td>0.766214</td>\n      <td>0.785162</td>\n      <td>0.774832</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.016200</td>\n      <td>0.382492</td>\n      <td>0.736334</td>\n      <td>0.788490</td>\n      <td>0.795626</td>\n      <td>0.792042</td>\n      <td>0.784300</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.011800</td>\n      <td>0.397557</td>\n      <td>0.736334</td>\n      <td>0.779971</td>\n      <td>0.804676</td>\n      <td>0.792131</td>\n      <td>0.785286</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.011800</td>\n      <td>0.396310</td>\n      <td>0.737621</td>\n      <td>0.785240</td>\n      <td>0.802413</td>\n      <td>0.793734</td>\n      <td>0.786501</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22104939818382263, 'eval_accuracy': 0.7421221864951768, 'eval_precision': 0.7822286962855062, 'eval_recall': 0.8099547511312217, 'eval_f1_micro': 0.795850314931456, 'eval_f1_macro': 0.7897481934286074, 'eval_runtime': 7.0665, 'eval_samples_per_second': 220.052, 'eval_steps_per_second': 13.868, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## 6 LAYERS","metadata":{}},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=False, layers_freezed=6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:05:01.845325Z","iopub.execute_input":"2024-12-17T09:05:01.845690Z","iopub.status.idle":"2024-12-17T09:18:32.085404Z","shell.execute_reply.started":"2024-12-17T09:05:01.845661Z","shell.execute_reply":"2024-12-17T09:18:32.084588Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:21, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.238067</td>\n      <td>0.707395</td>\n      <td>0.755427</td>\n      <td>0.787330</td>\n      <td>0.771049</td>\n      <td>0.761168</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.276500</td>\n      <td>0.224573</td>\n      <td>0.727974</td>\n      <td>0.776692</td>\n      <td>0.779035</td>\n      <td>0.777861</td>\n      <td>0.777041</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.177600</td>\n      <td>0.227681</td>\n      <td>0.735048</td>\n      <td>0.777616</td>\n      <td>0.806938</td>\n      <td>0.792006</td>\n      <td>0.785877</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.123100</td>\n      <td>0.265755</td>\n      <td>0.704823</td>\n      <td>0.749827</td>\n      <td>0.815988</td>\n      <td>0.781510</td>\n      <td>0.776815</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.123100</td>\n      <td>0.285083</td>\n      <td>0.731190</td>\n      <td>0.778024</td>\n      <td>0.795626</td>\n      <td>0.786726</td>\n      <td>0.783565</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.077300</td>\n      <td>0.334047</td>\n      <td>0.702251</td>\n      <td>0.733813</td>\n      <td>0.846154</td>\n      <td>0.785989</td>\n      <td>0.786090</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.048000</td>\n      <td>0.343496</td>\n      <td>0.729904</td>\n      <td>0.803543</td>\n      <td>0.752640</td>\n      <td>0.777259</td>\n      <td>0.771024</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.034400</td>\n      <td>0.360888</td>\n      <td>0.721543</td>\n      <td>0.764164</td>\n      <td>0.813725</td>\n      <td>0.788167</td>\n      <td>0.785740</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024800</td>\n      <td>0.373670</td>\n      <td>0.720900</td>\n      <td>0.758741</td>\n      <td>0.818250</td>\n      <td>0.787373</td>\n      <td>0.784322</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024800</td>\n      <td>0.365624</td>\n      <td>0.722186</td>\n      <td>0.773654</td>\n      <td>0.801659</td>\n      <td>0.787407</td>\n      <td>0.784818</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22768056392669678, 'eval_accuracy': 0.735048231511254, 'eval_precision': 0.7776162790697675, 'eval_recall': 0.8069381598793364, 'eval_f1_micro': 0.7920059215396003, 'eval_f1_macro': 0.7858773563449808, 'eval_runtime': 7.0962, 'eval_samples_per_second': 219.13, 'eval_steps_per_second': 13.81, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## 8 LAYERS","metadata":{}},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=False, layers_freezed=8) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:19:01.865076Z","iopub.execute_input":"2024-12-17T09:19:01.865406Z","iopub.status.idle":"2024-12-17T09:31:46.280436Z","shell.execute_reply.started":"2024-12-17T09:19:01.865377Z","shell.execute_reply":"2024-12-17T09:31:46.279309Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 12:35, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.237551</td>\n      <td>0.707395</td>\n      <td>0.746971</td>\n      <td>0.790347</td>\n      <td>0.768047</td>\n      <td>0.758204</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.287100</td>\n      <td>0.221479</td>\n      <td>0.722830</td>\n      <td>0.786159</td>\n      <td>0.762443</td>\n      <td>0.774119</td>\n      <td>0.770915</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.191500</td>\n      <td>0.226884</td>\n      <td>0.724759</td>\n      <td>0.763571</td>\n      <td>0.806184</td>\n      <td>0.784299</td>\n      <td>0.777958</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.146300</td>\n      <td>0.243145</td>\n      <td>0.727331</td>\n      <td>0.773888</td>\n      <td>0.800151</td>\n      <td>0.786800</td>\n      <td>0.777241</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.146300</td>\n      <td>0.261850</td>\n      <td>0.726045</td>\n      <td>0.793292</td>\n      <td>0.766968</td>\n      <td>0.779908</td>\n      <td>0.769391</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.102800</td>\n      <td>0.290066</td>\n      <td>0.716399</td>\n      <td>0.745308</td>\n      <td>0.838612</td>\n      <td>0.789212</td>\n      <td>0.788240</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.074300</td>\n      <td>0.303172</td>\n      <td>0.729260</td>\n      <td>0.776878</td>\n      <td>0.795626</td>\n      <td>0.786140</td>\n      <td>0.777243</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.054000</td>\n      <td>0.329354</td>\n      <td>0.715113</td>\n      <td>0.745283</td>\n      <td>0.834087</td>\n      <td>0.787189</td>\n      <td>0.784116</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.044400</td>\n      <td>0.329205</td>\n      <td>0.732476</td>\n      <td>0.769615</td>\n      <td>0.813725</td>\n      <td>0.791056</td>\n      <td>0.786684</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.044400</td>\n      <td>0.329245</td>\n      <td>0.727974</td>\n      <td>0.777289</td>\n      <td>0.800151</td>\n      <td>0.788554</td>\n      <td>0.783284</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.32920530438423157, 'eval_accuracy': 0.732475884244373, 'eval_precision': 0.7696148359486448, 'eval_recall': 0.8137254901960784, 'eval_f1_micro': 0.7910557184750733, 'eval_f1_macro': 0.7866838964570766, 'eval_runtime': 7.0993, 'eval_samples_per_second': 219.036, 'eval_steps_per_second': 13.804, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 10 LAYERS","metadata":{}},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=False, layers_freezed=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:31:46.282145Z","iopub.execute_input":"2024-12-17T09:31:46.282589Z","iopub.status.idle":"2024-12-17T09:43:45.505804Z","shell.execute_reply.started":"2024-12-17T09:31:46.282532Z","shell.execute_reply":"2024-12-17T09:43:45.504953Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 11:50, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.253207</td>\n      <td>0.693248</td>\n      <td>0.725694</td>\n      <td>0.788084</td>\n      <td>0.755604</td>\n      <td>0.744882</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.308800</td>\n      <td>0.225946</td>\n      <td>0.718971</td>\n      <td>0.787081</td>\n      <td>0.744344</td>\n      <td>0.765116</td>\n      <td>0.759318</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.211000</td>\n      <td>0.225315</td>\n      <td>0.727331</td>\n      <td>0.777194</td>\n      <td>0.781297</td>\n      <td>0.779240</td>\n      <td>0.771995</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.172600</td>\n      <td>0.234999</td>\n      <td>0.720257</td>\n      <td>0.774049</td>\n      <td>0.782805</td>\n      <td>0.778403</td>\n      <td>0.764725</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.172600</td>\n      <td>0.245333</td>\n      <td>0.722186</td>\n      <td>0.782148</td>\n      <td>0.779789</td>\n      <td>0.780967</td>\n      <td>0.772097</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.136000</td>\n      <td>0.262774</td>\n      <td>0.714469</td>\n      <td>0.752078</td>\n      <td>0.819005</td>\n      <td>0.784116</td>\n      <td>0.778105</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.114400</td>\n      <td>0.276780</td>\n      <td>0.720257</td>\n      <td>0.757193</td>\n      <td>0.813725</td>\n      <td>0.784442</td>\n      <td>0.776171</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.091300</td>\n      <td>0.281559</td>\n      <td>0.722186</td>\n      <td>0.765973</td>\n      <td>0.804676</td>\n      <td>0.784847</td>\n      <td>0.776552</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.083600</td>\n      <td>0.288973</td>\n      <td>0.718971</td>\n      <td>0.768782</td>\n      <td>0.794872</td>\n      <td>0.781609</td>\n      <td>0.774309</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.083600</td>\n      <td>0.291407</td>\n      <td>0.722186</td>\n      <td>0.770408</td>\n      <td>0.797134</td>\n      <td>0.783543</td>\n      <td>0.776232</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.2815586030483246, 'eval_accuracy': 0.7221864951768489, 'eval_precision': 0.7659727207465901, 'eval_recall': 0.8046757164404224, 'eval_f1_micro': 0.7848473703567488, 'eval_f1_macro': 0.7765521955817776, 'eval_runtime': 7.0937, 'eval_samples_per_second': 219.21, 'eval_steps_per_second': 13.815, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## FULLY FREEZED","metadata":{}},{"cell_type":"code","source":"train_model(128, 'indobenchmark/indobert-base-p1', multi_classifier=False, layers_freezed=12)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T09:43:45.506875Z","iopub.execute_input":"2024-12-17T09:43:45.507172Z","iopub.status.idle":"2024-12-17T09:54:57.371392Z","shell.execute_reply.started":"2024-12-17T09:43:45.507141Z","shell.execute_reply":"2024-12-17T09:54:57.370504Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 11:02, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.334860</td>\n      <td>0.593569</td>\n      <td>0.851711</td>\n      <td>0.337858</td>\n      <td>0.483801</td>\n      <td>0.414862</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.405500</td>\n      <td>0.283821</td>\n      <td>0.637942</td>\n      <td>0.783527</td>\n      <td>0.559578</td>\n      <td>0.652882</td>\n      <td>0.626020</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.286500</td>\n      <td>0.263543</td>\n      <td>0.656592</td>\n      <td>0.794589</td>\n      <td>0.598039</td>\n      <td>0.682444</td>\n      <td>0.657591</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.240700</td>\n      <td>0.252031</td>\n      <td>0.668167</td>\n      <td>0.769702</td>\n      <td>0.662896</td>\n      <td>0.712318</td>\n      <td>0.693835</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.240700</td>\n      <td>0.246598</td>\n      <td>0.680386</td>\n      <td>0.772414</td>\n      <td>0.675716</td>\n      <td>0.720837</td>\n      <td>0.707994</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.209200</td>\n      <td>0.243412</td>\n      <td>0.685531</td>\n      <td>0.764901</td>\n      <td>0.696833</td>\n      <td>0.729282</td>\n      <td>0.719849</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.188400</td>\n      <td>0.243103</td>\n      <td>0.688746</td>\n      <td>0.765957</td>\n      <td>0.705882</td>\n      <td>0.734694</td>\n      <td>0.723927</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.172700</td>\n      <td>0.243318</td>\n      <td>0.689389</td>\n      <td>0.776094</td>\n      <td>0.695324</td>\n      <td>0.733492</td>\n      <td>0.721430</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.168300</td>\n      <td>0.243300</td>\n      <td>0.688746</td>\n      <td>0.774874</td>\n      <td>0.693062</td>\n      <td>0.731688</td>\n      <td>0.720199</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.168300</td>\n      <td>0.243183</td>\n      <td>0.690032</td>\n      <td>0.772955</td>\n      <td>0.698341</td>\n      <td>0.733756</td>\n      <td>0.721618</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.24310289323329926, 'eval_accuracy': 0.6887459807073955, 'eval_precision': 0.7659574468085106, 'eval_recall': 0.7058823529411765, 'eval_f1_micro': 0.7346938775510204, 'eval_f1_macro': 0.7239273274892924, 'eval_runtime': 7.0835, 'eval_samples_per_second': 219.524, 'eval_steps_per_second': 13.835, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# ABLATION - SEQUENCE LENGTH","metadata":{}},{"cell_type":"code","source":"# Tokenize each text and calculate their lengths\ntoken_lengths = [len(tokenizer.tokenize(text)) for text in X_train]\n\n# Calculate the average length\naverage_length = sum(token_lengths) / len(token_lengths)\nmax_length = max(token_lengths)\n\nprint(\"Average length of tokenized text:\", average_length)\nprint(\"Max token length:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2024-12-17T10:14:44.622594Z","iopub.execute_input":"2024-12-17T10:14:44.622945Z","iopub.status.idle":"2024-12-17T10:14:50.045094Z","shell.execute_reply.started":"2024-12-17T10:14:44.622915Z","shell.execute_reply":"2024-12-17T10:14:50.044231Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Average length of tokenized text: 54.3126407204889\nMax token length: 2591\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncounts, bins = np.histogram(token_lengths, range=(0, 500))\nplt.stairs(counts, bins)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T10:14:50.046523Z","iopub.execute_input":"2024-12-17T10:14:50.046807Z","iopub.status.idle":"2024-12-17T10:14:50.275605Z","shell.execute_reply.started":"2024-12-17T10:14:50.046781Z","shell.execute_reply":"2024-12-17T10:14:50.274833Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"## MAX LENGTH 64","metadata":{}},{"cell_type":"code","source":"train_model(64, 'indobenchmark/indobert-base-p1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T10:15:07.373140Z","iopub.execute_input":"2024-12-17T10:15:07.373855Z","iopub.status.idle":"2024-12-17T10:23:44.912715Z","shell.execute_reply.started":"2024-12-17T10:15:07.373823Z","shell.execute_reply":"2024-12-17T10:23:44.911891Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 08:30, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.240055</td>\n      <td>0.716399</td>\n      <td>0.758496</td>\n      <td>0.791101</td>\n      <td>0.774456</td>\n      <td>0.766750</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.278300</td>\n      <td>0.223907</td>\n      <td>0.728617</td>\n      <td>0.800161</td>\n      <td>0.751885</td>\n      <td>0.775272</td>\n      <td>0.774416</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.183500</td>\n      <td>0.231723</td>\n      <td>0.729260</td>\n      <td>0.788863</td>\n      <td>0.769231</td>\n      <td>0.778923</td>\n      <td>0.774399</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.126300</td>\n      <td>0.263284</td>\n      <td>0.720257</td>\n      <td>0.787316</td>\n      <td>0.767722</td>\n      <td>0.777396</td>\n      <td>0.763792</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.126300</td>\n      <td>0.288229</td>\n      <td>0.719614</td>\n      <td>0.778029</td>\n      <td>0.779789</td>\n      <td>0.778908</td>\n      <td>0.774926</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.077900</td>\n      <td>0.318748</td>\n      <td>0.723473</td>\n      <td>0.756401</td>\n      <td>0.824284</td>\n      <td>0.788885</td>\n      <td>0.787536</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.050700</td>\n      <td>0.339900</td>\n      <td>0.725402</td>\n      <td>0.791667</td>\n      <td>0.759427</td>\n      <td>0.775212</td>\n      <td>0.769270</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.035000</td>\n      <td>0.359005</td>\n      <td>0.720900</td>\n      <td>0.761973</td>\n      <td>0.803922</td>\n      <td>0.782385</td>\n      <td>0.779991</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.025300</td>\n      <td>0.368483</td>\n      <td>0.726688</td>\n      <td>0.765299</td>\n      <td>0.801659</td>\n      <td>0.783057</td>\n      <td>0.780856</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.025300</td>\n      <td>0.369731</td>\n      <td>0.731190</td>\n      <td>0.776627</td>\n      <td>0.791855</td>\n      <td>0.784167</td>\n      <td>0.780261</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.31874769926071167, 'eval_accuracy': 0.7234726688102894, 'eval_precision': 0.756401384083045, 'eval_recall': 0.8242835595776772, 'eval_f1_micro': 0.7888848791050163, 'eval_f1_macro': 0.7875355390047298, 'eval_runtime': 4.8342, 'eval_samples_per_second': 321.664, 'eval_steps_per_second': 20.272, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## MAX LENGTH 80","metadata":{}},{"cell_type":"code","source":"train_model(80, 'indobenchmark/indobert-base-p1')","metadata":{"execution":{"iopub.status.busy":"2024-12-17T10:23:44.914398Z","iopub.execute_input":"2024-12-17T10:23:44.914705Z","iopub.status.idle":"2024-12-17T10:34:08.339008Z","shell.execute_reply.started":"2024-12-17T10:23:44.914673Z","shell.execute_reply":"2024-12-17T10:34:08.338143Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 10:15, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.233324</td>\n      <td>0.716399</td>\n      <td>0.765351</td>\n      <td>0.789593</td>\n      <td>0.777283</td>\n      <td>0.766951</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.275500</td>\n      <td>0.219845</td>\n      <td>0.737621</td>\n      <td>0.803318</td>\n      <td>0.766968</td>\n      <td>0.784722</td>\n      <td>0.782234</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.181300</td>\n      <td>0.229127</td>\n      <td>0.729904</td>\n      <td>0.777372</td>\n      <td>0.803167</td>\n      <td>0.790059</td>\n      <td>0.783199</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.124500</td>\n      <td>0.254633</td>\n      <td>0.732476</td>\n      <td>0.798905</td>\n      <td>0.769985</td>\n      <td>0.784178</td>\n      <td>0.774412</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.124500</td>\n      <td>0.298243</td>\n      <td>0.724116</td>\n      <td>0.756757</td>\n      <td>0.823529</td>\n      <td>0.788732</td>\n      <td>0.785397</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.077600</td>\n      <td>0.318122</td>\n      <td>0.709325</td>\n      <td>0.746441</td>\n      <td>0.830317</td>\n      <td>0.786148</td>\n      <td>0.785643</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.048300</td>\n      <td>0.339112</td>\n      <td>0.727974</td>\n      <td>0.784627</td>\n      <td>0.777526</td>\n      <td>0.781061</td>\n      <td>0.778147</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.034100</td>\n      <td>0.358802</td>\n      <td>0.727974</td>\n      <td>0.768625</td>\n      <td>0.809201</td>\n      <td>0.788391</td>\n      <td>0.785610</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024600</td>\n      <td>0.370270</td>\n      <td>0.728617</td>\n      <td>0.775165</td>\n      <td>0.795626</td>\n      <td>0.785262</td>\n      <td>0.783404</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024600</td>\n      <td>0.370343</td>\n      <td>0.724759</td>\n      <td>0.775585</td>\n      <td>0.800151</td>\n      <td>0.787676</td>\n      <td>0.785657</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:05]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22912734746932983, 'eval_accuracy': 0.729903536977492, 'eval_precision': 0.7773722627737226, 'eval_recall': 0.8031674208144797, 'eval_f1_micro': 0.7900593471810089, 'eval_f1_macro': 0.7831989229453638, 'eval_runtime': 5.691, 'eval_samples_per_second': 273.239, 'eval_steps_per_second': 17.22, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## MAX LENGTH 96","metadata":{}},{"cell_type":"code","source":"train_model(96, 'indobenchmark/indobert-base-p1')","metadata":{"execution":{"iopub.status.busy":"2024-12-17T10:34:08.340125Z","iopub.execute_input":"2024-12-17T10:34:08.340420Z","iopub.status.idle":"2024-12-17T10:45:38.347148Z","shell.execute_reply.started":"2024-12-17T10:34:08.340389Z","shell.execute_reply":"2024-12-17T10:45:38.346233Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 11:21, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.234395</td>\n      <td>0.712540</td>\n      <td>0.770504</td>\n      <td>0.772247</td>\n      <td>0.771375</td>\n      <td>0.761716</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.274800</td>\n      <td>0.222820</td>\n      <td>0.727331</td>\n      <td>0.803265</td>\n      <td>0.742081</td>\n      <td>0.771462</td>\n      <td>0.771459</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.180400</td>\n      <td>0.243920</td>\n      <td>0.727974</td>\n      <td>0.749498</td>\n      <td>0.843891</td>\n      <td>0.793899</td>\n      <td>0.787779</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.123600</td>\n      <td>0.262640</td>\n      <td>0.726045</td>\n      <td>0.779018</td>\n      <td>0.789593</td>\n      <td>0.784270</td>\n      <td>0.777756</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.123600</td>\n      <td>0.285395</td>\n      <td>0.721543</td>\n      <td>0.764037</td>\n      <td>0.810709</td>\n      <td>0.786681</td>\n      <td>0.784140</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.077000</td>\n      <td>0.311835</td>\n      <td>0.717685</td>\n      <td>0.748660</td>\n      <td>0.842383</td>\n      <td>0.792761</td>\n      <td>0.791125</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.050600</td>\n      <td>0.332521</td>\n      <td>0.724116</td>\n      <td>0.786423</td>\n      <td>0.777526</td>\n      <td>0.781949</td>\n      <td>0.775178</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.034100</td>\n      <td>0.365140</td>\n      <td>0.722830</td>\n      <td>0.759831</td>\n      <td>0.815988</td>\n      <td>0.786909</td>\n      <td>0.781479</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024800</td>\n      <td>0.365213</td>\n      <td>0.726045</td>\n      <td>0.767408</td>\n      <td>0.806184</td>\n      <td>0.786318</td>\n      <td>0.780833</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024800</td>\n      <td>0.362444</td>\n      <td>0.728617</td>\n      <td>0.774333</td>\n      <td>0.809955</td>\n      <td>0.791743</td>\n      <td>0.787563</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.24392013251781464, 'eval_accuracy': 0.7279742765273312, 'eval_precision': 0.7494976557267247, 'eval_recall': 0.8438914027149321, 'eval_f1_micro': 0.7938985455835403, 'eval_f1_macro': 0.7877792928590184, 'eval_runtime': 6.1953, 'eval_samples_per_second': 250.998, 'eval_steps_per_second': 15.819, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# USE BEST CONFIG","metadata":{}},{"cell_type":"code","source":"seeds = [50, 81, 14, 3, 94]\n\nfor seed in seeds:\n    set_seed(seed)\n    print(\"SEED:\", seed)\n    train_model(128, 'indobenchmark/indobert-base-p1', seed=seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T10:47:34.217867Z","iopub.execute_input":"2024-12-17T10:47:34.218704Z","iopub.status.idle":"2024-12-17T11:55:32.302840Z","shell.execute_reply.started":"2024-12-17T10:47:34.218673Z","shell.execute_reply":"2024-12-17T11:55:32.301910Z"}},"outputs":[{"name":"stdout","text":"SEED: 50\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:26, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.238083</td>\n      <td>0.711897</td>\n      <td>0.741781</td>\n      <td>0.816742</td>\n      <td>0.777459</td>\n      <td>0.765445</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.278700</td>\n      <td>0.219809</td>\n      <td>0.734405</td>\n      <td>0.799686</td>\n      <td>0.767722</td>\n      <td>0.783378</td>\n      <td>0.773880</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.187100</td>\n      <td>0.225664</td>\n      <td>0.725402</td>\n      <td>0.771631</td>\n      <td>0.820513</td>\n      <td>0.795322</td>\n      <td>0.793131</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.125600</td>\n      <td>0.250566</td>\n      <td>0.720900</td>\n      <td>0.766901</td>\n      <td>0.821267</td>\n      <td>0.793154</td>\n      <td>0.789530</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.125600</td>\n      <td>0.279562</td>\n      <td>0.736977</td>\n      <td>0.791957</td>\n      <td>0.772247</td>\n      <td>0.781978</td>\n      <td>0.772902</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.080200</td>\n      <td>0.309178</td>\n      <td>0.734405</td>\n      <td>0.804452</td>\n      <td>0.763198</td>\n      <td>0.783282</td>\n      <td>0.778211</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.054000</td>\n      <td>0.337428</td>\n      <td>0.720257</td>\n      <td>0.774403</td>\n      <td>0.807692</td>\n      <td>0.790698</td>\n      <td>0.786729</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.034500</td>\n      <td>0.339876</td>\n      <td>0.729260</td>\n      <td>0.782609</td>\n      <td>0.800905</td>\n      <td>0.791651</td>\n      <td>0.784861</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.026500</td>\n      <td>0.352955</td>\n      <td>0.725402</td>\n      <td>0.779749</td>\n      <td>0.795626</td>\n      <td>0.787607</td>\n      <td>0.780295</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.026500</td>\n      <td>0.359670</td>\n      <td>0.728617</td>\n      <td>0.779810</td>\n      <td>0.803922</td>\n      <td>0.791682</td>\n      <td>0.783786</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22566385567188263, 'eval_accuracy': 0.7254019292604501, 'eval_precision': 0.7716312056737589, 'eval_recall': 0.8205128205128205, 'eval_f1_micro': 0.7953216374269005, 'eval_f1_macro': 0.7931312336327655, 'eval_runtime': 7.2443, 'eval_samples_per_second': 214.652, 'eval_steps_per_second': 13.528, 'epoch': 10.0}\nSEED: 81\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:28, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.238776</td>\n      <td>0.711897</td>\n      <td>0.729858</td>\n      <td>0.812971</td>\n      <td>0.769176</td>\n      <td>0.766905</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.275600</td>\n      <td>0.218179</td>\n      <td>0.736977</td>\n      <td>0.785660</td>\n      <td>0.785068</td>\n      <td>0.785364</td>\n      <td>0.778489</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.179900</td>\n      <td>0.237848</td>\n      <td>0.723473</td>\n      <td>0.790143</td>\n      <td>0.749623</td>\n      <td>0.769350</td>\n      <td>0.765831</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.127700</td>\n      <td>0.259613</td>\n      <td>0.720257</td>\n      <td>0.761905</td>\n      <td>0.808446</td>\n      <td>0.784486</td>\n      <td>0.778934</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.127700</td>\n      <td>0.279223</td>\n      <td>0.732476</td>\n      <td>0.810723</td>\n      <td>0.752640</td>\n      <td>0.780602</td>\n      <td>0.768570</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.079100</td>\n      <td>0.300779</td>\n      <td>0.738907</td>\n      <td>0.789866</td>\n      <td>0.799397</td>\n      <td>0.794603</td>\n      <td>0.787617</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.050500</td>\n      <td>0.342165</td>\n      <td>0.721543</td>\n      <td>0.755158</td>\n      <td>0.828054</td>\n      <td>0.789928</td>\n      <td>0.787337</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.034700</td>\n      <td>0.353084</td>\n      <td>0.726688</td>\n      <td>0.772727</td>\n      <td>0.807692</td>\n      <td>0.789823</td>\n      <td>0.786193</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024500</td>\n      <td>0.363216</td>\n      <td>0.720900</td>\n      <td>0.768053</td>\n      <td>0.794118</td>\n      <td>0.780868</td>\n      <td>0.772785</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024500</td>\n      <td>0.363246</td>\n      <td>0.722830</td>\n      <td>0.769231</td>\n      <td>0.799397</td>\n      <td>0.784024</td>\n      <td>0.777768</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.3007791042327881, 'eval_accuracy': 0.7389067524115756, 'eval_precision': 0.789865871833085, 'eval_recall': 0.799396681749623, 'eval_f1_micro': 0.7946026986506748, 'eval_f1_macro': 0.7876170210635971, 'eval_runtime': 7.0567, 'eval_samples_per_second': 220.359, 'eval_steps_per_second': 13.888, 'epoch': 10.0}\nSEED: 14\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:24, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.237338</td>\n      <td>0.702251</td>\n      <td>0.744286</td>\n      <td>0.785822</td>\n      <td>0.764490</td>\n      <td>0.754919</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.275300</td>\n      <td>0.219795</td>\n      <td>0.724759</td>\n      <td>0.778111</td>\n      <td>0.782805</td>\n      <td>0.780451</td>\n      <td>0.775790</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.184900</td>\n      <td>0.231293</td>\n      <td>0.722186</td>\n      <td>0.763326</td>\n      <td>0.809955</td>\n      <td>0.785950</td>\n      <td>0.778471</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.125000</td>\n      <td>0.256614</td>\n      <td>0.739550</td>\n      <td>0.790396</td>\n      <td>0.782051</td>\n      <td>0.786202</td>\n      <td>0.779264</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.125000</td>\n      <td>0.302691</td>\n      <td>0.715756</td>\n      <td>0.742088</td>\n      <td>0.831071</td>\n      <td>0.784063</td>\n      <td>0.780814</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.076800</td>\n      <td>0.314455</td>\n      <td>0.726688</td>\n      <td>0.784627</td>\n      <td>0.777526</td>\n      <td>0.781061</td>\n      <td>0.773463</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.047900</td>\n      <td>0.334512</td>\n      <td>0.720900</td>\n      <td>0.786482</td>\n      <td>0.772247</td>\n      <td>0.779300</td>\n      <td>0.773620</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.036000</td>\n      <td>0.366639</td>\n      <td>0.722830</td>\n      <td>0.776108</td>\n      <td>0.779035</td>\n      <td>0.777569</td>\n      <td>0.771326</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024400</td>\n      <td>0.377470</td>\n      <td>0.720900</td>\n      <td>0.757597</td>\n      <td>0.808446</td>\n      <td>0.782196</td>\n      <td>0.775919</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.024400</td>\n      <td>0.375527</td>\n      <td>0.721543</td>\n      <td>0.763043</td>\n      <td>0.794118</td>\n      <td>0.778271</td>\n      <td>0.771974</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.2566143870353699, 'eval_accuracy': 0.7395498392282959, 'eval_precision': 0.7903963414634146, 'eval_recall': 0.782051282051282, 'eval_f1_micro': 0.7862016679302501, 'eval_f1_macro': 0.7792638269925131, 'eval_runtime': 7.146, 'eval_samples_per_second': 217.603, 'eval_steps_per_second': 13.714, 'epoch': 10.0}\nSEED: 3\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:26, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.233712</td>\n      <td>0.705466</td>\n      <td>0.791632</td>\n      <td>0.713424</td>\n      <td>0.750496</td>\n      <td>0.740545</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.280200</td>\n      <td>0.219278</td>\n      <td>0.726688</td>\n      <td>0.798737</td>\n      <td>0.763198</td>\n      <td>0.780563</td>\n      <td>0.773438</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.180500</td>\n      <td>0.229409</td>\n      <td>0.731833</td>\n      <td>0.779661</td>\n      <td>0.797888</td>\n      <td>0.788669</td>\n      <td>0.783346</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.131000</td>\n      <td>0.259881</td>\n      <td>0.726045</td>\n      <td>0.799358</td>\n      <td>0.751131</td>\n      <td>0.774495</td>\n      <td>0.765872</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.131000</td>\n      <td>0.298851</td>\n      <td>0.713183</td>\n      <td>0.746086</td>\n      <td>0.826546</td>\n      <td>0.784258</td>\n      <td>0.783003</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.081200</td>\n      <td>0.323375</td>\n      <td>0.724116</td>\n      <td>0.749831</td>\n      <td>0.836350</td>\n      <td>0.790731</td>\n      <td>0.787797</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.052900</td>\n      <td>0.342007</td>\n      <td>0.717685</td>\n      <td>0.773543</td>\n      <td>0.780543</td>\n      <td>0.777027</td>\n      <td>0.771636</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.036300</td>\n      <td>0.368793</td>\n      <td>0.720900</td>\n      <td>0.767611</td>\n      <td>0.797134</td>\n      <td>0.782094</td>\n      <td>0.777438</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.026700</td>\n      <td>0.378145</td>\n      <td>0.720900</td>\n      <td>0.769565</td>\n      <td>0.800905</td>\n      <td>0.784922</td>\n      <td>0.781253</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.026700</td>\n      <td>0.379450</td>\n      <td>0.720257</td>\n      <td>0.775298</td>\n      <td>0.785822</td>\n      <td>0.780524</td>\n      <td>0.775717</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.3233751952648163, 'eval_accuracy': 0.7241157556270097, 'eval_precision': 0.7498309668695065, 'eval_recall': 0.8363499245852187, 'eval_f1_micro': 0.7907308377896612, 'eval_f1_macro': 0.7877973488660139, 'eval_runtime': 7.1825, 'eval_samples_per_second': 216.497, 'eval_steps_per_second': 13.644, 'epoch': 10.0}\nSEED: 94\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3890' max='3890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3890/3890 13:26, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Micro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.241316</td>\n      <td>0.691318</td>\n      <td>0.831028</td>\n      <td>0.634238</td>\n      <td>0.719418</td>\n      <td>0.689379</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.278500</td>\n      <td>0.219678</td>\n      <td>0.716399</td>\n      <td>0.774313</td>\n      <td>0.786576</td>\n      <td>0.780397</td>\n      <td>0.771237</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.183500</td>\n      <td>0.224486</td>\n      <td>0.734405</td>\n      <td>0.788129</td>\n      <td>0.791101</td>\n      <td>0.789612</td>\n      <td>0.787975</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.128200</td>\n      <td>0.258995</td>\n      <td>0.726045</td>\n      <td>0.799681</td>\n      <td>0.755656</td>\n      <td>0.777045</td>\n      <td>0.769373</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.128200</td>\n      <td>0.282576</td>\n      <td>0.722830</td>\n      <td>0.785011</td>\n      <td>0.782051</td>\n      <td>0.783529</td>\n      <td>0.779032</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.081300</td>\n      <td>0.305507</td>\n      <td>0.729904</td>\n      <td>0.784592</td>\n      <td>0.791101</td>\n      <td>0.787833</td>\n      <td>0.782683</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.051700</td>\n      <td>0.334984</td>\n      <td>0.720900</td>\n      <td>0.761636</td>\n      <td>0.814480</td>\n      <td>0.787172</td>\n      <td>0.783743</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.036800</td>\n      <td>0.351632</td>\n      <td>0.724116</td>\n      <td>0.761636</td>\n      <td>0.814480</td>\n      <td>0.787172</td>\n      <td>0.782429</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.025500</td>\n      <td>0.348661</td>\n      <td>0.726688</td>\n      <td>0.782934</td>\n      <td>0.788839</td>\n      <td>0.785875</td>\n      <td>0.782576</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.025500</td>\n      <td>0.360749</td>\n      <td>0.726688</td>\n      <td>0.775182</td>\n      <td>0.800905</td>\n      <td>0.787834</td>\n      <td>0.783174</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22448624670505524, 'eval_accuracy': 0.7344051446945338, 'eval_precision': 0.7881292261457551, 'eval_recall': 0.7911010558069381, 'eval_f1_micro': 0.7896123447497179, 'eval_f1_macro': 0.7879748706770465, 'eval_runtime': 7.1103, 'eval_samples_per_second': 218.696, 'eval_steps_per_second': 13.783, 'epoch': 10.0}\n","output_type":"stream"}],"execution_count":30}]}