{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63f39bc",
   "metadata": {
    "papermill": {
     "duration": 0.011169,
     "end_time": "2025-06-09T18:02:22.259801",
     "exception": false,
     "start_time": "2025-06-09T18:02:22.248632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32db8cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:22.281442Z",
     "iopub.status.busy": "2025-06-09T18:02:22.281104Z",
     "iopub.status.idle": "2025-06-09T18:02:45.072370Z",
     "shell.execute_reply": "2025-06-09T18:02:45.071485Z"
    },
    "papermill": {
     "duration": 22.803941,
     "end_time": "2025-06-09T18:02:45.073920",
     "exception": false,
     "start_time": "2025-06-09T18:02:22.269979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f36b6b",
   "metadata": {
    "papermill": {
     "duration": 0.009513,
     "end_time": "2025-06-09T18:02:45.093529",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.084016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f73aaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.113888Z",
     "iopub.status.busy": "2025-06-09T18:02:45.113401Z",
     "iopub.status.idle": "2025-06-09T18:02:45.116719Z",
     "shell.execute_reply": "2025-06-09T18:02:45.116116Z"
    },
    "papermill": {
     "duration": 0.014762,
     "end_time": "2025-06-09T18:02:45.117884",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.103122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712dc18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.138325Z",
     "iopub.status.busy": "2025-06-09T18:02:45.138055Z",
     "iopub.status.idle": "2025-06-09T18:02:45.141724Z",
     "shell.execute_reply": "2025-06-09T18:02:45.141070Z"
    },
    "papermill": {
     "duration": 0.015116,
     "end_time": "2025-06-09T18:02:45.142852",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.127736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4d7c29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.163241Z",
     "iopub.status.busy": "2025-06-09T18:02:45.163011Z",
     "iopub.status.idle": "2025-06-09T18:02:45.171307Z",
     "shell.execute_reply": "2025-06-09T18:02:45.170726Z"
    },
    "papermill": {
     "duration": 0.019596,
     "end_time": "2025-06-09T18:02:45.172511",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.152915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f0fd4b",
   "metadata": {
    "papermill": {
     "duration": 0.009264,
     "end_time": "2025-06-09T18:02:45.191425",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.182161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b87d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.211117Z",
     "iopub.status.busy": "2025-06-09T18:02:45.210917Z",
     "iopub.status.idle": "2025-06-09T18:02:45.262332Z",
     "shell.execute_reply": "2025-06-09T18:02:45.260887Z"
    },
    "papermill": {
     "duration": 0.062937,
     "end_time": "2025-06-09T18:02:45.263972",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.201035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-besra'\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "sequence_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7ba10",
   "metadata": {
    "papermill": {
     "duration": 0.009795,
     "end_time": "2025-06-09T18:02:45.283676",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.273881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64c900b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.304455Z",
     "iopub.status.busy": "2025-06-09T18:02:45.304158Z",
     "iopub.status.idle": "2025-06-09T18:02:45.418995Z",
     "shell.execute_reply": "2025-06-09T18:02:45.418252Z"
    },
    "papermill": {
     "duration": 0.127027,
     "end_time": "2025-06-09T18:02:45.420583",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.293556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctors-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a688d4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.449689Z",
     "iopub.status.busy": "2025-06-09T18:02:45.449432Z",
     "iopub.status.idle": "2025-06-09T18:02:45.467330Z",
     "shell.execute_reply": "2025-06-09T18:02:45.466034Z"
    },
    "papermill": {
     "duration": 0.034369,
     "end_time": "2025-06-09T18:02:45.468494",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.434125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bd4bdc",
   "metadata": {
    "papermill": {
     "duration": 0.011128,
     "end_time": "2025-06-09T18:02:45.490292",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.479164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5feaafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:45.512628Z",
     "iopub.status.busy": "2025-06-09T18:02:45.512410Z",
     "iopub.status.idle": "2025-06-09T18:02:46.461504Z",
     "shell.execute_reply": "2025-06-09T18:02:46.460669Z"
    },
    "papermill": {
     "duration": 0.962293,
     "end_time": "2025-06-09T18:02:46.462882",
     "exception": false,
     "start_time": "2025-06-09T18:02:45.500589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2923793f3ba54eb698c6b01044958c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d3b773ff8b42b4b6242a07eb48ea4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203ce05d64164462a8ad55c8715be676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7d5e3ab38848e38d1b975e12329dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8030bd70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.485439Z",
     "iopub.status.busy": "2025-06-09T18:02:46.485166Z",
     "iopub.status.idle": "2025-06-09T18:02:46.489448Z",
     "shell.execute_reply": "2025-06-09T18:02:46.488681Z"
    },
    "papermill": {
     "duration": 0.016695,
     "end_time": "2025-06-09T18:02:46.490664",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.473969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24553099",
   "metadata": {
    "papermill": {
     "duration": 0.011567,
     "end_time": "2025-06-09T18:02:46.512806",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.501239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70f2db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.534598Z",
     "iopub.status.busy": "2025-06-09T18:02:46.534362Z",
     "iopub.status.idle": "2025-06-09T18:02:46.537884Z",
     "shell.execute_reply": "2025-06-09T18:02:46.537156Z"
    },
    "papermill": {
     "duration": 0.015732,
     "end_time": "2025-06-09T18:02:46.539078",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.523346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d938eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.560758Z",
     "iopub.status.busy": "2025-06-09T18:02:46.560563Z",
     "iopub.status.idle": "2025-06-09T18:02:46.565008Z",
     "shell.execute_reply": "2025-06-09T18:02:46.564256Z"
    },
    "papermill": {
     "duration": 0.016565,
     "end_time": "2025-06-09T18:02:46.566304",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.549739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb86318a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.588687Z",
     "iopub.status.busy": "2025-06-09T18:02:46.588465Z",
     "iopub.status.idle": "2025-06-09T18:02:46.600661Z",
     "shell.execute_reply": "2025-06-09T18:02:46.600060Z"
    },
    "papermill": {
     "duration": 0.024965,
     "end_time": "2025-06-09T18:02:46.601766",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.576801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "\n",
    "            nearest_cp = current_train_size\n",
    "            if nearest_cp not in checkpoints:\n",
    "                for cp in checkpoints:\n",
    "                    if cp > current_train_size:\n",
    "                        nearest_cp = cp\n",
    "                        break\n",
    "            percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e34feb2",
   "metadata": {
    "papermill": {
     "duration": 0.010915,
     "end_time": "2025-06-09T18:02:46.623336",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.612421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d2a001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.645339Z",
     "iopub.status.busy": "2025-06-09T18:02:46.645099Z",
     "iopub.status.idle": "2025-06-09T18:02:46.650263Z",
     "shell.execute_reply": "2025-06-09T18:02:46.649486Z"
    },
    "papermill": {
     "duration": 0.017404,
     "end_time": "2025-06-09T18:02:46.651418",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.634014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8443a3",
   "metadata": {
    "papermill": {
     "duration": 0.010376,
     "end_time": "2025-06-09T18:02:46.672405",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.662029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_score(predicted_prob_one, true_outcome, alpha_param=0.1, beta_param=3.0):\n",
    "    epsilon = 1e-9\n",
    "    safe_prob = np.clip(predicted_prob_one, epsilon, 1.0 - epsilon)\n",
    "\n",
    "    if true_outcome == 1:\n",
    "        # Arguments for the betaln function when the true outcome is 1\n",
    "        arg1 = alpha_param\n",
    "        arg2 = beta_param + 1\n",
    "        arg3 = alpha_param + safe_prob\n",
    "        arg4 = beta_param + 1 - safe_prob\n",
    "        if not (arg1 > 0 and arg2 > 0 and arg3 > 0 and arg4 > 0):\n",
    "            return -1e9\n",
    "        return -betaln(arg1, arg2) + betaln(arg3, arg4)\n",
    "    elif true_outcome == 0:\n",
    "        # Arguments for the betaln function when the true outcome is 0\n",
    "        arg1 = alpha_param + 1\n",
    "        arg2 = beta_param\n",
    "        arg3 = alpha_param + 1 - safe_prob\n",
    "        arg4 = beta_param + safe_prob\n",
    "        if not (arg1 > 0 and arg2 > 0 and arg3 > 0 and arg4 > 0):\n",
    "            return -1e9\n",
    "        return -betaln(arg1, arg2) + betaln(arg3, arg4)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: true_outcome must be 0 or 1.\")\n",
    "\n",
    "def calculate_expected_beta_score(predicted_prob_one, alpha_param, beta_param):\n",
    "    score_if_one = beta_score(predicted_prob_one, 1, alpha_param, beta_param)\n",
    "    score_if_zero = beta_score(predicted_prob_one, 0, alpha_param, beta_param)\n",
    "    \n",
    "    expected_score = predicted_prob_one * score_if_one + (1.0 - predicted_prob_one) * score_if_zero\n",
    "    return expected_score\n",
    "\n",
    "def get_ensemble_predictions_for_batch(ensemble_models, input_ids, attention_mask, device):\n",
    "    individual_model_probs_list = []\n",
    "    with torch.no_grad():\n",
    "        for model_instance in ensemble_models:\n",
    "            model_instance.eval()\n",
    "            model_instance.to(device)\n",
    "            outputs = model_instance(input_ids.to(device), attention_mask=attention_mask.to(device))\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            individual_model_probs_list.append(probs)\n",
    "\n",
    "        if not individual_model_probs_list:\n",
    "            return torch.empty(0, device=device), []\n",
    "\n",
    "        individual_probs_tensor = torch.stack(individual_model_probs_list)\n",
    "        average_probs = torch.mean(individual_probs_tensor, dim=0)\n",
    "\n",
    "    return average_probs, individual_model_probs_list\n",
    "\n",
    "def besra_sampling(\n",
    "    ensemble_models,\n",
    "    unlabeled_data,\n",
    "    train_indices,\n",
    "    remaining_indices,\n",
    "    estimation_data,\n",
    "    tokenizer,\n",
    "    num_classes,\n",
    "    sampling_dur,\n",
    "    new_samples,\n",
    "    trials,\n",
    "    alpha_param=0.1,\n",
    "    beta_param=3.0,\n",
    "    n_clusters=min_increment,\n",
    "):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    unlabeled_dataset = NetifierDataset(unlabeled_data,\n",
    "                                        np.zeros((len(unlabeled_data), num_classes)),\n",
    "                                        tokenizer,\n",
    "                                        max_length=sequence_length) \n",
    "    unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=batch_size, num_workers=4, pin_memory=True) \n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "\n",
    "    estimation_dataset = NetifierDataset(estimation_data,\n",
    "                                        np.zeros((len(estimation_data), num_classes)),\n",
    "                                        tokenizer,\n",
    "                                        max_length=sequence_length) # sequence_length\n",
    "    estimation_dataloader = DataLoader(estimation_dataset, batch_size=len(estimation_dataset), num_workers=4, pin_memory=True)\n",
    "    estimation_dataloader, unlabeled_dataloader = accelerator.prepare(estimation_dataloader, unlabeled_dataloader)\n",
    "\n",
    "    for model in ensemble_models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "    start_time = time.time()\n",
    "    candidate_scores = []\n",
    "    all_estimation_avg_probs = []\n",
    "    all_estimation_individual_probs_by_model = []\n",
    "    all_candidate_avg_probs = []\n",
    "    all_candidate_individual_probs_by_model = []\n",
    "\n",
    "    # Pre compute predictions for all estimation and candidate samples\n",
    "    for est_batch in estimation_dataloader:\n",
    "        est_input_ids = est_batch['input_ids']\n",
    "        est_attention_mask = est_batch['attention_mask']\n",
    "        est_avg_probs_batch, est_indiv_probs_batch = get_ensemble_predictions_for_batch(ensemble_models, est_input_ids, est_attention_mask, device)\n",
    "        all_estimation_avg_probs.append(accelerator.gather_for_metrics(est_avg_probs_batch))\n",
    "\n",
    "        if not all_estimation_individual_probs_by_model:\n",
    "            all_estimation_individual_probs_by_model = [[] for _ in est_indiv_probs_batch]\n",
    "        for model_idx, probs in enumerate(est_indiv_probs_batch):\n",
    "            all_estimation_individual_probs_by_model[model_idx].append(accelerator.gather_for_metrics(probs))\n",
    "\n",
    "    for cand_batch in unlabeled_dataloader:\n",
    "        cand_input_ids = cand_batch['input_ids']\n",
    "        cand_attention_mask = cand_batch['attention_mask']\n",
    "        cand_avg_probs_batch, cand_indiv_probs_batch = get_ensemble_predictions_for_batch(ensemble_models, cand_input_ids, cand_attention_mask, device)\n",
    "        all_candidate_avg_probs.append(accelerator.gather_for_metrics(cand_avg_probs_batch))\n",
    "\n",
    "        if not all_candidate_individual_probs_by_model:\n",
    "             all_candidate_individual_probs_by_model = [[] for _ in cand_indiv_probs_batch]\n",
    "        for model_idx, probs in enumerate(cand_indiv_probs_batch):\n",
    "            all_candidate_individual_probs_by_model[model_idx].append(accelerator.gather_for_metrics(probs))\n",
    "\n",
    "    # Concatenate all batch predictions into single tensors\n",
    "    all_estimation_avg_probs = torch.cat(all_estimation_avg_probs, dim=0)\n",
    "    all_estimation_individual_probs = [torch.cat(model_probs, dim=0) for model_probs in all_estimation_individual_probs_by_model]\n",
    "    all_candidate_avg_probs = torch.cat(all_candidate_avg_probs, dim=0)\n",
    "    all_candidate_individual_probs = [torch.cat(model_probs, dim=0) for model_probs in all_candidate_individual_probs_by_model]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    # Score change calculation\n",
    "    for candidate_index in range(len(all_candidate_avg_probs)):\n",
    "        candidate_avg_probs_for_sample = all_candidate_avg_probs[candidate_index]\n",
    "        candidate_individual_probs_for_sample = [m_probs[candidate_index] for m_probs in all_candidate_individual_probs]\n",
    "        candidate_delta_q_score = 0.0\n",
    "\n",
    "        for estimation_index in range(len(all_estimation_avg_probs)):\n",
    "            estimation_avg_probs_for_sample = all_estimation_avg_probs[estimation_index]\n",
    "            estimation_individual_probs_for_sample = [m_probs[estimation_index] for m_probs in all_estimation_individual_probs]\n",
    "\n",
    "            # Calculate the initial expected score on the estimation sample before any update\n",
    "            initial_expected_score_on_estimation_sample = 0.0\n",
    "            for estimation_class_index in range(num_classes):\n",
    "                prob_one_avg_for_est_class = estimation_avg_probs_for_sample[estimation_class_index].item()\n",
    "                initial_expected_score_on_estimation_sample += calculate_expected_beta_score(prob_one_avg_for_est_class, alpha_param, beta_param)\n",
    "\n",
    "            delta_q_for_one_estimation_sample = 0.0\n",
    "            for candidate_class_index in range(num_classes):\n",
    "                expected_score_after_update = 0.0\n",
    "                for hypothetical_candidate_label in [0, 1]:\n",
    "                    prob_one_avg_for_candidate_class = candidate_avg_probs_for_sample[candidate_class_index].item()\n",
    "                    prob_of_hypothetical_label_avg = prob_one_avg_for_candidate_class if hypothetical_candidate_label == 1 else (1.0 - prob_one_avg_for_candidate_class)\n",
    "\n",
    "                    # Bayesian Update by model reweighting\n",
    "                    model_weights = []\n",
    "                    for model_index in range(len(ensemble_models)):\n",
    "                        prob_one_individual_for_candidate_class = candidate_individual_probs_for_sample[model_index][candidate_class_index].item()\n",
    "                        prob_of_hypothetical_label_individual = prob_one_individual_for_candidate_class if hypothetical_candidate_label == 1 else (1.0 - prob_one_individual_for_candidate_class)\n",
    "                        model_weights.append(prob_of_hypothetical_label_individual)\n",
    "\n",
    "                    sum_model_weights = sum(model_weights)\n",
    "                    if sum_model_weights < 1e-9:\n",
    "                        normalized_model_weights = [1.0 / len(ensemble_models)] * len(ensemble_models)\n",
    "                    else:\n",
    "                        normalized_model_weights = [w / sum_model_weights for w in model_weights]\n",
    "\n",
    "                    reweighted_prob_one_for_est_class = 0.0\n",
    "\n",
    "                    # Reweight the individual model probabilities for the candidate class\n",
    "                    for model_index in range(len(ensemble_models)):\n",
    "                        prob_one_individual_for_est_class = estimation_individual_probs_for_sample[model_index][candidate_class_index].item()\n",
    "                        reweighted_prob_one_for_est_class += normalized_model_weights[model_index] * prob_one_individual_for_est_class\n",
    "\n",
    "                    # Calculate new scores\n",
    "                    updated_expected_score_on_estimation_sample = calculate_expected_beta_score(reweighted_prob_one_for_est_class, alpha_param, beta_param)\n",
    "                    expected_score_after_update += prob_of_hypothetical_label_avg * updated_expected_score_on_estimation_sample\n",
    "\n",
    "                delta_q_for_one_estimation_sample += (expected_score_after_update - initial_expected_score_on_estimation_sample)\n",
    "            candidate_delta_q_score += delta_q_for_one_estimation_sample\n",
    "        candidate_scores.append(candidate_delta_q_score)\n",
    "                \n",
    "    # K-Means Clustering and Selection\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        candidate_scores = np.array(candidate_scores)\n",
    "        candidate_scores = candidate_scores.reshape(-1, 1)\n",
    "    \n",
    "        accelerator.print(f\"BESRA Uncertainty Score Threshold {np.percentile(candidate_scores, 90)}\")\n",
    "    \n",
    "        target_samples = math.ceil(0.1 * len(unlabeled_data)) \n",
    "        collected_indices = set()\n",
    "        thresholds = []\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "    \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "    \n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "    \n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(candidate_scores)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(candidate_scores[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "    \n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    '1-FR': [y_train[i][0] for i in temp],\n",
    "                    '2-GI': [y_train[i][1] for i in temp],\n",
    "                    '3-PI': [y_train[i][2] for i in temp],\n",
    "                    '4-DM': [y_train[i][3] for i in temp],\n",
    "                    '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                    '6-RE': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            # print(f\"Thresholds: {thresholds}\")\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "    \n",
    "            # threshold_data = pd.DataFrame({\n",
    "            #     'Threshold': thresholds\n",
    "            # })\n",
    "            # threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fb7f5",
   "metadata": {
    "papermill": {
     "duration": 0.010378,
     "end_time": "2025-06-09T18:02:46.740892",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.730514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ae1e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.762835Z",
     "iopub.status.busy": "2025-06-09T18:02:46.762631Z",
     "iopub.status.idle": "2025-06-09T18:02:46.773368Z",
     "shell.execute_reply": "2025-06-09T18:02:46.772739Z"
    },
    "papermill": {
     "duration": 0.023102,
     "end_time": "2025-06-09T18:02:46.774537",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.751435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(model_accuracies), 4)}, F1 Micro: {round(np.mean(model_f1_micros), 4)}, F1 Macro: {round(np.mean(model_f1_macros), 4)}\")\n",
    "\n",
    "        nearest_cp = current_train_size\n",
    "        if nearest_cp not in checkpoints:\n",
    "            for cp in checkpoints:\n",
    "                if cp > current_train_size:\n",
    "                    nearest_cp = cp\n",
    "                    break\n",
    "        percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "        \n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            # model = BertForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p2', num_labels=6, problem_type='multi_label_classification')\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}-{percentage}')\n",
    "            models.append(model)\n",
    "        \n",
    "        # Perform query strategy to select new samples\n",
    "        estimation_pool_indices = np.random.choice(remaining_indices, size=min(8, math.ceil(0.1 * len(remaining_indices))), replace=False).tolist()\n",
    "        estimation_pool_data = [X_train[i] for i in estimation_pool_indices]\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            models, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            estimation_pool_data,\n",
    "            tokenizer, \n",
    "            6,\n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(model_accuracies), 4)}, F1 Micro: {round(np.mean(model_f1_micros), 4)}, F1 Macro: {round(np.mean(model_f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6c2b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.796306Z",
     "iopub.status.busy": "2025-06-09T18:02:46.796075Z",
     "iopub.status.idle": "2025-06-09T18:02:46.799283Z",
     "shell.execute_reply": "2025-06-09T18:02:46.798681Z"
    },
    "papermill": {
     "duration": 0.015409,
     "end_time": "2025-06-09T18:02:46.800475",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.785066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [[50, 67, 42], [81, 90, 11], [14, 7, 33], [3, 44, 85], [94, 21, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef0580f",
   "metadata": {
    "papermill": {
     "duration": 0.010454,
     "end_time": "2025-06-09T18:02:46.821620",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.811166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.615, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2856, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2022, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1279, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2059, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2131, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1384, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0898, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.893277645111084 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6337, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3845, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.301, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2196, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1882, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2195, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2409, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1562, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1024, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.59402561187744 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5833, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3269, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2131, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2275, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1403, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.89524579048157 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 463.9964139061849\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 15.734721183776855 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.483, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2523, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1753, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1346, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1421, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1524, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0996, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 46.24887943267822 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5206, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.277, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2006, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1834, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1424, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1634, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1142, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1259, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 46.86585712432861 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2468, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1876, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1425, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1333, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1583, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1711, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1102, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1169, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 47.08794975280762 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 489.0876915856023\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.930206775665283 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4259, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1887, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1532, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1252, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1213, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1008, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1005, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0813, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.535579442977905 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4454, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1334, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1314, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1115, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1073, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 52.645182609558105 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3984, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1505, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1238, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1033, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1028, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0752, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.2392373085022 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 500.96431292164715\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 14.08792519569397 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2013, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9551, F1 Micro: 0.9658, F1 Macro: 0.6489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1048, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Epoch 9/10, Train Loss: 0.0935, Accuracy: 0.9535, F1 Micro: 0.9649, F1 Macro: 0.6881\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Model 1 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 50.31070113182068 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4016, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2339, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1957, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2051, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1659, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1825, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.152, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1209, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1018, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7087\n",
      "Model 2 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.70      0.71       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 56.56966972351074 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2276, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2032, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1798, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1446, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1054, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6523\n",
      "Model 3 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.675798654556274 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.671\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 501.90094159194615\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.680832386016846 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3362, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1736, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7621\n",
      "Model 1 - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.80      0.75      0.76       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 61.21383833885193 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3587, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1827, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1705, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1338, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.1285, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0841, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6539\n",
      "Model 2 - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.03278470039368 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3156, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1879, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1118, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7072\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7089\n",
      "Model 3 - Iteration 156: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.71      0.71       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 61.95708179473877 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9621, F1 Micro: 0.9711, F1 Macro: 0.7083\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 511.17059729208165\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.499192953109741 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3525, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1758, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Epoch 8/10, Train Loss: 0.0776, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0497, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0548, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Model 1 - Iteration 181: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 64.11534690856934 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3604, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1821, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1342, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Epoch 8/10, Train Loss: 0.0966, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6957\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 10/10, Train Loss: 0.0562, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Model 2 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.94      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 62.31234169006348 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3287, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1783, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1788, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1297, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7079\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Model 3 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.566938400268555 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.675\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 474.4832918848841\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.584110736846924 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3109, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1758, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1379, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6512\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0629, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9535, F1 Micro: 0.9647, F1 Macro: 0.6965\n",
      "Epoch 10/10, Train Loss: 0.0432, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Model 1 - Iteration 203: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.97      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.73       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 67.06402349472046 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3274, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1845, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0855, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 10/10, Train Loss: 0.0505, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7331\n",
      "Model 2 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.88071298599243 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2974, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1794, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1712, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.65\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.7059\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6522\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7055\n",
      "Model 3 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 64.1708333492279 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7028\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 476.91309989181576\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.478517532348633 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2878, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1565, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1375, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.7127\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Model 1 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 67.81235361099243 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3108, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1569, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7201\n",
      "Epoch 8/10, Train Loss: 0.0695, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7172\n",
      "Model 2 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.93      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.97      0.97       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 69.92066025733948 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2821, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1753, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.14, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6517\n",
      "Epoch 8/10, Train Loss: 0.0674, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7079\n",
      "Model 3 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 67.69938278198242 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9658, F1 Micro: 0.9737, F1 Macro: 0.6983\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 497.89143046093386\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.803831815719604 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3035, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1842, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.119, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1033, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7334\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Model 1 - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 75.7359607219696 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3162, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1864, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7258\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 10/10, Train Loss: 0.0466, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Model 2 - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.68851327896118 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.182, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1911, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1652, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1125, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 6/10, Train Loss: 0.0927, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.699\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.699\n",
      "Epoch 8/10, Train Loss: 0.0518, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7179\n",
      "Epoch 9/10, Train Loss: 0.0441, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.699\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Model 3 - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.54085397720337 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 504.80918302188985\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.114365100860596 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2975, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2014, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1545, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9487, F1 Micro: 0.9614, F1 Macro: 0.7166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0711, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7254\n",
      "Epoch 9/10, Train Loss: 0.0482, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7136\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7196\n",
      "Model 1 - Iteration 250: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.60335326194763 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3122, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2033, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7381\n",
      "Epoch 7/10, Train Loss: 0.0879, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.6982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0759, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 9/10, Train Loss: 0.0492, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Model 2 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 76.21618342399597 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2887, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2041, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 6/10, Train Loss: 0.1001, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 7/10, Train Loss: 0.075, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7355\n",
      "Epoch 9/10, Train Loss: 0.0468, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Model 3 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.74      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.44730925559998 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9642, F1 Micro: 0.9726, F1 Macro: 0.7456\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 515.4125113663806\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.600776195526123 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3009, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1415, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.0798, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7189\n",
      "Epoch 7/10, Train Loss: 0.0809, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7355\n",
      "Epoch 9/10, Train Loss: 0.0445, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Model 1 - Iteration 265: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 78.67612791061401 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3057, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Epoch 8/10, Train Loss: 0.0557, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0463, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Model 2 - Iteration 265: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.48257851600647 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2897, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1787, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1557, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1276, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 6/10, Train Loss: 0.0704, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7175\n",
      "Epoch 7/10, Train Loss: 0.0788, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7159\n",
      "Epoch 8/10, Train Loss: 0.0536, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7344\n",
      "Epoch 9/10, Train Loss: 0.0453, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.7251\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Model 3 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.68493723869324 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7183\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 492.33445480779216\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.96293044090271 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2823, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 5/10, Train Loss: 0.1105, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Epoch 10/10, Train Loss: 0.0398, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7182\n",
      "Model 1 - Iteration 279: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 75.87333726882935 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2992, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1912, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1014, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 9/10, Train Loss: 0.0452, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0406, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Model 2 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.92371344566345 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.273, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1055, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 7/10, Train Loss: 0.0674, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.718\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Model 3 - Iteration 279: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.58283615112305 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9637, F1 Micro: 0.9723, F1 Macro: 0.7558\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 522.2892563260344\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.138201713562012 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2941, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.168, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1411, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0808, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0677, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 9/10, Train Loss: 0.0445, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.7284\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7087\n",
      "Model 1 - Iteration 292: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.26750946044922 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.305, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1587, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0855, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.052, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Model 2 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.58614206314087 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2887, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1394, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1183, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7481\n",
      "Epoch 6/10, Train Loss: 0.0769, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7337\n",
      "Epoch 7/10, Train Loss: 0.0663, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7331\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 9/10, Train Loss: 0.0425, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6974\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7339\n",
      "Model 3 - Iteration 292: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.76      0.74      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.01406121253967 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7504\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 494.6547163954902\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.103180408477783 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1705, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Epoch 6/10, Train Loss: 0.0822, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7248\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.7175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7261\n",
      "Epoch 9/10, Train Loss: 0.0381, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7256\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7256\n",
      "Model 1 - Iteration 300: Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.74      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.96096420288086 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2877, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1736, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9503, F1 Micro: 0.9628, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0639, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0546, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Model 2 - Iteration 300: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.35084819793701 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2665, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1721, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.1116, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Epoch 6/10, Train Loss: 0.0807, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7882\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 3 - Iteration 300: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.31332492828369 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9626, F1 Micro: 0.9715, F1 Macro: 0.7694\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 533.5122953733816\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.431124687194824 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2854, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1425, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 6/10, Train Loss: 0.0813, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7418\n",
      "Epoch 7/10, Train Loss: 0.0522, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7548\n",
      "Model 1 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.7016110420227 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2932, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1703, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1542, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1342, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0525, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Epoch 9/10, Train Loss: 0.0458, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Epoch 10/10, Train Loss: 0.032, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Model 2 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.07327222824097 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.276, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6505\n",
      "Epoch 6/10, Train Loss: 0.075, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7352\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 10/10, Train Loss: 0.0311, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.8015\n",
      "Model 3 - Iteration 310: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.57157254219055 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7376\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 506.45592676896126\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.531407594680786 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7334\n",
      "Epoch 5/10, Train Loss: 0.104, Accuracy: 0.9519, F1 Micro: 0.9639, F1 Macro: 0.727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0848, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.719\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7438\n",
      "Epoch 9/10, Train Loss: 0.0375, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Model 1 - Iteration 320: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.2701063156128 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2774, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0546, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0481, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Model 2 - Iteration 320: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.79719066619873 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2587, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1802, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1597, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 5/10, Train Loss: 0.1016, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.752\n",
      "Epoch 7/10, Train Loss: 0.0574, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7406\n",
      "Epoch 8/10, Train Loss: 0.0507, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Epoch 10/10, Train Loss: 0.0356, Accuracy: 0.9535, F1 Micro: 0.9647, F1 Macro: 0.6965\n",
      "Model 3 - Iteration 320: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.78      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.22212171554565 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7666\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 516.1823430290025\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.907162666320801 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2616, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1712, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1511, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 5/10, Train Loss: 0.1037, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7177\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.7238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0643, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7855\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.718\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7911\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7174\n",
      "Model 1 - Iteration 330: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.39410090446472 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1538, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0891, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0669, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "Epoch 8/10, Train Loss: 0.0438, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0386, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "Model 2 - Iteration 330: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 91.13414263725281 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2561, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1706, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1285, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1007, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Epoch 7/10, Train Loss: 0.0545, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7839\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7849\n",
      "Model 3 - Iteration 330: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 87.4968147277832 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7953\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 435.1720880759766\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.70711350440979 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1436, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 5/10, Train Loss: 0.1028, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7155\n",
      "Epoch 6/10, Train Loss: 0.0752, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7278\n",
      "Epoch 7/10, Train Loss: 0.0619, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Epoch 8/10, Train Loss: 0.0458, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Model 1 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.12253713607788 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1741, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1501, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1069, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0754, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8066\n",
      "Epoch 8/10, Train Loss: 0.0426, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7214\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8213\n",
      "Epoch 10/10, Train Loss: 0.0292, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8056\n",
      "Model 2 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 91.97752809524536 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1712, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1611, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0721, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0541, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "Epoch 9/10, Train Loss: 0.0366, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8018\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8032\n",
      "Model 3 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.14355444908142 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9685, F1 Micro: 0.9759, F1 Macro: 0.761\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 378.59787666663993\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.1035706996917725 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2521, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1132, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 5/10, Train Loss: 0.0818, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Epoch 6/10, Train Loss: 0.0625, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7128\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Epoch 9/10, Train Loss: 0.0342, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7945\n",
      "Model 1 - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.29472732543945 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2589, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.162, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1821, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1317, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0901, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 6/10, Train Loss: 0.0658, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0654, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8012\n",
      "Model 2 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.74      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 93.52069234848022 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2414, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1604, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1276, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7196\n",
      "Epoch 5/10, Train Loss: 0.0859, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0608, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7383\n",
      "Epoch 7/10, Train Loss: 0.0606, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7034\n",
      "Epoch 10/10, Train Loss: 0.029, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7668\n",
      "Model 3 - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.70      0.70      0.70       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.50295925140381 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9669, F1 Micro: 0.9746, F1 Macro: 0.7355\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 319.63316534490536\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.4365551471710205 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2602, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1818, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1239, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0948, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7459\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7278\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7694\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Model 1 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.16153573989868 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1792, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1335, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1049, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7678\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7139\n",
      "Epoch 7/10, Train Loss: 0.0609, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 2 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.99      0.98       406\n",
      "\n",
      "Training completed in 91.24163341522217 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1795, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1563, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1277, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 5/10, Train Loss: 0.0981, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 6/10, Train Loss: 0.0661, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0541, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Model 3 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.75448989868164 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.7776\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 261.105027743092\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.049846887588501 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2483, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.181, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1518, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1339, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1007, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0736, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0407, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8168\n",
      "Epoch 9/10, Train Loss: 0.0313, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8435\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8442\n",
      "Model 1 - Iteration 370: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.93      0.79      0.82       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 95.94435405731201 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2537, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.777\n",
      "Epoch 7/10, Train Loss: 0.0523, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8167\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "Model 2 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 99.20664358139038 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2371, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 5/10, Train Loss: 0.0932, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 6/10, Train Loss: 0.0652, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 8/10, Train Loss: 0.0368, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7931\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7941\n",
      "Model 3 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 91.18850517272949 s\n",
      "Averaged - Iteration 370: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.7462\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 193.33430264474893\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.576737642288208 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.251, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1614, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1288, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0679, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7107\n",
      "Epoch 7/10, Train Loss: 0.0571, Accuracy: 0.9551, F1 Micro: 0.9656, F1 Macro: 0.7931\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Epoch 9/10, Train Loss: 0.0321, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8113\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.785\n",
      "Model 1 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.71      0.71       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 97.81491494178772 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.087, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.738\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0535, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8206\n",
      "Epoch 10/10, Train Loss: 0.0314, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7318\n",
      "Model 2 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 99.81205725669861 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2432, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.162, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1247, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "Epoch 5/10, Train Loss: 0.0847, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.7246\n",
      "Epoch 6/10, Train Loss: 0.0602, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0532, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8311\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Model 3 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 98.04431986808777 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.785\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 132.0794372757175\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0539064407348633 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2544, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1554, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1363, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 4/10, Train Loss: 0.1153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.0916, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7224\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0614, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.051, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7346\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8051\n",
      "Model 1 - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.89      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 101.86910796165466 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2634, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1358, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1114, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Epoch 5/10, Train Loss: 0.0891, Accuracy: 0.9519, F1 Micro: 0.9639, F1 Macro: 0.7097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0502, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7381\n",
      "Epoch 8/10, Train Loss: 0.047, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.792\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7871\n",
      "Model 2 - Iteration 390: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 99.39139819145203 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2481, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1347, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1192, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.089, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0485, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7217\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7217\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7867\n",
      "Model 3 - Iteration 390: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.70      0.75      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 102.17826271057129 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.755\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 65.96109086121956\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7071499824523926 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2405, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1502, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1467, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0845, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0675, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7309\n",
      "Epoch 7/10, Train Loss: 0.0604, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7867\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Model 1 - Iteration 400: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 104.00786209106445 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2482, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1511, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1509, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0877, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 6/10, Train Loss: 0.066, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7658\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0346, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Model 2 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 100.71981883049011 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2301, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1482, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0822, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Epoch 6/10, Train Loss: 0.0574, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 7/10, Train Loss: 0.0505, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7936\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0281, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Model 3 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 101.47410416603088 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9669, F1 Micro: 0.9747, F1 Macro: 0.7934\n",
      "Total sampling time: 173.22 seconds\n",
      "Total runtime: 5979.797975063324 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426171e",
   "metadata": {
    "papermill": {
     "duration": 0.010588,
     "end_time": "2025-06-09T18:02:46.868824",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.858236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ddff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 2\n",
      "Random seed: [81, 90, 11]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2902, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1712, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1268, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2056, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2181, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1398, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 37.58194661140442 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5962, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2089, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2205, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.139, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0885, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.211053133010864 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3321, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1752, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2191, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2272, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.145, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0942, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.88227987289429 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 466.11103747209154\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 15.868785619735718 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4783, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1855, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1284, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.092, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.089, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.98544931411743 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.446, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2404, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1642, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1815, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1215, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1257, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1466, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0895, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0829, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.05751633644104 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4361, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2497, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1824, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1337, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1548, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0948, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0949, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.84063506126404 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 489.22060156549026\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.508080959320068 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4135, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1498, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1338, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1105, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.64849805831909 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3831, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2409, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1657, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1342, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1107, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 9/10, Train Loss: 0.0876, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0714, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 46.74107480049133 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3818, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1391, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9519, F1 Micro: 0.9636, F1 Macro: 0.6869\n",
      "Epoch 10/10, Train Loss: 0.0697, Accuracy: 0.9535, F1 Micro: 0.9646, F1 Macro: 0.6489\n",
      "Model 3 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 47.314199447631836 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 503.3621972424906\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.661535739898682 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3616, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1952, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1917, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1844, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1372, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1334, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1035, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.6496\n",
      "Epoch 9/10, Train Loss: 0.0959, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 10/10, Train Loss: 0.068, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 1 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.75359606742859 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3297, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1316, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.1256, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 8/10, Train Loss: 0.1077, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 10/10, Train Loss: 0.0806, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.6486\n",
      "Model 2 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.391239404678345 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3318, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1939, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1986, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1869, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1457, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1125, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 9/10, Train Loss: 0.0966, Accuracy: 0.9551, F1 Micro: 0.9658, F1 Macro: 0.6489\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9551, F1 Micro: 0.9658, F1 Macro: 0.6489\n",
      "Model 3 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.97      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.120468854904175 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6516\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 500.06911802870906\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.912551164627075 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3421, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1709, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1721, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1803, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1444, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7637\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7618\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Model 1 - Iteration 156: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.74      0.79      0.76       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 56.56067109107971 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3149, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1678, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1403, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.1144, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.6556\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 9/10, Train Loss: 0.0725, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 10/10, Train Loss: 0.0543, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Model 2 - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.6556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.97      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.24689960479736 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3205, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1118, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Model 3 - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 55.11294460296631 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9642, F1 Micro: 0.9727, F1 Macro: 0.6907\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 498.33022685912715\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.471185684204102 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3281, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1745, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 8/10, Train Loss: 0.068, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7186\n",
      "Epoch 9/10, Train Loss: 0.0517, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 10/10, Train Loss: 0.0381, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Model 1 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.09882354736328 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3068, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1449, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1364, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 8/10, Train Loss: 0.0752, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0537, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0424, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Model 2 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 59.24329233169556 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3088, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1742, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1489, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1373, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 7/10, Train Loss: 0.1181, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.717\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Model 3 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 57.4416766166687 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.6985\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 493.73108525407497\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.300514698028564 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3075, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2026, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 6/10, Train Loss: 0.1134, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Epoch 8/10, Train Loss: 0.0588, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7261\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Epoch 10/10, Train Loss: 0.0378, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8183\n",
      "Model 1 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.62128138542175 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2833, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1984, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1853, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.149, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0948, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Epoch 9/10, Train Loss: 0.041, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7104\n",
      "Epoch 10/10, Train Loss: 0.0386, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7755\n",
      "Model 2 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.36354446411133 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2914, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.203, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1873, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 8/10, Train Loss: 0.0693, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7831\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.766\n",
      "Model 3 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 62.915605545043945 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 506.20141609106304\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.463762521743774 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3095, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1224, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7382\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6995\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8198\n",
      "Model 1 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 64.40567660331726 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2903, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1903, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.6566\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7259\n",
      "Epoch 9/10, Train Loss: 0.0446, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7798\n",
      "Model 2 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.54728507995605 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2951, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1953, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1476, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1264, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7852\n",
      "Epoch 10/10, Train Loss: 0.0411, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7614\n",
      "Model 3 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.00520038604736 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.7735\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 516.5081769871597\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.820281744003296 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2992, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1673, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Epoch 7/10, Train Loss: 0.0852, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0418, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8143\n",
      "Epoch 9/10, Train Loss: 0.0367, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.806\n",
      "Model 1 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 71.5446572303772 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2802, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Epoch 7/10, Train Loss: 0.0908, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0418, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8162\n",
      "Model 2 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.92      0.79      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 74.88661098480225 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.285, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1621, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6957\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0436, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7958\n",
      "Model 3 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 71.40351176261902 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.806\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 530.2113950226802\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 7.8874194622039795 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2842, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2065, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1603, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0503, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8327\n",
      "Epoch 9/10, Train Loss: 0.044, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8319\n",
      "Model 1 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.49103283882141 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2056, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1425, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.6556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0697, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7816\n",
      "Epoch 8/10, Train Loss: 0.0574, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.787\n",
      "Epoch 9/10, Train Loss: 0.0458, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "Model 2 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.78      0.79      0.78       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 73.00248527526855 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2699, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.206, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1692, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.155, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 6/10, Train Loss: 0.1279, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7749\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7845\n",
      "Epoch 9/10, Train Loss: 0.0466, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7837\n",
      "Epoch 10/10, Train Loss: 0.0398, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Model 3 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 69.66065216064453 s\n",
      "Averaged - Iteration 250: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.756\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 500.82676292225227\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.668088912963867 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2872, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Epoch 6/10, Train Loss: 0.0916, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 7/10, Train Loss: 0.0602, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8051\n",
      "Epoch 8/10, Train Loss: 0.0435, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8447\n",
      "Model 1 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.94      0.83      0.84       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.40118861198425 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2705, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1781, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1161, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 7/10, Train Loss: 0.0706, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7953\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.8484\n",
      "Model 2 - Iteration 265: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.8484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 75.68955302238464 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2694, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1787, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Epoch 7/10, Train Loss: 0.0685, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.7737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0558, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8305\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "Model 3 - Iteration 265: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 76.11926531791687 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.8416\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 524.8579841229549\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.0508873462677 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2931, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2051, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1513, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6526\n",
      "Epoch 5/10, Train Loss: 0.1163, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7533\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "Epoch 9/10, Train Loss: 0.0434, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0345, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8039\n",
      "Model 1 - Iteration 279: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 75.45927929878235 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2757, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2062, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1237, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8124\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8134\n",
      "Model 2 - Iteration 279: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 76.44671773910522 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2842, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2092, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1801, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1652, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.1392, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7675\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.7995\n",
      "Epoch 8/10, Train Loss: 0.0544, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0471, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8303\n",
      "Model 3 - Iteration 279: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.74      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 75.46955013275146 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.804\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 504.6000840540461\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.493014097213745 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2832, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1876, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1846, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1151, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7694\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.786\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7684\n",
      "Epoch 9/10, Train Loss: 0.0403, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8099\n",
      "Epoch 10/10, Train Loss: 0.0272, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8119\n",
      "Model 1 - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 80.10236501693726 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2682, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1875, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1511, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1209, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0692, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Epoch 9/10, Train Loss: 0.0439, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.817\n",
      "Model 2 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.92      0.79      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 84.3592734336853 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2695, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1878, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1876, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.163, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.1456, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.8098\n",
      "Epoch 7/10, Train Loss: 0.0752, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.056, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.0477, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7932\n",
      "Model 3 - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.74      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 77.93616914749146 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.7835\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 530.3586133905267\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.161444425582886 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2741, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1545, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0978, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Epoch 8/10, Train Loss: 0.0557, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "Epoch 9/10, Train Loss: 0.0374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7847\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7874\n",
      "Model 1 - Iteration 300: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.31184935569763 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.254, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8325\n",
      "Epoch 10/10, Train Loss: 0.0337, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Model 2 - Iteration 300: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 84.21670031547546 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1625, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1846, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7865\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0524, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Model 3 - Iteration 300: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.43309497833252 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9669, F1 Micro: 0.9747, F1 Macro: 0.791\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 521.3049204718649\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.051182746887207 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2882, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1862, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1519, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1121, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7383\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7944\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8032\n",
      "Epoch 9/10, Train Loss: 0.0374, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.8016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0291, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Model 1 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 81.14498662948608 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2741, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1884, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.7309\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0646, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.8136\n",
      "Epoch 9/10, Train Loss: 0.0386, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0321, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8315\n",
      "Model 2 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.40444350242615 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2755, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8298\n",
      "Epoch 8/10, Train Loss: 0.0549, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8007\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Model 3 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.50546097755432 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9674, F1 Micro: 0.9751, F1 Macro: 0.8104\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 519.6171263582476\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.626140356063843 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2673, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1993, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1993, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0498, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8293\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.804\n",
      "Model 1 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.9937629699707 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1978, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1992, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7798\n",
      "Epoch 6/10, Train Loss: 0.104, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7871\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Model 2 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.13033294677734 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1995, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1848, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1231, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.8294\n",
      "Epoch 7/10, Train Loss: 0.0617, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8019\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.8017\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Model 3 - Iteration 320: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.8294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.92      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.92      0.82      0.83       406\n",
      "weighted avg       0.97      0.97      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.94575548171997 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9674, F1 Micro: 0.975, F1 Macro: 0.7988\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 507.49712273490786\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.814714193344116 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2817, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1969, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.175, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1369, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1093, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0478, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7699\n",
      "Epoch 8/10, Train Loss: 0.0462, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8124\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7883\n",
      "Model 1 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.87      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.96272683143616 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2626, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1932, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 5/10, Train Loss: 0.1033, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0722, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7234\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7935\n",
      "Epoch 8/10, Train Loss: 0.0418, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7788\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.749\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8157\n",
      "Model 2 - Iteration 330: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 83.50942349433899 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1978, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1565, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Epoch 5/10, Train Loss: 0.1253, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7595\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0484, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7673\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Model 3 - Iteration 330: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.69928622245789 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9685, F1 Micro: 0.9759, F1 Macro: 0.7541\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 456.56309987587855\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.457113265991211 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1401, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0889, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0837, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0512, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8041\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.805\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8126\n",
      "Model 1 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.4324357509613 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2536, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1935, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.6516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1544, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6546\n",
      "Epoch 5/10, Train Loss: 0.0923, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7371\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Epoch 7/10, Train Loss: 0.0543, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0418, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8616\n",
      "Model 2 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.83      0.86       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.65094041824341 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2569, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1619, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1024, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7666\n",
      "Epoch 7/10, Train Loss: 0.0573, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7788\n",
      "Model 3 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 87.2987871170044 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.8291\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 396.40215453602883\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.06036114692688 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2599, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1726, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1352, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0786, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7466\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7668\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8033\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7941\n",
      "Model 1 - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.01759457588196 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2459, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1803, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1111, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7775\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.7897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "Epoch 10/10, Train Loss: 0.0272, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.803\n",
      "Model 2 - Iteration 350: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.27651047706604 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2477, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.182, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1443, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7523\n",
      "Epoch 6/10, Train Loss: 0.0796, Accuracy: 0.9487, F1 Micro: 0.9614, F1 Macro: 0.7697\n",
      "Epoch 7/10, Train Loss: 0.0617, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0549, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.802\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7847\n",
      "Model 3 - Iteration 350: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.97      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.74      0.78       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 91.42274236679077 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7877\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 328.51433289193824\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.4235103130340576 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2567, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.134, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1269, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 5/10, Train Loss: 0.0961, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8093\n",
      "Epoch 7/10, Train Loss: 0.0496, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.766\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7635\n",
      "Epoch 9/10, Train Loss: 0.0402, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "Model 1 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.39870429039001 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1576, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1303, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1362, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0984, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8464\n",
      "Model 2 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 93.52263450622559 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2475, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1609, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1372, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6956\n",
      "Epoch 6/10, Train Loss: 0.0752, Accuracy: 0.9535, F1 Micro: 0.965, F1 Macro: 0.7849\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7665\n",
      "Epoch 8/10, Train Loss: 0.0468, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Epoch 9/10, Train Loss: 0.0444, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7665\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7852\n",
      "Model 3 - Iteration 360: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.04002499580383 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9674, F1 Micro: 0.9751, F1 Macro: 0.7737\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 260.80261930903197\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.8837616443634033 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2417, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1787, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1159, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 5/10, Train Loss: 0.1001, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.066, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7625\n",
      "Epoch 8/10, Train Loss: 0.038, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0184, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8058\n",
      "Model 1 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 93.80122637748718 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2269, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1444, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 4/10, Train Loss: 0.121, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0915, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "Epoch 6/10, Train Loss: 0.0652, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7875\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8321\n",
      "Epoch 10/10, Train Loss: 0.0189, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8303\n",
      "Model 2 - Iteration 370: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 91.96041965484619 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2335, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1528, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 5/10, Train Loss: 0.1051, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 6/10, Train Loss: 0.0649, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8198\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7684\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7682\n",
      "Model 3 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 91.74723958969116 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8084\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 199.16801544019248\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.3290793895721436 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2498, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1212, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 5/10, Train Loss: 0.0886, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 6/10, Train Loss: 0.0656, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.8014\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8099\n",
      "Epoch 8/10, Train Loss: 0.0317, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8089\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8022\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8089\n",
      "Model 1 - Iteration 380: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 91.50302386283875 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2347, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1665, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1545, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 4/10, Train Loss: 0.1211, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0928, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7776\n",
      "Epoch 6/10, Train Loss: 0.0729, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0454, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8038\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8161\n",
      "Model 2 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.92      0.79      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.98857188224792 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2367, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1677, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1608, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1331, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0963, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "Epoch 6/10, Train Loss: 0.069, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7955\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Epoch 8/10, Train Loss: 0.0314, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 9/10, Train Loss: 0.0262, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "Model 3 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.74      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 93.52115201950073 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7742\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 130.28703259731836\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9935200214385986 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1503, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1425, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1368, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.08, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 6/10, Train Loss: 0.0629, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.6877\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0364, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0274, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8325\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8293\n",
      "Model 1 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.92      0.83      0.83       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 98.17128896713257 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1488, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1392, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1382, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6546\n",
      "Epoch 5/10, Train Loss: 0.0818, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7376\n",
      "Epoch 6/10, Train Loss: 0.0643, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0562, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0338, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.027, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8176\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.93      0.79      0.82       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 98.93529200553894 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2499, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1498, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1452, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0976, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 6/10, Train Loss: 0.0681, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8025\n",
      "Epoch 7/10, Train Loss: 0.0589, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6964\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Model 3 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 96.73143529891968 s\n",
      "Averaged - Iteration 390: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.8181\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 66.42608686177913\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6712055206298828 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2388, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1513, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1395, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 4/10, Train Loss: 0.1225, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0885, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0614, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0441, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.79\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7035\n",
      "Epoch 9/10, Train Loss: 0.025, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7676\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7625\n",
      "Model 1 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 97.76598954200745 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.222, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.149, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.135, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 4/10, Train Loss: 0.1252, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Epoch 5/10, Train Loss: 0.0875, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Epoch 6/10, Train Loss: 0.0636, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.762\n",
      "Epoch 7/10, Train Loss: 0.0434, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.8078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0246, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0265, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8046\n",
      "Model 2 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.50      0.25      0.33         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.84      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.93069219589233 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2265, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1051, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 6/10, Train Loss: 0.0806, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Epoch 9/10, Train Loss: 0.0249, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7673\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8023\n",
      "Model 3 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 97.05136108398438 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9669, F1 Micro: 0.9747, F1 Macro: 0.7995\n",
      "Total sampling time: 170.58 seconds\n",
      "Total runtime: 5869.555249452591 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac46802",
   "metadata": {
    "papermill": {
     "duration": 0.01062,
     "end_time": "2025-06-09T18:02:46.915841",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.905221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 3\n",
      "Random seed: [14, 7, 33]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5363, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3254, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1532, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1377, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1236, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1004, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1137, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1258, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.035823583602905 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.633, Accuracy: 0.9503, F1 Micro: 0.9616, F1 Macro: 0.645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3689, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2519, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1519, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.133, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1279, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1128, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1219, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.55143761634827 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5157, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3148, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2375, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1435, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1387, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1233, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.101, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1101, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1222, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.22103548049927 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 477.0583559286562\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "\n",
      "Sampling duration: 17.20614457130432 secondsNew train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4361, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2218, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1902, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1897, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1429, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1578, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1387, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1255, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1052, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.80696678161621 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5077, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2347, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1997, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1904, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1422, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1541, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1395, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1217, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0967, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.63767218589783 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4203, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2235, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2015, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1937, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1437, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1468, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1382, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.96709990501404 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 491.1583395500546\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.339614391326904 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3926, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2251, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1803, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.182, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1377, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1018, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 1 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.61959505081177 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4266, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2227, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.182, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1781, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1343, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.104, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 9/10, Train Loss: 0.0978, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 2 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 46.4755482673645 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2218, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1482, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1659, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1965, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1277, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1166, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0924, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Model 3 - Iteration 97: Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.908992528915405 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9589, F1 Micro: 0.9687, F1 Macro: 0.6512\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 480.6450495502858\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.907652616500854 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1401, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.132, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1168, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0958, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 1 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 56.910322189331055 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4016, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1781, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1336, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1231, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.118, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0956, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7167\n",
      "Model 2 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.83      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.80      0.71      0.72       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 56.710233211517334 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3526, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1766, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1765, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1457, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1365, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1319, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1223, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 10/10, Train Loss: 0.103, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Model 3 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.17928862571716 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9589, F1 Micro: 0.9688, F1 Macro: 0.6732\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 486.8804394367857\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.514201164245605 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3398, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.198, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1527, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1545, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1413, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1615, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.108, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1117, Accuracy: 0.9551, F1 Micro: 0.9654, F1 Macro: 0.6482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6533\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.12594938278198 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3658, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1956, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1486, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1533, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7636\n",
      "Epoch 10/10, Train Loss: 0.0657, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7518\n",
      "Model 2 - Iteration 156: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.74      0.79      0.76       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 58.46911334991455 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3255, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1969, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.152, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1542, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1695, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.133, Accuracy: 0.9647, F1 Micro: 0.9726, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7233\n",
      "Epoch 10/10, Train Loss: 0.0779, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Model 3 - Iteration 156: Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 59.76224207878113 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7136\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 482.33223482937177\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.559466123580933 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3111, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1484, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.109, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7072\n",
      "Epoch 10/10, Train Loss: 0.0475, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Model 1 - Iteration 181: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 61.908472537994385 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.337, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1447, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7637\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7259\n",
      "Epoch 10/10, Train Loss: 0.0425, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Model 2 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.74      0.79      0.76       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 60.5281023979187 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3024, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1536, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1314, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1125, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 9/10, Train Loss: 0.0849, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Model 3 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.836276054382324 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6901\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 497.86231748960785\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.706316232681274 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3001, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1734, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1572, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1199, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1129, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "Epoch 8/10, Train Loss: 0.0654, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Model 1 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 65.83501625061035 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3263, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1721, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7177\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.076, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.736\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7124\n",
      "Model 2 - Iteration 203: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.27233839035034 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2969, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1732, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1612, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 7/10, Train Loss: 0.1252, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.719\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7266\n",
      "Model 3 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 64.06137132644653 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6823\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 473.5865439620729\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.535318613052368 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3143, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1849, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1903, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1128, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.0776, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6968\n",
      "Model 1 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 69.63335633277893 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3323, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1855, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1884, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1539, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Epoch 7/10, Train Loss: 0.0654, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0557, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7309\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7384\n",
      "Model 2 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 66.977854013443 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3067, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1882, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1918, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1624, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1319, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7223\n",
      "Epoch 7/10, Train Loss: 0.0879, Accuracy: 0.9471, F1 Micro: 0.9605, F1 Macro: 0.7099\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7107\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7225\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7105\n",
      "Model 3 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 66.29600954055786 s\n",
      "Averaged - Iteration 223: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.7253\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 501.9544974249986\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.986425876617432 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2788, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1525, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1737, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0513, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0447, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.46814036369324 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2947, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 5/10, Train Loss: 0.1113, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7177\n",
      "Epoch 6/10, Train Loss: 0.0899, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0428, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Model 2 - Iteration 241: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.7020251750946 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2726, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1913, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1818, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1524, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.084, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0448, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Model 3 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 74.46407628059387 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.7828\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 521.4043606386977\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.429590702056885 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2871, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.155, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0724, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0551, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 10/10, Train Loss: 0.0335, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Model 1 - Iteration 250: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 76.77571964263916 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3007, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Epoch 7/10, Train Loss: 0.0722, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7433\n",
      "Epoch 9/10, Train Loss: 0.046, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Epoch 10/10, Train Loss: 0.0417, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7876\n",
      "Model 2 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.50136518478394 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2785, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.196, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 7/10, Train Loss: 0.0784, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7438\n",
      "Epoch 9/10, Train Loss: 0.0474, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 10/10, Train Loss: 0.0378, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7283\n",
      "Model 3 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.71350836753845 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7321\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 502.52734672231395\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.922489881515503 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2871, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2049, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1668, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 8/10, Train Loss: 0.0549, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "Model 1 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 76.82253909111023 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2991, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.203, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.106, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.734\n",
      "Epoch 7/10, Train Loss: 0.074, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7433\n",
      "Epoch 9/10, Train Loss: 0.0459, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7431\n",
      "Epoch 10/10, Train Loss: 0.0291, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Model 2 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 74.43683767318726 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2044, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1719, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.756\n",
      "Epoch 8/10, Train Loss: 0.0542, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7558\n",
      "Epoch 9/10, Train Loss: 0.042, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7649\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Model 3 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.73      0.79      0.76       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 75.8207221031189 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7409\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 516.8191506097022\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.165194272994995 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1917, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1574, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0781, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.06, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "Epoch 8/10, Train Loss: 0.0498, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8026\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8067\n",
      "Model 1 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 81.54703211784363 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2936, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1341, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0982, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7529\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7428\n",
      "Epoch 7/10, Train Loss: 0.0575, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0471, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0377, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Model 2 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 77.82223296165466 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2694, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1925, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1344, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0839, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0668, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 9/10, Train Loss: 0.0346, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "Model 3 - Iteration 279: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 79.01185846328735 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.781\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 527.2468196879842\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.120851039886475 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1728, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1519, Accuracy: 0.9567, F1 Micro: 0.9663, F1 Macro: 0.6482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "Epoch 8/10, Train Loss: 0.057, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7754\n",
      "Model 1 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.26487183570862 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2864, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1645, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1211, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1114, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0833, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0699, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7452\n",
      "Epoch 8/10, Train Loss: 0.0558, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "Epoch 9/10, Train Loss: 0.0394, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0388, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Model 2 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.74      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.92943930625916 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2609, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1707, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.6912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Epoch 7/10, Train Loss: 0.0761, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "Model 3 - Iteration 292: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 80.95440101623535 s\n",
      "Averaged - Iteration 292: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.7731\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 506.64356057231737\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.216888427734375 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2593, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1652, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1728, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0922, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0265, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Model 1 - Iteration 300: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 82.21844124794006 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2765, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1649, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7622\n",
      "Epoch 5/10, Train Loss: 0.1034, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0888, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 7/10, Train Loss: 0.0634, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7146\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7493\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 2 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.76      0.75      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.8076343536377 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.165, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 7/10, Train Loss: 0.0655, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Epoch 8/10, Train Loss: 0.0457, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7156\n",
      "Epoch 9/10, Train Loss: 0.0392, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 80.75520300865173 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7457\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 515.8670739268191\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.712714195251465 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1812, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.162, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1551, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.6951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0831, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0556, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0372, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.778\n",
      "Model 1 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.75      0.78       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 88.00308680534363 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.289, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1798, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1001, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7533\n",
      "Epoch 6/10, Train Loss: 0.0757, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7517\n",
      "Epoch 7/10, Train Loss: 0.07, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0509, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 9/10, Train Loss: 0.0441, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7999\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Model 2 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.70975112915039 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2668, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1796, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1556, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1142, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7193\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0684, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Model 3 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 84.81836986541748 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7826\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 512.6057311575663\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.415341377258301 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2532, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1638, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1135, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0545, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7719\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7701\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7686\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "Model 1 - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 85.8993124961853 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1279, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 5/10, Train Loss: 0.0844, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7194\n",
      "Epoch 6/10, Train Loss: 0.072, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0507, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8106\n",
      "Model 2 - Iteration 320: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.83      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.02917408943176 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2453, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1667, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Epoch 7/10, Train Loss: 0.0575, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.7172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0512, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Epoch 9/10, Train Loss: 0.0357, Accuracy: 0.9535, F1 Micro: 0.9642, F1 Macro: 0.7916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "Model 3 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.19984745979309 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.7958\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 526.9290095980934\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.882854700088501 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2578, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1471, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 6/10, Train Loss: 0.088, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0578, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7893\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7568\n",
      "Epoch 10/10, Train Loss: 0.0207, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8051\n",
      "Model 1 - Iteration 330: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 87.5792908668518 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1764, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0909, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 6/10, Train Loss: 0.0803, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7518\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "Epoch 9/10, Train Loss: 0.0329, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.8098\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Model 2 - Iteration 330: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 87.94241046905518 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2555, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2113, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0552, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "Epoch 8/10, Train Loss: 0.0402, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8098\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7451\n",
      "Epoch 10/10, Train Loss: 0.0196, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7452\n",
      "Model 3 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.44312834739685 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.7918\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 459.26286416891895\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.391778945922852 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1801, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.135, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1031, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "Epoch 6/10, Train Loss: 0.0919, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "Epoch 7/10, Train Loss: 0.0494, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0429, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7711\n",
      "Epoch 9/10, Train Loss: 0.0346, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7235\n",
      "Model 1 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 90.88776111602783 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1819, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1061, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0819, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0443, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8039\n",
      "Epoch 8/10, Train Loss: 0.0469, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7355\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7855\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7805\n",
      "Model 2 - Iteration 340: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.83      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.98808097839355 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2509, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1821, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1328, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.0974, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7312\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0489, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8179\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8633\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.767\n",
      "Model 3 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.92      0.79      0.82       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 89.52403926849365 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.7817\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 396.40399341600613\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.853184938430786 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2624, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1539, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1458, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.79\n",
      "Epoch 7/10, Train Loss: 0.0511, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7701\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 9/10, Train Loss: 0.0281, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7004\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.77\n",
      "Model 1 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.27584290504456 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2752, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1513, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1364, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1189, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7629\n",
      "Epoch 5/10, Train Loss: 0.1072, Accuracy: 0.9487, F1 Micro: 0.9616, F1 Macro: 0.7106\n",
      "Epoch 6/10, Train Loss: 0.0801, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0542, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7469\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7452\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Model 2 - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 89.2745201587677 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1533, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Epoch 5/10, Train Loss: 0.1276, Accuracy: 0.9487, F1 Micro: 0.9616, F1 Macro: 0.7135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0418, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.74\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8337\n",
      "Model 3 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 92.85845136642456 s\n",
      "Averaged - Iteration 350: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.7902\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 312.478319663134\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.538404703140259 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 5/10, Train Loss: 0.097, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.068, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0509, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8176\n",
      "Model 1 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.93      0.79      0.82       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 94.96981477737427 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2503, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1525, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1235, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 5/10, Train Loss: 0.0975, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0689, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Model 2 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 93.32614707946777 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2295, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1597, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1075, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0739, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7222\n",
      "Epoch 7/10, Train Loss: 0.0525, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0372, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7035\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7799\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7709\n",
      "Model 3 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7035\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.70      0.71      0.70       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.4048113822937 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.775\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 266.09438643079466\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.9413888454437256 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2405, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1722, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1501, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1198, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 5/10, Train Loss: 0.0959, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6994\n",
      "Epoch 6/10, Train Loss: 0.0665, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.6992\n",
      "Epoch 7/10, Train Loss: 0.0494, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0256, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0196, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7807\n",
      "Model 1 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 97.3112473487854 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2541, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1722, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1007, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 5/10, Train Loss: 0.0828, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 7/10, Train Loss: 0.0527, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0369, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Model 2 - Iteration 370: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.75711107254028 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2364, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.171, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1549, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 6/10, Train Loss: 0.0773, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0257, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Epoch 10/10, Train Loss: 0.0184, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Model 3 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 97.74695897102356 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7798\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 199.29849981752147\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.3801610469818115 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.241, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1639, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1214, Accuracy: 0.9519, F1 Micro: 0.9638, F1 Macro: 0.6844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.087, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 6/10, Train Loss: 0.0629, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0436, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0342, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.806\n",
      "Model 1 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 100.47320508956909 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2512, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1791, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0928, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0832, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "Epoch 6/10, Train Loss: 0.0637, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 7/10, Train Loss: 0.0472, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0371, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8172\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8189\n",
      "Model 2 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 96.51760959625244 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2344, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1787, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1278, Accuracy: 0.9535, F1 Micro: 0.965, F1 Macro: 0.7278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0948, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Epoch 6/10, Train Loss: 0.0723, Accuracy: 0.9535, F1 Micro: 0.9651, F1 Macro: 0.728\n",
      "Epoch 7/10, Train Loss: 0.0515, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.035, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "Epoch 9/10, Train Loss: 0.0283, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.8026\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Model 3 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.71286368370056 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.7923\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 133.3653893626225\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.1608314514160156 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2323, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1593, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0431, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7447\n",
      "Epoch 9/10, Train Loss: 0.0245, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Epoch 10/10, Train Loss: 0.0194, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7642\n",
      "Model 1 - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 100.68930506706238 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2458, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1603, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1355, Accuracy: 0.9519, F1 Micro: 0.9639, F1 Macro: 0.7225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1143, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 5/10, Train Loss: 0.0846, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.727\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 7/10, Train Loss: 0.0487, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Epoch 8/10, Train Loss: 0.0505, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7862\n",
      "Model 2 - Iteration 390: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.71      0.74      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 93.92202925682068 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2268, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1591, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1493, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1002, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Epoch 6/10, Train Loss: 0.0811, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8167\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 9/10, Train Loss: 0.025, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7882\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7762\n",
      "Model 3 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.93      0.79      0.82       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.6339967250824 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9669, F1 Micro: 0.9747, F1 Macro: 0.7831\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 64.8808844330621\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.673234224319458 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2301, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1733, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1407, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1194, Accuracy: 0.9551, F1 Micro: 0.9652, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0818, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0497, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0431, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7881\n",
      "Epoch 8/10, Train Loss: 0.0288, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Epoch 10/10, Train Loss: 0.0241, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Model 1 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.74      0.79       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 98.52437233924866 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2416, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1245, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0944, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0696, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7444\n",
      "Epoch 6/10, Train Loss: 0.048, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7267\n",
      "Epoch 7/10, Train Loss: 0.0457, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8009\n",
      "Epoch 8/10, Train Loss: 0.0288, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.743\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8014\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7864\n",
      "Model 2 - Iteration 400: Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.95      0.99      0.97       406\n",
      "   macro avg       0.71      0.79      0.74       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 96.86683750152588 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2255, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1431, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1196, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0804, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7328\n",
      "Epoch 6/10, Train Loss: 0.055, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "Epoch 8/10, Train Loss: 0.0305, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7196\n",
      "Epoch 9/10, Train Loss: 0.0255, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7901\n",
      "Model 3 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 101.84232068061829 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7742\n",
      "Total sampling time: 173.56 seconds\n",
      "Total runtime: 5880.71527671814 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea20074",
   "metadata": {
    "papermill": {
     "duration": 0.010471,
     "end_time": "2025-06-09T18:02:46.962514",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.952043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f146ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T18:02:46.984602Z",
     "iopub.status.busy": "2025-06-09T18:02:46.984404Z",
     "iopub.status.idle": "2025-06-09T19:38:47.823930Z",
     "shell.execute_reply": "2025-06-09T19:38:47.823233Z"
    },
    "papermill": {
     "duration": 5760.852314,
     "end_time": "2025-06-09T19:38:47.825484",
     "exception": false,
     "start_time": "2025-06-09T18:02:46.973170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 4\n",
      "Random seed: [3, 44, 85]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2956, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2125, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2292, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.65901041030884 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6001, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.321, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2749, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2152, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2232, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 40.17673945426941 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2802, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1102, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1939, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2098, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1334, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.76321887969971 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 469.45561823379916\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 18.01935577392578 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4083, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1607, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1375, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1585, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1281, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1006, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.354471921920776 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4619, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1788, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.188, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1359, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1531, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1165, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 10/10, Train Loss: 0.0884, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 41.70243573188782 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4097, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2584, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1296, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1487, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1602, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1175, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0944, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.05621576309204 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 486.9844226415898\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 16.397735834121704 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3493, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1795, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1805, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1455, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1238, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1348, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1123, Accuracy: 0.9519, F1 Micro: 0.9631, F1 Macro: 0.6467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0743, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.48818635940552 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3871, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1385, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1113, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1201, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Epoch 9/10, Train Loss: 0.1023, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 10/10, Train Loss: 0.0749, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Model 2 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.28244233131409 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3446, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1763, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1809, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1232, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1136, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1178, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.78058123588562 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 499.0105999604803\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 14.630615711212158 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.313, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2038, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1813, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1827, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1193, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.6509\n",
      "Epoch 9/10, Train Loss: 0.1081, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 10/10, Train Loss: 0.0855, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 1 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.6509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.93      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.97      0.97       406\n",
      "\n",
      "Training completed in 51.38010025024414 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3338, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2075, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1988, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.164, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1206, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 9/10, Train Loss: 0.1041, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 10/10, Train Loss: 0.0935, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 2 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.97      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.47285985946655 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3018, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2062, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1933, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1559, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1383, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Epoch 9/10, Train Loss: 0.0825, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.9551, F1 Micro: 0.9657, F1 Macro: 0.6487\n",
      "Model 3 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.25303030014038 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9594, F1 Micro: 0.9689, F1 Macro: 0.6511\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 481.65704718394744\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 13.491992712020874 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2964, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1526, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 8/10, Train Loss: 0.1321, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7167\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7166\n",
      "Model 1 - Iteration 156: Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.97      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 55.87011742591858 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3164, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1905, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 7/10, Train Loss: 0.1137, Accuracy: 0.9535, F1 Micro: 0.9644, F1 Macro: 0.6477\n",
      "Epoch 8/10, Train Loss: 0.1122, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 2 - Iteration 156: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 52.437886238098145 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2891, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1897, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1656, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1143, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 8/10, Train Loss: 0.1059, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 10/10, Train Loss: 0.0461, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 3 - Iteration 156: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 57.65811276435852 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9594, F1 Micro: 0.9691, F1 Macro: 0.6514\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 476.1692955665723\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.984170198440552 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2888, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1885, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1511, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.1299, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.6509\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6504\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Model 1 - Iteration 181: Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.35405421257019 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3116, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1585, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 6/10, Train Loss: 0.1479, Accuracy: 0.9551, F1 Micro: 0.9657, F1 Macro: 0.6487\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9551, F1 Micro: 0.9657, F1 Macro: 0.6487\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6505\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9551, F1 Micro: 0.9656, F1 Macro: 0.6486\n",
      "Model 2 - Iteration 181: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 57.063207149505615 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1893, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.164, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 6/10, Train Loss: 0.1283, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0463, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Model 3 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.33771824836731 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9621, F1 Micro: 0.971, F1 Macro: 0.6527\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 487.5832337552614\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 11.12472677230835 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2829, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1137, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0685, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Epoch 9/10, Train Loss: 0.056, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Model 1 - Iteration 203: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 64.68936848640442 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2974, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1964, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1854, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 6/10, Train Loss: 0.1647, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.6496\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 2 - Iteration 203: Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 63.154465198516846 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1926, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1605, Accuracy: 0.9663, F1 Micro: 0.9739, F1 Macro: 0.6544\n",
      "Epoch 6/10, Train Loss: 0.141, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 8/10, Train Loss: 0.0574, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6983\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0353, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6505\n",
      "Model 3 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9739, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.93      0.93      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 61.408613204956055 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.675\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 474.57525757737915\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 10.000332593917847 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2889, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1757, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 8/10, Train Loss: 0.0648, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0523, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7626\n",
      "Model 1 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 69.44230914115906 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.305, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1642, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9551, F1 Micro: 0.9658, F1 Macro: 0.6489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9535, F1 Micro: 0.9645, F1 Macro: 0.6962\n",
      "Model 2 - Iteration 223: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.41940188407898 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.0708, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 8/10, Train Loss: 0.0544, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0485, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6525\n",
      "Model 3 - Iteration 223: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 65.93966794013977 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9621, F1 Micro: 0.9711, F1 Macro: 0.6893\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 500.1167416593107\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 9.29203486442566 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2613, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1693, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1178, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7952\n",
      "Epoch 8/10, Train Loss: 0.05, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7953\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7942\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.21973538398743 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.6499\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.7112\n",
      "Epoch 8/10, Train Loss: 0.0518, Accuracy: 0.9535, F1 Micro: 0.9646, F1 Macro: 0.6912\n",
      "Epoch 9/10, Train Loss: 0.0377, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 10/10, Train Loss: 0.039, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 2 - Iteration 241: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 68.52472734451294 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2568, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1781, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1676, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1539, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1201, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7947\n",
      "Epoch 6/10, Train Loss: 0.0877, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7014\n",
      "Epoch 7/10, Train Loss: 0.0626, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7433\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7166\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Model 3 - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.81      0.79      0.79       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 68.58291792869568 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9642, F1 Micro: 0.9728, F1 Macro: 0.7475\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 505.0111035168778\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.32905626296997 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2064, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1912, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1355, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1128, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 8/10, Train Loss: 0.062, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Epoch 9/10, Train Loss: 0.0412, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7502\n",
      "Model 1 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.36296510696411 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2078, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1335, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Epoch 8/10, Train Loss: 0.0568, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6982\n",
      "Epoch 9/10, Train Loss: 0.0439, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6895\n",
      "Epoch 10/10, Train Loss: 0.0379, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Model 2 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.09120750427246 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2552, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2066, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Epoch 7/10, Train Loss: 0.0785, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6948\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Epoch 9/10, Train Loss: 0.0396, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0337, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7541\n",
      "Model 3 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 71.20166969299316 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9653, F1 Micro: 0.9735, F1 Macro: 0.7097\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 505.38052408045723\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.974792957305908 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1827, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1527, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0803, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.0511, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7772\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.029, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7646\n",
      "Model 1 - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 78.64563512802124 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2686, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9551, F1 Micro: 0.9657, F1 Macro: 0.7144\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.6925\n",
      "Epoch 9/10, Train Loss: 0.0567, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.693\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7469\n",
      "Model 2 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.70855259895325 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2526, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Epoch 7/10, Train Loss: 0.0646, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7623\n",
      "Epoch 9/10, Train Loss: 0.0436, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7444\n",
      "Model 3 - Iteration 265: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.82894515991211 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7126\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 487.8171624178253\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.2634148597717285 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2762, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1889, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0792, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0671, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.037, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7772\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7944\n",
      "Model 1 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 77.29834342002869 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2896, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1874, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1556, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1283, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 6/10, Train Loss: 0.1178, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6991\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0355, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7882\n",
      "Model 2 - Iteration 279: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 75.94548320770264 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1877, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1536, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.1203, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0674, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7969\n",
      "Epoch 8/10, Train Loss: 0.0524, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "Model 3 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 79.33114051818848 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7884\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 515.0597046468264\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.077178716659546 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2667, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1744, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1469, Accuracy: 0.9503, F1 Micro: 0.9628, F1 Macro: 0.7177\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9519, F1 Micro: 0.9638, F1 Macro: 0.7148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 9/10, Train Loss: 0.0435, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Model 1 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.3873028755188 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.277, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Model 2 - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 80.00530004501343 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1694, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.136, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7197\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Epoch 8/10, Train Loss: 0.0524, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7476\n",
      "Model 3 - Iteration 292: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 78.127268075943 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.7657\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 523.0202937863659\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.309472560882568 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2436, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.175, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0735, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 9/10, Train Loss: 0.0316, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7951\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "Model 1 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.95041060447693 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2551, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.182, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1511, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Epoch 6/10, Train Loss: 0.0843, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 7/10, Train Loss: 0.0642, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0313, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Model 2 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.93285131454468 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2391, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1494, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 6/10, Train Loss: 0.0779, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 8/10, Train Loss: 0.0369, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Epoch 9/10, Train Loss: 0.0316, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7533\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.74      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.05415749549866 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9674, F1 Micro: 0.9751, F1 Macro: 0.7697\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 521.6186004770084\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.805812358856201 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2578, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1175, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0911, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0685, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 8/10, Train Loss: 0.0516, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7344\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7632\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.763\n",
      "Model 1 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.74      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.4210455417633 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2692, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1696, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.14, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1155, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Epoch 6/10, Train Loss: 0.0791, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7283\n",
      "Epoch 7/10, Train Loss: 0.0638, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.053, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7376\n",
      "Epoch 10/10, Train Loss: 0.032, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7865\n",
      "Model 2 - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 83.62380909919739 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.26, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1709, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.139, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0813, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0656, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0314, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Model 3 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 86.28056502342224 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9669, F1 Micro: 0.9747, F1 Macro: 0.7559\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 528.6825971392262\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.557087421417236 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2296, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Epoch 8/10, Train Loss: 0.0583, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7352\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Model 1 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 84.80748224258423 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2422, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Epoch 5/10, Train Loss: 0.1228, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "Epoch 7/10, Train Loss: 0.0541, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7849\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.712\n",
      "Epoch 10/10, Train Loss: 0.0377, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7331\n",
      "Model 2 - Iteration 320: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.70061349868774 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2275, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1734, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 6/10, Train Loss: 0.094, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7433\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Epoch 8/10, Train Loss: 0.0481, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.819\n",
      "Epoch 9/10, Train Loss: 0.0338, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7441\n",
      "Epoch 10/10, Train Loss: 0.0335, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7349\n",
      "Model 3 - Iteration 320: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.90963077545166 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7238\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 505.29771755494954\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.043502569198608 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2404, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1826, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1695, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1292, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1037, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0574, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7956\n",
      "Epoch 8/10, Train Loss: 0.0433, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7967\n",
      "Model 1 - Iteration 330: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.62794375419617 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1849, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1261, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 5/10, Train Loss: 0.1029, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 6/10, Train Loss: 0.0676, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 7/10, Train Loss: 0.0545, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7274\n",
      "Epoch 8/10, Train Loss: 0.0435, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7268\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7274\n",
      "Model 2 - Iteration 330: Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 83.11860918998718 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2396, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1193, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 6/10, Train Loss: 0.0658, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 7/10, Train Loss: 0.0502, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7995\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 3 - Iteration 330: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.36486434936523 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9669, F1 Micro: 0.9746, F1 Macro: 0.7018\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 439.258802878136\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.5782740116119385 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2264, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1453, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Epoch 5/10, Train Loss: 0.1181, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1027, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0589, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 9/10, Train Loss: 0.0265, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7494\n",
      "Model 1 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.8941605091095 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2392, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1679, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1438, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0537, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 8/10, Train Loss: 0.0426, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Model 2 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.38783359527588 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2263, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 5/10, Train Loss: 0.1093, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Epoch 6/10, Train Loss: 0.0915, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Epoch 8/10, Train Loss: 0.04, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 9/10, Train Loss: 0.0249, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.795\n",
      "Epoch 10/10, Train Loss: 0.0259, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Model 3 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.65226101875305 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9685, F1 Micro: 0.9759, F1 Macro: 0.7566\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 391.2441460268377\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.9064743518829346 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2419, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.131, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.074, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Epoch 7/10, Train Loss: 0.0578, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0545, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8644\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7977\n",
      "Model 1 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.83      0.86       406\n",
      "weighted avg       0.98      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 91.2525999546051 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1248, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.0915, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 6/10, Train Loss: 0.0669, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.699\n",
      "Epoch 7/10, Train Loss: 0.0532, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8762\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Model 2 - Iteration 350: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.93      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.75      0.86         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.86      0.88       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.01457571983337 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2373, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1151, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 5/10, Train Loss: 0.081, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0682, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "Epoch 7/10, Train Loss: 0.0525, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Epoch 8/10, Train Loss: 0.0445, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7872\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7893\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.97578930854797 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8265\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 324.56546605271257\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.4669690132141113 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2333, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1517, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0812, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7635\n",
      "Epoch 9/10, Train Loss: 0.0316, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0174, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Model 1 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.74      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.40396094322205 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2407, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0578, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 9/10, Train Loss: 0.037, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7872\n",
      "Epoch 10/10, Train Loss: 0.0185, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.8136\n",
      "Model 2 - Iteration 360: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 89.44507479667664 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2288, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1009, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 6/10, Train Loss: 0.0602, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7673\n",
      "Epoch 7/10, Train Loss: 0.0485, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Epoch 8/10, Train Loss: 0.0307, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8162\n",
      "Epoch 10/10, Train Loss: 0.0155, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7226\n",
      "Model 3 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.92      0.79      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 91.95765519142151 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.7701\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 264.2936882387543\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7873895168304443 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2139, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1765, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1565, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.129, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0945, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 6/10, Train Loss: 0.0675, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0267, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8446\n",
      "Epoch 10/10, Train Loss: 0.0213, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Model 1 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.94      0.83      0.84       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.27572584152222 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2238, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1766, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1193, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.0916, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0589, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8303\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7855\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8295\n",
      "Model 2 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8303\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 91.44433951377869 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2129, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1499, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1142, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0868, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 6/10, Train Loss: 0.0556, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0516, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 8/10, Train Loss: 0.0352, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7852\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Model 3 - Iteration 370: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.94598722457886 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8041\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 199.1252316640471\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.5154573917388916 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2235, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1469, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1114, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7639\n",
      "Epoch 6/10, Train Loss: 0.0723, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 7/10, Train Loss: 0.0554, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Epoch 8/10, Train Loss: 0.0434, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7618\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "Model 1 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 95.61188650131226 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2363, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1474, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.111, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0478, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7557\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8032\n",
      "Model 2 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 97.81138253211975 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.225, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1482, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1559, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1344, Accuracy: 0.9535, F1 Micro: 0.965, F1 Macro: 0.7116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1018, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0644, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 7/10, Train Loss: 0.0493, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8018\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8007\n",
      "Epoch 9/10, Train Loss: 0.0256, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8023\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Model 3 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 93.6207206249237 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8135\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 132.12095332818527\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.288578748703003 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2182, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1594, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1509, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0953, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0749, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8325\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8602\n",
      "Model 1 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 101.87200284004211 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2264, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1594, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1214, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0432, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.0356, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 9/10, Train Loss: 0.0252, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.8442\n",
      "Model 2 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.74      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.71675443649292 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2174, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1585, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1148, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 5/10, Train Loss: 0.0836, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7309\n",
      "Epoch 6/10, Train Loss: 0.0663, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0416, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0301, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "Epoch 9/10, Train Loss: 0.024, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Epoch 10/10, Train Loss: 0.0183, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Model 3 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 98.03623819351196 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7811\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 66.20116141412834\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8269023895263672 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2195, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1722, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1286, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0796, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7381\n",
      "Epoch 6/10, Train Loss: 0.0687, Accuracy: 0.9631, F1 Micro: 0.9714, F1 Macro: 0.7181\n",
      "Epoch 7/10, Train Loss: 0.0467, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0315, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Model 1 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 100.22281622886658 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2261, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1707, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1463, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1206, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 5/10, Train Loss: 0.0728, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6983\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.7248\n",
      "Epoch 7/10, Train Loss: 0.0414, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7915\n",
      "Epoch 8/10, Train Loss: 0.0364, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.7648\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.784\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7928\n",
      "Model 2 - Iteration 400: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.7497992515564 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2183, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1733, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1448, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1072, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0692, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0588, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8067\n",
      "Epoch 7/10, Train Loss: 0.0425, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0301, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8151\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8135\n",
      "Epoch 10/10, Train Loss: 0.0196, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8144\n",
      "Model 3 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 100.01817488670349 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.7708\n",
      "Total sampling time: 179.67 seconds\n",
      "Total runtime: 5759.961121082306 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca9ae4",
   "metadata": {
    "papermill": {
     "duration": 0.153166,
     "end_time": "2025-06-09T19:38:48.137437",
     "exception": false,
     "start_time": "2025-06-09T19:38:47.984271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10e8b271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T19:38:48.446873Z",
     "iopub.status.busy": "2025-06-09T19:38:48.446550Z",
     "iopub.status.idle": "2025-06-09T21:21:04.145349Z",
     "shell.execute_reply": "2025-06-09T21:21:04.144568Z"
    },
    "papermill": {
     "duration": 6135.854063,
     "end_time": "2025-06-09T21:21:04.146850",
     "exception": false,
     "start_time": "2025-06-09T19:38:48.292787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 5\n",
      "Random seed: [94, 21, 5]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5613, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2349, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2173, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1608, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1909, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1611, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1423, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.31173777580261 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5537, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3132, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2322, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.218, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.163, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1988, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1598, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1501, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.60421061515808 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3226, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2242, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.23, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2076, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1708, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1648, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.642181396484375 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 477.4092703090814\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 17.903120756149292 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4548, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2428, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2038, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1979, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.193, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1401, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1235, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1334, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.1161, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 42.96212935447693 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4391, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2386, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2005, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1986, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1385, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1399, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1175, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.039536237716675 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2086, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2049, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1558, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1393, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.166, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.913809061050415 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 480.321848775163\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 16.174708366394043 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.379, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.23, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2135, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.192, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1367, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.1407, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 8/10, Train Loss: 0.1179, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6509\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Model 1 - Iteration 97: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 46.65908122062683 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2286, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1494, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2051, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1835, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1347, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1292, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1129, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 2 - Iteration 97: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.92185306549072 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3796, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2371, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2152, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1985, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1513, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1555, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1432, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1015, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.0756, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 3 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.4085967540741 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 478.52130605766115\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 14.9243323802948 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3271, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.213, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1509, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1352, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1288, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1229, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0942, Accuracy: 0.9519, F1 Micro: 0.963, F1 Macro: 0.6463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0811, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 1 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 54.82066750526428 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3271, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2133, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1814, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1231, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1048, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 2 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 54.97282648086548 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3389, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2256, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1615, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1402, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1335, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1364, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1101, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Model 3 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 55.26904320716858 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9626, F1 Micro: 0.9715, F1 Macro: 0.6751\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 489.0962756633727\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 13.610524892807007 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3088, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1652, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1611, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1554, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1479, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1349, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0967, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.7165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 61.273571491241455 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3002, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1632, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1505, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1178, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0812, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Model 2 - Iteration 156: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.71021842956543 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3148, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1712, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1554, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1266, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1363, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Model 3 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 63.05220866203308 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9642, F1 Micro: 0.9728, F1 Macro: 0.7198\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 495.23390217205525\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.889829158782959 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2913, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1657, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1709, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1538, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 7/10, Train Loss: 0.1258, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0965, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 9/10, Train Loss: 0.0656, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Model 1 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 59.72226572036743 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.283, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1631, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1686, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1692, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1239, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.126, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 9/10, Train Loss: 0.0629, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Model 2 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 63.09339928627014 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2984, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1769, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1694, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1576, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.11, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Model 3 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 63.484296560287476 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7206\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 475.37038529942515\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 11.529653072357178 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2816, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1854, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1846, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1438, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1095, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 9/10, Train Loss: 0.0595, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0411, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Model 1 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 68.21789026260376 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1851, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1787, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1408, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1013, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0608, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Model 2 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.15836811065674 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2894, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.19, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1571, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1474, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9519, F1 Micro: 0.9638, F1 Macro: 0.6844\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0623, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Model 3 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 67.73396706581116 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9642, F1 Micro: 0.9727, F1 Macro: 0.7197\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 510.673522936513\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 10.166173219680786 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.282, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1931, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 6/10, Train Loss: 0.1374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0736, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7104\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7479\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7629\n",
      "Model 1 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.70      0.71       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.78026056289673 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2766, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.154, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1245, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.695\n",
      "Epoch 8/10, Train Loss: 0.0653, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Epoch 9/10, Train Loss: 0.0596, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 10/10, Train Loss: 0.0405, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Model 2 - Iteration 223: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 66.7962543964386 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2895, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1968, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1579, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1662, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 6/10, Train Loss: 0.1525, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1163, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 9/10, Train Loss: 0.0691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6905\n",
      "Epoch 10/10, Train Loss: 0.0502, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Model 3 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 68.98895001411438 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7171\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 519.6370440923595\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 9.81320595741272 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2707, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1815, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1624, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1106, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 7/10, Train Loss: 0.0741, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7548\n",
      "Epoch 8/10, Train Loss: 0.0615, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7509\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7486\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.777\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.31576228141785 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2695, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1307, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7291\n",
      "Epoch 8/10, Train Loss: 0.0582, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6946\n",
      "Epoch 9/10, Train Loss: 0.0486, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Model 2 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 72.88780069351196 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2773, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1864, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1316, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Epoch 8/10, Train Loss: 0.0667, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7327\n",
      "Epoch 9/10, Train Loss: 0.0627, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7083\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0565, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "Model 3 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.76      0.75      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.97178435325623 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7311\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 521.9345650636666\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.543792963027954 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2769, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1858, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1815, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Epoch 6/10, Train Loss: 0.1157, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0544, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0417, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7768\n",
      "Model 1 - Iteration 250: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.76      0.79      0.78       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 75.96407914161682 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.273, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1835, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1796, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1589, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 7/10, Train Loss: 0.072, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7426\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Model 2 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.29979920387268 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2833, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.186, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 6/10, Train Loss: 0.1268, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6912\n",
      "Epoch 8/10, Train Loss: 0.0572, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7257\n",
      "Epoch 9/10, Train Loss: 0.061, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 10/10, Train Loss: 0.0482, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7019\n",
      "Model 3 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.02862453460693 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9653, F1 Micro: 0.9735, F1 Macro: 0.7175\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 500.02562445983176\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.996600866317749 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1874, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7457\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7437\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7775\n",
      "Epoch 9/10, Train Loss: 0.0502, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "Model 1 - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 77.11649680137634 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1876, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1541, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Epoch 6/10, Train Loss: 0.0921, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7477\n",
      "Epoch 9/10, Train Loss: 0.0528, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Model 2 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.75      0.75      0.75       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 77.40607762336731 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2811, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1905, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1719, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1634, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1415, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.7246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0618, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Model 3 - Iteration 265: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 77.22730684280396 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7487\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 525.001163747778\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.430219650268555 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2818, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1487, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Epoch 6/10, Train Loss: 0.0893, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0657, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7538\n",
      "Epoch 8/10, Train Loss: 0.0601, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.752\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7349\n",
      "Model 1 - Iteration 279: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.78      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 76.81105279922485 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1482, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0686, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7653\n",
      "Epoch 8/10, Train Loss: 0.0533, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 9/10, Train Loss: 0.0541, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.7418\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Model 2 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.74      0.79      0.77       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 78.25239515304565 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2887, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1821, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 6/10, Train Loss: 0.1022, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.751\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Epoch 8/10, Train Loss: 0.0542, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7512\n",
      "Epoch 9/10, Train Loss: 0.0525, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.743\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Model 3 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 75.38443279266357 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9658, F1 Micro: 0.9739, F1 Macro: 0.7466\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 511.38444417978565\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.180525302886963 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.115, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7393\n",
      "Epoch 6/10, Train Loss: 0.0968, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7307\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 10/10, Train Loss: 0.0237, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Model 1 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 78.47341084480286 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2657, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1905, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1139, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.72\n",
      "Epoch 6/10, Train Loss: 0.1011, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7434\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7423\n",
      "Model 2 - Iteration 292: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.8489842414856 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2745, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.193, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "Epoch 6/10, Train Loss: 0.1028, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.7597\n",
      "Epoch 7/10, Train Loss: 0.0722, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7193\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7258\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7493\n",
      "Model 3 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 77.81199598312378 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.7491\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 518.3599837017782\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.395907640457153 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2546, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1788, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1406, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7452\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.7246\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7958\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7751\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Model 1 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 81.29122495651245 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2503, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1759, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.162, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Epoch 7/10, Train Loss: 0.069, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0469, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8319\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7666\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7644\n",
      "Model 2 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 81.66171741485596 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1805, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.1513, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0711, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.049, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "Epoch 10/10, Train Loss: 0.0377, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7258\n",
      "Model 3 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.16668391227722 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9669, F1 Micro: 0.9749, F1 Macro: 0.8162\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 532.2104831650549\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.04552149772644 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2488, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Epoch 6/10, Train Loss: 0.09, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7225\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7283\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7966\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Model 1 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 81.37499022483826 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2463, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1816, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1434, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 6/10, Train Loss: 0.0893, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 7/10, Train Loss: 0.065, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7973\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Model 2 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 82.84016394615173 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.257, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1856, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1077, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0702, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "Epoch 8/10, Train Loss: 0.0542, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6943\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7225\n",
      "Model 3 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 86.35742688179016 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7475\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 523.4458869601\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.712472438812256 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2422, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1646, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1663, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1134, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0911, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7677\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7538\n",
      "Epoch 8/10, Train Loss: 0.05, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7283\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Model 1 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7677\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 84.2387433052063 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.241, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1665, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1376, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1049, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0857, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7556\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0541, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8067\n",
      "Epoch 9/10, Train Loss: 0.0413, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Model 2 - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 86.1435170173645 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2486, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1679, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0576, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7709\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7967\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8214\n",
      "Model 3 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 87.90750432014465 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7818\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 524.1320694584775\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.201582908630371 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2584, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1867, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Epoch 5/10, Train Loss: 0.1092, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 6/10, Train Loss: 0.0725, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0337, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Model 1 - Iteration 330: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.29612946510315 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1836, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0794, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7701\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Model 2 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.52194285392761 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2628, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1861, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1882, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 6/10, Train Loss: 0.0811, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.737\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0503, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7967\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8038\n",
      "Model 3 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 89.3379123210907 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9674, F1 Micro: 0.9752, F1 Macro: 0.7739\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 459.58815081276435\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.490028142929077 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2451, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.179, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1583, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7621\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9535, F1 Micro: 0.9647, F1 Macro: 0.7153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0767, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0537, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0337, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "Model 1 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 92.56142234802246 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2434, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1803, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1212, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7214\n",
      "Epoch 6/10, Train Loss: 0.0851, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Epoch 8/10, Train Loss: 0.0426, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.738\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7867\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8025\n",
      "Model 2 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.36714887619019 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2536, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8451\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.8185\n",
      "Model 3 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.93      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.94      0.82      0.85       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.43482422828674 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9685, F1 Micro: 0.9759, F1 Macro: 0.7964\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 390.095177688807\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.110201120376587 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.238, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1593, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1109, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 6/10, Train Loss: 0.0784, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.046, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7558\n",
      "Model 1 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.73      0.79      0.76       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 92.88810515403748 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1642, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1329, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "Epoch 5/10, Train Loss: 0.1171, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Epoch 6/10, Train Loss: 0.0862, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.0563, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7657\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7361\n",
      "Model 2 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.38331699371338 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.248, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1686, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1632, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0826, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7203\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 8/10, Train Loss: 0.0471, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7499\n",
      "Epoch 10/10, Train Loss: 0.0303, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7388\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.76      0.74      0.75       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.41312026977539 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7205\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 322.18235742485535\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5973494052886963 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2462, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1608, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1038, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "Epoch 6/10, Train Loss: 0.0635, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7517\n",
      "Epoch 7/10, Train Loss: 0.0563, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "Epoch 8/10, Train Loss: 0.0383, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8206\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8196\n",
      "Model 1 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.0501127243042 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2458, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.175, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1612, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1474, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1031, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0679, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.04, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8319\n",
      "Model 2 - Iteration 360: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 92.36004590988159 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.253, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 5/10, Train Loss: 0.1062, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7187\n",
      "Epoch 6/10, Train Loss: 0.0687, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7444\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8454\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0272, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8456\n",
      "Model 3 - Iteration 360: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 91.06493854522705 s\n",
      "Averaged - Iteration 360: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.7909\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 263.9350050551266\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.947252035140991 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2443, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1441, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1098, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 6/10, Train Loss: 0.0679, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7255\n",
      "Epoch 7/10, Train Loss: 0.0482, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Epoch 8/10, Train Loss: 0.0411, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "Epoch 10/10, Train Loss: 0.0187, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7918\n",
      "Model 1 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.79821062088013 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1688, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0699, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0491, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 9/10, Train Loss: 0.0314, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "Model 2 - Iteration 370: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 100.78165483474731 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2542, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1818, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1562, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7625\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0534, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7289\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Model 3 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 99.30443286895752 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7627\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 199.12686718001925\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4581751823425293 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2433, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0879, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0662, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0595, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7798\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7355\n",
      "Epoch 10/10, Train Loss: 0.0185, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7541\n",
      "Model 1 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 98.63541769981384 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2422, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1696, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1579, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1345, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 5/10, Train Loss: 0.0956, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7427\n",
      "Epoch 6/10, Train Loss: 0.0636, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.061, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.769\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Model 2 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 98.49624443054199 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2504, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1616, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1503, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Epoch 5/10, Train Loss: 0.1014, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7452\n",
      "Epoch 6/10, Train Loss: 0.0635, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.8324\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7867\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Model 3 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.8324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 94.9668140411377 s\n",
      "Averaged - Iteration 380: Accuracy: 0.969, F1 Micro: 0.9763, F1 Macro: 0.7937\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 132.36011046016623\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.157829523086548 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2244, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1461, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "Epoch 5/10, Train Loss: 0.0868, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7551\n",
      "Epoch 6/10, Train Loss: 0.0593, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0528, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 9/10, Train Loss: 0.0279, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8225\n",
      "Model 1 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 97.98780059814453 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1483, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1636, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1389, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.0863, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0598, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "Epoch 7/10, Train Loss: 0.0528, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7626\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0274, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "Epoch 10/10, Train Loss: 0.0214, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "Model 2 - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 98.04385256767273 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2302, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1502, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.164, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1471, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0965, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "Epoch 6/10, Train Loss: 0.065, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0592, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7519\n",
      "Epoch 9/10, Train Loss: 0.0321, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8058\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7476\n",
      "Model 3 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.76      0.75      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 100.49541068077087 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7987\n",
      "Launching training on 2 GPUs.\n",
      "BESRA Uncertainty Score Threshold 66.14842637794487\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8212776184082031 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2381, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0967, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7234\n",
      "Epoch 6/10, Train Loss: 0.0779, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Epoch 8/10, Train Loss: 0.0346, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7511\n",
      "Epoch 9/10, Train Loss: 0.0231, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8099\n",
      "Epoch 10/10, Train Loss: 0.0235, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8032\n",
      "Model 1 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 97.26173043251038 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2335, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1731, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1596, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 5/10, Train Loss: 0.1017, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0778, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7002\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7857\n",
      "Model 2 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 97.5716233253479 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2432, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1613, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.109, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0754, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7881\n",
      "Epoch 8/10, Train Loss: 0.04, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8327\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Model 3 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 102.28548860549927 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7589\n",
      "Total sampling time: 182.1 seconds\n",
      "Total runtime: 6134.969714164734 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7624107,
     "sourceId": 12109404,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11927.862151,
   "end_time": "2025-06-09T21:21:07.524010",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-09T18:02:19.661859",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04d3b773ff8b42b4b6242a07eb48ea4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_abf73961d1a145adadd77b6dc330221c",
        "IPY_MODEL_c46fb3e8e2b545cea857a107e0a3b5f0",
        "IPY_MODEL_3c13c0601518465eb2e9c91cf7d677fc"
       ],
       "layout": "IPY_MODEL_bba2e27b83104e51ae1f091623e4533d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0be524231467473db482b4ea3d1823b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0dc8f55089534acd9d405822759a682d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "10a5dbdacaba4bed925454f0747cc09a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "148f21c008514cea8b439b483e6a0d99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1bf1154285634c0f88fd367ff7b6a7fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "202aa40ee4584debbb9078e610bb3117": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "203ce05d64164462a8ad55c8715be676": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_63d6fe06d54c46cd8eb085d5f819dc72",
        "IPY_MODEL_e5cc68f6df1f4cd18a2b0c6eb4b36f85",
        "IPY_MODEL_6296a885c7154998b4672aee880d4682"
       ],
       "layout": "IPY_MODEL_148f21c008514cea8b439b483e6a0d99",
       "tabbable": null,
       "tooltip": null
      }
     },
     "259ad59455554919995ad3f0a900c04e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2923793f3ba54eb698c6b01044958c6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_79f1d7b91ce3407493db2a1f1c619fdf",
        "IPY_MODEL_d6ffb5d5af024f2c9889f8a23e2df664",
        "IPY_MODEL_8a09a1a74bc0402691086bd5c4220336"
       ],
       "layout": "IPY_MODEL_10a5dbdacaba4bed925454f0747cc09a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2f193afae83e43d3a6d43746ee9d7142": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8145562d210b40f9943bbe48154f276f",
       "placeholder": "​",
       "style": "IPY_MODEL_259ad59455554919995ad3f0a900c04e",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "3c13c0601518465eb2e9c91cf7d677fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7a479b14d634794b470dc1545cb3363",
       "placeholder": "​",
       "style": "IPY_MODEL_44f2be61c3ac4cf39a1962264fe19568",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.46MB/s]"
      }
     },
     "44f2be61c3ac4cf39a1962264fe19568": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4c28ca92e86d41afb6c9b524e5d47328": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d7d5e3ab38848e38d1b975e12329dac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2f193afae83e43d3a6d43746ee9d7142",
        "IPY_MODEL_e12139a7bebd490897db512a0ab8dbd6",
        "IPY_MODEL_f8eb85c4fb9249089f99fb7f4a145d2b"
       ],
       "layout": "IPY_MODEL_81243994faad4858a1617947d72239cd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4f80c653b81d4e8f8844e7c654810212": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56610d65949a4e97ae79d6d525104a4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "598e013100564dda8671983ec4a5de88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5d272e14d9b84a63b9bead4fda7dacde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f43d97c63c04beaa69cdf77deeab2a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6296a885c7154998b4672aee880d4682": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4f80c653b81d4e8f8844e7c654810212",
       "placeholder": "​",
       "style": "IPY_MODEL_0dc8f55089534acd9d405822759a682d",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 11.7kB/s]"
      }
     },
     "63d6fe06d54c46cd8eb085d5f819dc72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6572c5af562c46998db82168f6a88c14",
       "placeholder": "​",
       "style": "IPY_MODEL_82dd6b44bd2843849912b39c8b627e8e",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "6572c5af562c46998db82168f6a88c14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a98f3dbbaf740d8a77547de669df4a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "79f1d7b91ce3407493db2a1f1c619fdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0be524231467473db482b4ea3d1823b5",
       "placeholder": "​",
       "style": "IPY_MODEL_6a98f3dbbaf740d8a77547de669df4a5",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "81243994faad4858a1617947d72239cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8145562d210b40f9943bbe48154f276f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82dd6b44bd2843849912b39c8b627e8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8a09a1a74bc0402691086bd5c4220336": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e3e84bed4ab14369af68595634d94283",
       "placeholder": "​",
       "style": "IPY_MODEL_202aa40ee4584debbb9078e610bb3117",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 166B/s]"
      }
     },
     "9849f5d12a7846bf9c2c8866fd161f5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d2b1a072a5f498192311dd01903a19f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abf73961d1a145adadd77b6dc330221c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d69d51d54b4e4a3487f66190ba24a892",
       "placeholder": "​",
       "style": "IPY_MODEL_5f43d97c63c04beaa69cdf77deeab2a3",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "b3453bf0f715475c8b190451682c80f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b730e100e591446da19490c5b2686b6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b7a479b14d634794b470dc1545cb3363": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bba2e27b83104e51ae1f091623e4533d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c46fb3e8e2b545cea857a107e0a3b5f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4c28ca92e86d41afb6c9b524e5d47328",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_56610d65949a4e97ae79d6d525104a4e",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "cda404ba9e794b0c8d71ab581644634d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d69d51d54b4e4a3487f66190ba24a892": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6ffb5d5af024f2c9889f8a23e2df664": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b3453bf0f715475c8b190451682c80f2",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_598e013100564dda8671983ec4a5de88",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "e12139a7bebd490897db512a0ab8dbd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d272e14d9b84a63b9bead4fda7dacde",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b730e100e591446da19490c5b2686b6d",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "e3e84bed4ab14369af68595634d94283": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5cc68f6df1f4cd18a2b0c6eb4b36f85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9d2b1a072a5f498192311dd01903a19f",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1bf1154285634c0f88fd367ff7b6a7fc",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "f8eb85c4fb9249089f99fb7f4a145d2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cda404ba9e794b0c8d71ab581644634d",
       "placeholder": "​",
       "style": "IPY_MODEL_9849f5d12a7846bf9c2c8866fd161f5f",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 179kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
