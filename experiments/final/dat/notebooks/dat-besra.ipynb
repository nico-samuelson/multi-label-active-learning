{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d562a4a",
   "metadata": {
    "papermill": {
     "duration": 0.01068,
     "end_time": "2025-04-12T12:33:35.166971",
     "exception": false,
     "start_time": "2025-04-12T12:33:35.156291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2577c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:33:35.187050Z",
     "iopub.status.busy": "2025-04-12T12:33:35.186758Z",
     "iopub.status.idle": "2025-04-12T12:33:59.893969Z",
     "shell.execute_reply": "2025-04-12T12:33:59.893258Z"
    },
    "papermill": {
     "duration": 24.719024,
     "end_time": "2025-04-12T12:33:59.895640",
     "exception": false,
     "start_time": "2025-04-12T12:33:35.176616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2dd3a1",
   "metadata": {
    "papermill": {
     "duration": 0.009364,
     "end_time": "2025-04-12T12:33:59.915258",
     "exception": false,
     "start_time": "2025-04-12T12:33:59.905894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ba4a7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:33:59.935186Z",
     "iopub.status.busy": "2025-04-12T12:33:59.934677Z",
     "iopub.status.idle": "2025-04-12T12:33:59.938220Z",
     "shell.execute_reply": "2025-04-12T12:33:59.937410Z"
    },
    "papermill": {
     "duration": 0.014701,
     "end_time": "2025-04-12T12:33:59.939379",
     "exception": false,
     "start_time": "2025-04-12T12:33:59.924678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8690796c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:33:59.960027Z",
     "iopub.status.busy": "2025-04-12T12:33:59.959771Z",
     "iopub.status.idle": "2025-04-12T12:33:59.963306Z",
     "shell.execute_reply": "2025-04-12T12:33:59.962677Z"
    },
    "papermill": {
     "duration": 0.014907,
     "end_time": "2025-04-12T12:33:59.964450",
     "exception": false,
     "start_time": "2025-04-12T12:33:59.949543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da8978f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:33:59.984668Z",
     "iopub.status.busy": "2025-04-12T12:33:59.984446Z",
     "iopub.status.idle": "2025-04-12T12:33:59.993115Z",
     "shell.execute_reply": "2025-04-12T12:33:59.992532Z"
    },
    "papermill": {
     "duration": 0.020178,
     "end_time": "2025-04-12T12:33:59.994362",
     "exception": false,
     "start_time": "2025-04-12T12:33:59.974184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c546a3",
   "metadata": {
    "papermill": {
     "duration": 0.010163,
     "end_time": "2025-04-12T12:34:00.015444",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.005281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f51d84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:00.036176Z",
     "iopub.status.busy": "2025-04-12T12:34:00.035935Z",
     "iopub.status.idle": "2025-04-12T12:34:00.087030Z",
     "shell.execute_reply": "2025-04-12T12:34:00.085649Z"
    },
    "papermill": {
     "duration": 0.063049,
     "end_time": "2025-04-12T12:34:00.088446",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.025397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-besra'\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "sequence_length = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3898e5",
   "metadata": {
    "papermill": {
     "duration": 0.010496,
     "end_time": "2025-04-12T12:34:00.108709",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.098213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "559f6ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:00.130707Z",
     "iopub.status.busy": "2025-04-12T12:34:00.130440Z",
     "iopub.status.idle": "2025-04-12T12:34:00.254111Z",
     "shell.execute_reply": "2025-04-12T12:34:00.253224Z"
    },
    "papermill": {
     "duration": 0.136203,
     "end_time": "2025-04-12T12:34:00.255434",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.119231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctors-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7623878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:00.276922Z",
     "iopub.status.busy": "2025-04-12T12:34:00.276656Z",
     "iopub.status.idle": "2025-04-12T12:34:00.293184Z",
     "shell.execute_reply": "2025-04-12T12:34:00.292257Z"
    },
    "papermill": {
     "duration": 0.028466,
     "end_time": "2025-04-12T12:34:00.294523",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.266057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4292146",
   "metadata": {
    "papermill": {
     "duration": 0.010638,
     "end_time": "2025-04-12T12:34:00.316772",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.306134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "199809ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:00.338440Z",
     "iopub.status.busy": "2025-04-12T12:34:00.338228Z",
     "iopub.status.idle": "2025-04-12T12:34:01.075986Z",
     "shell.execute_reply": "2025-04-12T12:34:01.075158Z"
    },
    "papermill": {
     "duration": 0.75055,
     "end_time": "2025-04-12T12:34:01.077689",
     "exception": false,
     "start_time": "2025-04-12T12:34:00.327139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebeb2fc52e54abdbac9d3542412b629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630f224b26024fd691976b10a9532a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addbbe044d28408e84e198741562a5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f74db37213243d8bf4e7c3876a8ff63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c35ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.102981Z",
     "iopub.status.busy": "2025-04-12T12:34:01.102644Z",
     "iopub.status.idle": "2025-04-12T12:34:01.107337Z",
     "shell.execute_reply": "2025-04-12T12:34:01.106465Z"
    },
    "papermill": {
     "duration": 0.018542,
     "end_time": "2025-04-12T12:34:01.108861",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.090319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe607a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.135380Z",
     "iopub.status.busy": "2025-04-12T12:34:01.135089Z",
     "iopub.status.idle": "2025-04-12T12:34:01.141708Z",
     "shell.execute_reply": "2025-04-12T12:34:01.140863Z"
    },
    "papermill": {
     "duration": 0.020534,
     "end_time": "2025-04-12T12:34:01.143222",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.122688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x78eb3d50b1c0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x78eb3d508f40>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataloaders(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83b641",
   "metadata": {
    "papermill": {
     "duration": 0.011991,
     "end_time": "2025-04-12T12:34:01.167571",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.155580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648cfa06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.193243Z",
     "iopub.status.busy": "2025-04-12T12:34:01.192940Z",
     "iopub.status.idle": "2025-04-12T12:34:01.197269Z",
     "shell.execute_reply": "2025-04-12T12:34:01.196359Z"
    },
    "papermill": {
     "duration": 0.018778,
     "end_time": "2025-04-12T12:34:01.198569",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.179791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2821b046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.223231Z",
     "iopub.status.busy": "2025-04-12T12:34:01.222944Z",
     "iopub.status.idle": "2025-04-12T12:34:01.228339Z",
     "shell.execute_reply": "2025-04-12T12:34:01.227430Z"
    },
    "papermill": {
     "duration": 0.019349,
     "end_time": "2025-04-12T12:34:01.229741",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.210392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f602ffd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.255528Z",
     "iopub.status.busy": "2025-04-12T12:34:01.255271Z",
     "iopub.status.idle": "2025-04-12T12:34:01.268869Z",
     "shell.execute_reply": "2025-04-12T12:34:01.267946Z"
    },
    "papermill": {
     "duration": 0.027808,
     "end_time": "2025-04-12T12:34:01.270327",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.242519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b910b0",
   "metadata": {
    "papermill": {
     "duration": 0.011045,
     "end_time": "2025-04-12T12:34:01.293050",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.282005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a72dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.318681Z",
     "iopub.status.busy": "2025-04-12T12:34:01.318373Z",
     "iopub.status.idle": "2025-04-12T12:34:01.325017Z",
     "shell.execute_reply": "2025-04-12T12:34:01.324000Z"
    },
    "papermill": {
     "duration": 0.02144,
     "end_time": "2025-04-12T12:34:01.326577",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.305137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad0bfb",
   "metadata": {
    "papermill": {
     "duration": 0.012202,
     "end_time": "2025-04-12T12:34:01.351569",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.339367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5fddbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.377241Z",
     "iopub.status.busy": "2025-04-12T12:34:01.376930Z",
     "iopub.status.idle": "2025-04-12T12:34:01.399378Z",
     "shell.execute_reply": "2025-04-12T12:34:01.398484Z"
    },
    "papermill": {
     "duration": 0.036735,
     "end_time": "2025-04-12T12:34:01.400654",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.363919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_score(p, y, alpha=0.1, beta=3):\n",
    "    \"\"\"Calculates Beta score for a given probability p and label y.\"\"\"\n",
    "    \n",
    "    if y == 1:\n",
    "        return -betaln(alpha, beta + 1) + betaln(alpha + p, beta + 1 - p)\n",
    "    elif y == 0:\n",
    "        return -betaln(alpha + 1, beta) + betaln(alpha + 1 - p, beta + p)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: y must be 0 or 1.\")\n",
    "\n",
    "def bayesian_update(prior, likelihood, evidence, alpha=0.1, beta_param=3):\n",
    "    \"\"\" \n",
    "    Bayes' Theorem: P(y'|x') = P(x'|y') * P(y') / P(x')\n",
    "    P(y'|x') or likelihood = model probs\n",
    "    p(y') or prior = class probabilities\n",
    "    p(x') or evidence = 1 / number of data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Beta score to simulate the posterior\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    \n",
    "    # We calculate the posterior using the Beta distribution\n",
    "    return posterior\n",
    "\n",
    "def compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx):\n",
    "    scores_before = []\n",
    "    scores_after = []\n",
    "\n",
    "    # Before data addition: calculate Beta score for predicted prob\n",
    "    scores_before.append(beta_score(predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    scores_before.append(beta_score(1-predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    \n",
    "    # After data addition: use Bayesian update (posterior probability)\n",
    "    for k in range(2):\n",
    "        prior = predicted_prob\n",
    "        likelihood = class_probs[class_idx][k]  # Likelihood is the true label (0 or 1)\n",
    "        posterior = bayesian_update(prior, likelihood, 1)\n",
    "        scores_after.append(beta_score(posterior, int(1 if posterior >= 0.5 else 0)))\n",
    "\n",
    "    score_diff_0 = scores_after[0] - scores_before[0]\n",
    "    score_diff_1 = scores_after[1] - scores_before[1]\n",
    "    return label_probs['0'] * score_diff_0 + label_probs['1'] * score_diff_1\n",
    "\n",
    "# Function to compute Expected Score Change (âˆ†Q)\n",
    "def besra_sampling(models, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    \n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    labeled_dataset = DoctorAnswerDataset(current_X_train, current_y_train, tokenizer, max_length=sequence_length)\n",
    "    label_probs = labeled_dataset.get_global_probs()\n",
    "    class_probs = labeled_dataset.get_per_class_probs()\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    start_time = time.time()\n",
    "    score_changes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        model_probs = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.sigmoid(logits)  # Multi-label classification uses sigmoid\n",
    "                model_probs.append(probs.unsqueeze(0))  # Add batch dimension for averaging\n",
    "        \n",
    "        # Stack all model predictions and compute the mean across models\n",
    "        model_probs = torch.cat(model_probs, dim=0)  # Concatenate predictions across models\n",
    "        probs = model_probs.mean(dim=0)  # Take the mean along the model axis\n",
    "\n",
    "        # Calculate Beta scores before and after data addition\n",
    "        for i in range(len(probs)):\n",
    "            score_diff = []\n",
    "            for class_idx in range(probs.shape[1]):\n",
    "                predicted_prob = probs[i, class_idx].item()\n",
    "                score_diff.append(compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx))\n",
    "            \n",
    "            score_changes.append(np.mean(score_diff))\n",
    "    \n",
    "    accelerator.wait_for_everyone()    \n",
    "    if accelerator.is_local_main_process:\n",
    "        score_changes = np.array(score_changes)\n",
    "        score_changes = score_changes.reshape(-1, 1)\n",
    "\n",
    "        target_samples = math.ceil(0.1 * len(X_pool))\n",
    "        collected_indices = set()\n",
    "        thresholds = []\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "\n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(score_changes)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(score_changes[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    '1-FR': [y_train[i][0] for i in temp],\n",
    "                    '2-GI': [y_train[i][1] for i in temp],\n",
    "                    '3-PI': [y_train[i][2] for i in temp],\n",
    "                    '4-DM': [y_train[i][3] for i in temp],\n",
    "                    '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                    '6-RE': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dce8ba",
   "metadata": {
    "papermill": {
     "duration": 0.012677,
     "end_time": "2025-04-12T12:34:01.425160",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.412483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a5f173c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.450390Z",
     "iopub.status.busy": "2025-04-12T12:34:01.450119Z",
     "iopub.status.idle": "2025-04-12T12:34:01.461166Z",
     "shell.execute_reply": "2025-04-12T12:34:01.460410Z"
    },
    "papermill": {
     "duration": 0.024649,
     "end_time": "2025-04-12T12:34:01.462371",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.437722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "\n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}')\n",
    "            models.append(model)\n",
    "        \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (models, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b38e320",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.486529Z",
     "iopub.status.busy": "2025-04-12T12:34:01.486295Z",
     "iopub.status.idle": "2025-04-12T12:34:01.489575Z",
     "shell.execute_reply": "2025-04-12T12:34:01.488970Z"
    },
    "papermill": {
     "duration": 0.016471,
     "end_time": "2025-04-12T12:34:01.490824",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.474353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [[50, 67, 42], [81, 90, 11], [14, 7, 33], [3, 44, 85], [94, 21, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8611636f",
   "metadata": {
    "papermill": {
     "duration": 0.012389,
     "end_time": "2025-04-12T12:34:01.515436",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.503047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d35c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.615, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2856, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2023, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1278, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2059, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2132, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1384, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0898, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.320504665374756 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6337, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3845, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.301, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2196, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1882, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1392, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2195, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2409, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1562, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1024, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.52383351325989 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5833, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3269, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2131, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2275, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1403, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.53197193145752 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 17.991623878479004 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4872, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2072, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1904, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.151, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1454, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.136, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1353, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1092, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.5465247631073 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3006, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2126, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1988, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1533, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1335, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1238, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.80923581123352 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2737, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1978, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1909, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1388, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1314, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.109, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.11188268661499 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 19.86781072616577 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4035, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.175, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1514, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1646, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1427, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Model 1 - Iteration 97: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.260809659957886 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.437, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.226, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1603, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1765, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1082, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1112, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.1171, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Model 2 - Iteration 97: Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 47.566163778305054 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3847, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1714, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.0905, Accuracy: 0.9567, F1 Micro: 0.9668, F1 Macro: 0.6494\n",
      "Epoch 10/10, Train Loss: 0.0968, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 3 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.90712785720825 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9589, F1 Micro: 0.9687, F1 Macro: 0.6513\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 17.53180766105652 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1825, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1686, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 9/10, Train Loss: 0.0801, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.0804, Accuracy: 0.9551, F1 Micro: 0.9658, F1 Macro: 0.6489\n",
      "Model 1 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.89616823196411 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4004, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1905, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1966, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1895, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1308, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1148, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 9/10, Train Loss: 0.1038, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.101, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Model 2 - Iteration 128: Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.17254948616028 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3547, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1797, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1972, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1866, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1716, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1538, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1139, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.0909, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.6488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0842, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 10/10, Train Loss: 0.0788, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 128: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 50.665627241134644 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9594, F1 Micro: 0.9691, F1 Macro: 0.6515\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 15.970755815505981 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.336, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1185, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 8/10, Train Loss: 0.092, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0784, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Model 1 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.32685160636902 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3564, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1774, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1434, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1524, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0955, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 9/10, Train Loss: 0.0738, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Model 2 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 56.280572175979614 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3165, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1701, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1531, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1417, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1459, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0897, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 10/10, Train Loss: 0.0678, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Model 3 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 59.882241010665894 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9608, F1 Micro: 0.9701, F1 Macro: 0.6566\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 14.152815341949463 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3332, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1576, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1204, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6526\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.1135, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 8/10, Train Loss: 0.0836, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 9/10, Train Loss: 0.066, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Model 1 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.93      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 57.3404860496521 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1811, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.1229, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 8/10, Train Loss: 0.0895, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 9/10, Train Loss: 0.0679, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Model 2 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.51827573776245 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.126, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 6/10, Train Loss: 0.1198, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.113, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 8/10, Train Loss: 0.0819, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.716\n",
      "Model 3 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 57.61482763290405 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9614, F1 Micro: 0.9706, F1 Macro: 0.6561\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 12.728511810302734 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2985, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1447, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1399, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.1176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 8/10, Train Loss: 0.0874, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Model 1 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 61.43497824668884 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3185, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1357, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1182, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.6566\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 9/10, Train Loss: 0.0545, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Model 2 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.6566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 64.89530611038208 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2824, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1496, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1105, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0977, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Model 3 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 69.15143013000488 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9621, F1 Micro: 0.9711, F1 Macro: 0.6559\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 11.451860666275024 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2917, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1455, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1026, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0574, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Model 1 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.76164817810059 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3132, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1503, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1819, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1479, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 6/10, Train Loss: 0.12, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 8/10, Train Loss: 0.0671, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.066, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Model 2 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 67.64699602127075 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2802, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1443, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 6/10, Train Loss: 0.1059, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 8/10, Train Loss: 0.0636, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 9/10, Train Loss: 0.0584, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7172\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Model 3 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.34978437423706 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9626, F1 Micro: 0.9715, F1 Macro: 0.6631\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 10.18775987625122 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2866, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1531, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 5/10, Train Loss: 0.1193, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0692, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0532, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7503\n",
      "Epoch 10/10, Train Loss: 0.0407, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7785\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.76      0.75      0.75       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.39525413513184 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3014, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1826, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1573, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7266\n",
      "Epoch 9/10, Train Loss: 0.052, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Epoch 10/10, Train Loss: 0.0452, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Model 2 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 72.3183012008667 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1149, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0897, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 7/10, Train Loss: 0.0602, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Epoch 8/10, Train Loss: 0.0575, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Epoch 9/10, Train Loss: 0.0492, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Model 3 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.17379522323608 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6706\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 9.248712301254272 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2796, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1893, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1652, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1468, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1147, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7264\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7124\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9551, F1 Micro: 0.9656, F1 Macro: 0.7113\n",
      "Epoch 9/10, Train Loss: 0.0612, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7275\n",
      "Epoch 10/10, Train Loss: 0.0413, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7266\n",
      "Model 1 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.10560750961304 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.291, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1922, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1684, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1564, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1264, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "Epoch 6/10, Train Loss: 0.1373, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.11, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0416, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7225\n",
      "Model 2 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 74.23519659042358 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1914, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1077, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Epoch 6/10, Train Loss: 0.1079, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0626, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.0392, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7383\n",
      "Model 3 - Iteration 250: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 74.27544045448303 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9635, F1 Micro: 0.9722, F1 Macro: 0.6749\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 8.780327796936035 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2992, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1615, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1565, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 5/10, Train Loss: 0.1277, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7621\n",
      "Epoch 6/10, Train Loss: 0.0797, Accuracy: 0.9535, F1 Micro: 0.9651, F1 Macro: 0.728\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9535, F1 Micro: 0.9649, F1 Macro: 0.7115\n",
      "Epoch 8/10, Train Loss: 0.0686, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7308\n",
      "Epoch 9/10, Train Loss: 0.0505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7383\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7358\n",
      "Model 1 - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.265629529953 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1639, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.9535, F1 Micro: 0.9651, F1 Macro: 0.728\n",
      "Epoch 6/10, Train Loss: 0.0915, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7287\n",
      "Epoch 7/10, Train Loss: 0.0657, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 9/10, Train Loss: 0.0536, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "Model 2 - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 72.82964491844177 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1601, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1529, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7342\n",
      "Epoch 6/10, Train Loss: 0.0756, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.762\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 10/10, Train Loss: 0.0365, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6985\n",
      "Model 3 - Iteration 265: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.74      0.79      0.77       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.98493003845215 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9638, F1 Micro: 0.9723, F1 Macro: 0.6798\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.945001125335693 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2842, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1642, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1566, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 6/10, Train Loss: 0.1009, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 7/10, Train Loss: 0.0738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7256\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7207\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.7113\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Model 1 - Iteration 279: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.46834754943848 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2951, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1668, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0763, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0656, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 9/10, Train Loss: 0.0522, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0467, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Model 2 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.5487585067749 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2737, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1648, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1572, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7451\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7256\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 8/10, Train Loss: 0.0603, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Model 3 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.12522172927856 s\n",
      "Averaged - Iteration 279: Accuracy: 0.964, F1 Micro: 0.9725, F1 Macro: 0.6808\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.1636998653411865 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2842, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1232, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.1138, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0775, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 7/10, Train Loss: 0.0752, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7146\n",
      "Epoch 8/10, Train Loss: 0.0526, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "Model 1 - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.82774090766907 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3001, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.134, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0836, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0794, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0562, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.057, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "Model 2 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 85.43623733520508 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1286, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0787, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0706, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Epoch 8/10, Train Loss: 0.0532, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Epoch 9/10, Train Loss: 0.0539, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0335, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 83.33067512512207 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9644, F1 Micro: 0.9728, F1 Macro: 0.6866\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.676163196563721 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2861, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.136, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1106, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0946, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.0448, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7357\n",
      "Model 1 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.13264203071594 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3028, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1434, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1247, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0937, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 7/10, Train Loss: 0.0666, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.067, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "Epoch 9/10, Train Loss: 0.0527, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0425, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Model 2 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 84.0509181022644 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1668, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0931, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0592, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 9/10, Train Loss: 0.045, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7026\n",
      "Model 3 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 84.06332159042358 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9646, F1 Micro: 0.973, F1 Macro: 0.6922\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.237706422805786 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1815, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0866, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Epoch 8/10, Train Loss: 0.0611, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7113\n",
      "Epoch 9/10, Train Loss: 0.0486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7781\n",
      "Epoch 10/10, Train Loss: 0.0366, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7164\n",
      "Model 1 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 83.65569996833801 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2845, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1556, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.109, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 6/10, Train Loss: 0.0858, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 8/10, Train Loss: 0.06, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0436, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "Epoch 10/10, Train Loss: 0.0351, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7291\n",
      "Model 2 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 84.3084557056427 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1836, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.108, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0682, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0568, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "Epoch 9/10, Train Loss: 0.0446, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7881\n",
      "Epoch 10/10, Train Loss: 0.0343, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8032\n",
      "Model 3 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 84.38983488082886 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9649, F1 Micro: 0.9732, F1 Macro: 0.6993\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.65068244934082 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1923, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1318, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1174, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Epoch 6/10, Train Loss: 0.0803, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7225\n",
      "Epoch 7/10, Train Loss: 0.0552, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7274\n",
      "Epoch 8/10, Train Loss: 0.0562, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7965\n",
      "Epoch 9/10, Train Loss: 0.0429, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 10/10, Train Loss: 0.0358, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7318\n",
      "Model 1 - Iteration 320: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.06842875480652 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2863, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1973, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1869, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.1365, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.092, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.739\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0511, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "Epoch 9/10, Train Loss: 0.0384, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7197\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7297\n",
      "Model 2 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 84.17328548431396 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1965, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1447, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Epoch 6/10, Train Loss: 0.0859, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 8/10, Train Loss: 0.0532, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Model 3 - Iteration 320: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.04269528388977 s\n",
      "Averaged - Iteration 320: Accuracy: 0.965, F1 Micro: 0.9733, F1 Macro: 0.7021\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.125621795654297 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2596, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1846, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1385, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1051, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 6/10, Train Loss: 0.0841, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7266\n",
      "Epoch 7/10, Train Loss: 0.0545, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0586, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Epoch 10/10, Train Loss: 0.0343, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "Model 1 - Iteration 330: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.2786135673523 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1849, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1458, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1093, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0855, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "Epoch 7/10, Train Loss: 0.0543, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0515, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Model 2 - Iteration 330: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.46499538421631 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2536, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1833, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1809, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1047, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0806, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0515, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0496, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7966\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 330: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 91.73217129707336 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9652, F1 Micro: 0.9734, F1 Macro: 0.7056\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.537201881408691 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.274, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1656, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1501, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 5/10, Train Loss: 0.1035, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0718, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7466\n",
      "Epoch 7/10, Train Loss: 0.0739, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7214\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8048\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Model 1 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.58580470085144 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2829, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1431, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1481, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 5/10, Train Loss: 0.1037, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7208\n",
      "Epoch 6/10, Train Loss: 0.0709, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0659, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7278\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7293\n",
      "Model 2 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.9656331539154 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1382, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1447, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 5/10, Train Loss: 0.0942, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0651, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.8009\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9567, F1 Micro: 0.9675, F1 Macro: 0.7954\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Model 3 - Iteration 340: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.67323660850525 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9653, F1 Micro: 0.9735, F1 Macro: 0.7094\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.0689098834991455 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.275, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1694, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 4/10, Train Loss: 0.1368, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1181, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0824, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0644, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7501\n",
      "Epoch 8/10, Train Loss: 0.058, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7491\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7491\n",
      "Model 1 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.76      0.75      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.92488646507263 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2902, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1851, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1728, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.14, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Epoch 6/10, Train Loss: 0.0847, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Epoch 7/10, Train Loss: 0.063, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8046\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "Model 2 - Iteration 350: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.97254681587219 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.27, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1136, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 7/10, Train Loss: 0.0615, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0527, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7475\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8041\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 93.29475021362305 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9654, F1 Micro: 0.9736, F1 Macro: 0.7125\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.6551826000213623 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2525, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.735\n",
      "Epoch 5/10, Train Loss: 0.0923, Accuracy: 0.9487, F1 Micro: 0.9602, F1 Macro: 0.7116\n",
      "Epoch 6/10, Train Loss: 0.0736, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0511, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7218\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0406, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7891\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7874\n",
      "Model 1 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.07352089881897 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2703, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 5/10, Train Loss: 0.1004, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.07, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0536, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7667\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8106\n",
      "Epoch 9/10, Train Loss: 0.0375, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7827\n",
      "Model 2 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 90.49710655212402 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2486, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 5/10, Train Loss: 0.0944, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.7199\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Model 3 - Iteration 360: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 88.85897755622864 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9655, F1 Micro: 0.9737, F1 Macro: 0.7151\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.1378657817840576 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2604, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1541, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1463, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 6/10, Train Loss: 0.079, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7215\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0397, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 10/10, Train Loss: 0.0221, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Model 1 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.82912707328796 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1684, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 6/10, Train Loss: 0.0722, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Epoch 7/10, Train Loss: 0.0538, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8049\n",
      "Epoch 8/10, Train Loss: 0.0372, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Model 2 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.81593704223633 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2524, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1676, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1591, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "Epoch 7/10, Train Loss: 0.0513, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8633\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "Epoch 10/10, Train Loss: 0.0193, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7939\n",
      "Model 3 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.83      0.86       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 95.25827407836914 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9657, F1 Micro: 0.9738, F1 Macro: 0.7203\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.5352635383605957 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2549, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1702, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1493, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 4/10, Train Loss: 0.1205, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.0901, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Epoch 6/10, Train Loss: 0.0704, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Epoch 8/10, Train Loss: 0.038, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7985\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7985\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7762\n",
      "Model 1 - Iteration 380: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.61454939842224 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2604, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1719, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1522, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1196, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 5/10, Train Loss: 0.096, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0734, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Model 2 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.35494804382324 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.243, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1703, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1216, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0889, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.0621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.0511, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7949\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Model 3 - Iteration 380: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.58751606941223 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9656, F1 Micro: 0.9738, F1 Macro: 0.7224\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0036771297454834 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2546, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1711, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1387, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 4/10, Train Loss: 0.1415, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Epoch 5/10, Train Loss: 0.0851, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7259\n",
      "Epoch 6/10, Train Loss: 0.0653, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0546, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.786\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8013\n",
      "Model 1 - Iteration 390: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.50      0.25      0.33         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.80      0.83      0.80       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.01672625541687 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1516, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Epoch 5/10, Train Loss: 0.0929, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0675, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Epoch 7/10, Train Loss: 0.051, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Model 2 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.8383309841156 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2493, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1726, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1428, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Epoch 5/10, Train Loss: 0.0847, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0631, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7865\n",
      "Epoch 7/10, Train Loss: 0.0538, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7959\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 10/10, Train Loss: 0.0196, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Model 3 - Iteration 390: Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.1207811832428 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9656, F1 Micro: 0.9738, F1 Macro: 0.7251\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.280233383178711 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2539, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1661, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1539, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7382\n",
      "Epoch 5/10, Train Loss: 0.0886, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7185\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7287\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7189\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7806\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7807\n",
      "Model 1 - Iteration 400: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.90268015861511 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2619, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1579, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.9519, F1 Micro: 0.9639, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8003\n",
      "Model 2 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.75      0.46         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.87      0.83      0.80       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 101.12238669395447 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.246, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1688, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1548, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 4/10, Train Loss: 0.1325, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7193\n",
      "Epoch 5/10, Train Loss: 0.0898, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7131\n",
      "Epoch 6/10, Train Loss: 0.0687, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7197\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7941\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7969\n",
      "Model 3 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 93.37003660202026 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9656, F1 Micro: 0.9737, F1 Macro: 0.7254\n",
      "Total sampling time: 198.93 seconds\n",
      "Total runtime: 5879.69814157486 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bd5e6",
   "metadata": {
    "papermill": {
     "duration": 0.011664,
     "end_time": "2025-04-12T12:34:01.569430",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.557766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb793a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 2\n",
      "Random seed: [81, 90, 11]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2902, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1712, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1268, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2056, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2181, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1398, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0891, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 40.08470392227173 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5962, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1207, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2089, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2205, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.139, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0885, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.234983682632446 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3321, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1752, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2191, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2272, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.145, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0942, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.24101543426514 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 16.826268911361694 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5052, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2541, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2366, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1678, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1878, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1744, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1589, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1377, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1006, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.95      0.98      0.97       406\n",
      "   macro avg       0.72      0.71      0.71       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.95      0.99      0.97       406\n",
      "\n",
      "Training completed in 44.99334788322449 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2348, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2252, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1876, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1501, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1414, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0981, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 2 - Iteration 63: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.768423318862915 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4557, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2492, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.234, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1645, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1481, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.1025, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.396722078323364 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9586, F1 Micro: 0.9686, F1 Macro: 0.6604\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 18.394705533981323 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4252, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1994, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1056, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0921, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7086\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 1 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.70      0.71       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 50.02401924133301 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3964, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1923, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1898, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1742, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1636, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.0992, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 9/10, Train Loss: 0.0909, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6512\n",
      "Epoch 10/10, Train Loss: 0.0804, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6526\n",
      "Model 2 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 46.94137907028198 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3931, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.202, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1123, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 9/10, Train Loss: 0.0896, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.6927\n",
      "Epoch 10/10, Train Loss: 0.0775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 97: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 47.93659257888794 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6641\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 16.471329927444458 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3672, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2109, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1855, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2024, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1742, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1407, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 8/10, Train Loss: 0.1124, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0785, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Model 1 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.507333517074585 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3324, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2029, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.183, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1728, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1807, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 7/10, Train Loss: 0.1319, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0828, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0733, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Model 2 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.466716289520264 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3362, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2093, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2016, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1993, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.1446, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 8/10, Train Loss: 0.1195, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Epoch 10/10, Train Loss: 0.0833, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Model 3 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.302802085876465 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9603, F1 Micro: 0.9698, F1 Macro: 0.6612\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 14.774492502212524 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3423, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1755, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1898, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1754, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Model 1 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 57.32176184654236 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1789, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "Epoch 7/10, Train Loss: 0.1127, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7639\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7518\n",
      "Epoch 9/10, Train Loss: 0.0737, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7476\n",
      "Model 2 - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 54.87653398513794 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3208, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1711, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1939, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1847, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.126, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1269, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 10/10, Train Loss: 0.062, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Model 3 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 56.40520405769348 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.66\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 13.554689884185791 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3334, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1415, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Epoch 8/10, Train Loss: 0.0766, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Epoch 9/10, Train Loss: 0.0568, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Model 1 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.53589367866516 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3139, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1699, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Epoch 6/10, Train Loss: 0.1358, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 2 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 61.02611780166626 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3131, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1897, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.171, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1596, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1512, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 9/10, Train Loss: 0.0575, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.708\n",
      "Epoch 10/10, Train Loss: 0.0544, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7617\n",
      "Model 3 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.770646810531616 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9624, F1 Micro: 0.9714, F1 Macro: 0.6726\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 11.807303428649902 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3168, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.193, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1517, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1233, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 7/10, Train Loss: 0.0887, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7257\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7019\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Epoch 10/10, Train Loss: 0.0384, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8209\n",
      "Model 1 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 63.320109844207764 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3004, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1899, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1234, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 7/10, Train Loss: 0.0923, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.719\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7483\n",
      "Model 2 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 64.7633695602417 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2989, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0645, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7852\n",
      "Epoch 9/10, Train Loss: 0.0485, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7675\n",
      "Epoch 10/10, Train Loss: 0.0362, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7739\n",
      "Model 3 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.97      0.75      0.79       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 64.39281749725342 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9628, F1 Micro: 0.9717, F1 Macro: 0.6852\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 11.041414499282837 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3146, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1137, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0842, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.056, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 9/10, Train Loss: 0.0535, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7874\n",
      "Epoch 10/10, Train Loss: 0.0486, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7865\n",
      "Model 1 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 67.91016006469727 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1849, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1141, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7447\n",
      "Epoch 7/10, Train Loss: 0.0869, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0582, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8308\n",
      "Model 2 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.19415330886841 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2951, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1893, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1584, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1306, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1433, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0622, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7862\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Model 3 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 69.74528002738953 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9634, F1 Micro: 0.9721, F1 Macro: 0.7002\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 10.643656492233276 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2973, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1901, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1631, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1048, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7551\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0408, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8112\n",
      "Epoch 10/10, Train Loss: 0.0394, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7947\n",
      "Model 1 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.73      0.79      0.76       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.40223336219788 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.281, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1038, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Epoch 7/10, Train Loss: 0.0722, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0393, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7957\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7986\n",
      "Epoch 10/10, Train Loss: 0.044, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Model 2 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 71.68051838874817 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2811, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1935, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1801, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 6/10, Train Loss: 0.1344, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0808, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7458\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7852\n",
      "Epoch 9/10, Train Loss: 0.0435, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Model 3 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 72.88211059570312 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9638, F1 Micro: 0.9724, F1 Macro: 0.7066\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 8.700453519821167 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3048, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1946, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7105\n",
      "Epoch 5/10, Train Loss: 0.1066, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Epoch 6/10, Train Loss: 0.0778, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 8/10, Train Loss: 0.041, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7955\n",
      "Epoch 9/10, Train Loss: 0.0451, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "Model 1 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.10882186889648 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2848, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1921, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1716, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1443, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1032, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7291\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7274\n",
      "Epoch 7/10, Train Loss: 0.0492, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7375\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.734\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8041\n",
      "Epoch 10/10, Train Loss: 0.0364, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7383\n",
      "Model 2 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 70.80190014839172 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7743\n",
      "Epoch 6/10, Train Loss: 0.0908, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.062, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8025\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0494, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 10/10, Train Loss: 0.0375, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7923\n",
      "Model 3 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.81933641433716 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9639, F1 Micro: 0.9725, F1 Macro: 0.7141\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 9.270914793014526 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3038, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1694, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1627, Accuracy: 0.9503, F1 Micro: 0.9628, F1 Macro: 0.7143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1005, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Epoch 6/10, Train Loss: 0.0725, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7301\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8108\n",
      "Epoch 9/10, Train Loss: 0.0438, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7865\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Model 1 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.56263899803162 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.29, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Epoch 5/10, Train Loss: 0.1033, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.7235\n",
      "Epoch 6/10, Train Loss: 0.0744, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 7/10, Train Loss: 0.0639, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7187\n",
      "Epoch 8/10, Train Loss: 0.0483, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7431\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7979\n",
      "Model 2 - Iteration 265: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 71.8422315120697 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7076\n",
      "Epoch 6/10, Train Loss: 0.0791, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6948\n",
      "Epoch 7/10, Train Loss: 0.0645, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8007\n",
      "Epoch 8/10, Train Loss: 0.049, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7648\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8014\n",
      "Model 3 - Iteration 265: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.97      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.89      0.79      0.80       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.40325856208801 s\n",
      "Averaged - Iteration 265: Accuracy: 0.964, F1 Micro: 0.9726, F1 Macro: 0.7199\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.432400703430176 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2005, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1676, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7291\n",
      "Epoch 6/10, Train Loss: 0.0849, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.066, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0561, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8058\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7924\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "Model 1 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 78.12969660758972 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.254, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1989, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0842, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7382\n",
      "Epoch 8/10, Train Loss: 0.0584, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8089\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.72\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7347\n",
      "Model 2 - Iteration 279: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 76.63322734832764 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2565, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2008, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0961, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8109\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 8/10, Train Loss: 0.0551, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7976\n",
      "Epoch 9/10, Train Loss: 0.0418, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Model 3 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 78.19923710823059 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9642, F1 Micro: 0.9727, F1 Macro: 0.7238\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 6.755521297454834 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2819, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1953, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1766, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "Epoch 5/10, Train Loss: 0.1019, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7034\n",
      "Epoch 6/10, Train Loss: 0.0835, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7972\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7934\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7857\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8057\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Model 1 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 77.28757214546204 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1737, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.154, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 6/10, Train Loss: 0.0863, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7428\n",
      "Epoch 7/10, Train Loss: 0.079, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0535, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Epoch 9/10, Train Loss: 0.0476, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8148\n",
      "Model 2 - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 81.24283385276794 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1921, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1796, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7668\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0434, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.77\n",
      "Model 3 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.36977338790894 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9645, F1 Micro: 0.9729, F1 Macro: 0.7251\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.15350604057312 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.292, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1724, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1901, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1475, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.102, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7032\n",
      "Epoch 6/10, Train Loss: 0.0814, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7957\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7266\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7957\n",
      "Model 1 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 82.69476842880249 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.274, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1891, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.104, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0788, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7434\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8049\n",
      "Model 2 - Iteration 300: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.83      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 84.56942248344421 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2765, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1734, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1572, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9535, F1 Micro: 0.9647, F1 Macro: 0.6914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0896, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 7/10, Train Loss: 0.0583, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7864\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7605\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8198\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.4670250415802 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9646, F1 Micro: 0.973, F1 Macro: 0.7301\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.787226676940918 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2753, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0848, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0578, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 9/10, Train Loss: 0.0398, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7867\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7796\n",
      "Model 1 - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 82.64777660369873 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2573, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1722, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1918, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.107, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8126\n",
      "Epoch 8/10, Train Loss: 0.0569, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7966\n",
      "Epoch 10/10, Train Loss: 0.0315, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7392\n",
      "Model 2 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 82.6251471042633 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2618, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0862, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8049\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7665\n",
      "Epoch 8/10, Train Loss: 0.059, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Epoch 9/10, Train Loss: 0.0403, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7673\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8022\n",
      "Model 3 - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.83      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 82.82016825675964 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7347\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.292821645736694 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2789, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1952, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1908, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1505, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1035, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0862, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7649\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7298\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8108\n",
      "Model 1 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.94300413131714 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2604, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1023, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7952\n",
      "Epoch 6/10, Train Loss: 0.0856, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7174\n",
      "Epoch 7/10, Train Loss: 0.0672, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7421\n",
      "Epoch 8/10, Train Loss: 0.0406, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0374, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8298\n",
      "Model 2 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.64195013046265 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2658, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1967, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1557, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 5/10, Train Loss: 0.1116, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0944, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0714, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Model 3 - Iteration 320: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.11564111709595 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9649, F1 Micro: 0.9732, F1 Macro: 0.7384\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.858071327209473 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2494, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1583, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1318, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1054, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0729, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8066\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7849\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7458\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Model 1 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.88      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.03418254852295 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2363, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1668, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 6/10, Train Loss: 0.0687, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0472, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8645\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7639\n",
      "Epoch 9/10, Train Loss: 0.0267, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.83      0.86       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 85.14852952957153 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2403, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1624, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7675\n",
      "Epoch 6/10, Train Loss: 0.0796, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Model 3 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.04897856712341 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9652, F1 Micro: 0.9734, F1 Macro: 0.7435\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.1169373989105225 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2556, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1744, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1395, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.084, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7532\n",
      "Epoch 6/10, Train Loss: 0.0723, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0591, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.804\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8032\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8099\n",
      "Model 1 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.41297650337219 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2378, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1376, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.0991, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0841, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7647\n",
      "Epoch 7/10, Train Loss: 0.061, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8158\n",
      "Epoch 9/10, Train Loss: 0.0276, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8458\n",
      "Model 2 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 89.3738477230072 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2424, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1749, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1409, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Epoch 8/10, Train Loss: 0.0484, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Model 3 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.04241061210632 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9653, F1 Micro: 0.9736, F1 Macro: 0.7478\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.9695868492126465 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1889, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.095, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Epoch 6/10, Train Loss: 0.0629, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0449, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8151\n",
      "Model 1 - Iteration 350: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 89.54476976394653 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2613, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1877, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1662, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1287, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7215\n",
      "Epoch 5/10, Train Loss: 0.0983, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7566\n",
      "Epoch 7/10, Train Loss: 0.053, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0515, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8474\n",
      "Epoch 9/10, Train Loss: 0.028, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8464\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8464\n",
      "Model 2 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 89.48332071304321 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1885, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1063, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0752, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7769\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "Model 3 - Iteration 350: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.85372519493103 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9656, F1 Micro: 0.9738, F1 Macro: 0.7525\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.4757637977600098 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1622, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9647, F1 Micro: 0.9727, F1 Macro: 0.6535\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Epoch 5/10, Train Loss: 0.0975, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0683, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0489, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8046\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7273\n",
      "Epoch 9/10, Train Loss: 0.0278, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Epoch 10/10, Train Loss: 0.0207, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Model 1 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.80290293693542 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2479, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9631, F1 Micro: 0.9714, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1461, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1015, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Epoch 6/10, Train Loss: 0.072, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "Epoch 8/10, Train Loss: 0.0443, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7633\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Model 2 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 91.82337641716003 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2507, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1605, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1184, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 6/10, Train Loss: 0.0826, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0486, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.75\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Model 3 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.76      0.74      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.59527111053467 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9657, F1 Micro: 0.9739, F1 Macro: 0.7546\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.2202651500701904 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2545, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1629, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6963\n",
      "Epoch 5/10, Train Loss: 0.0907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0727, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Epoch 8/10, Train Loss: 0.0309, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8184\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8032\n",
      "Model 1 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.74      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.23078513145447 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.239, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0942, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8334\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0467, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8334\n",
      "Epoch 8/10, Train Loss: 0.031, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8206\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Model 2 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 95.81742262840271 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2406, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.148, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.1059, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.709\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Epoch 7/10, Train Loss: 0.0541, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7652\n",
      "Epoch 8/10, Train Loss: 0.0343, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Model 3 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 92.28292083740234 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9659, F1 Micro: 0.974, F1 Macro: 0.7571\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.456437349319458 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1693, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1594, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1066, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.0767, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0315, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8464\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Model 1 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 98.52067637443542 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2524, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1668, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1619, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 4/10, Train Loss: 0.1014, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Epoch 5/10, Train Loss: 0.0738, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7445\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0472, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0327, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "Model 2 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.14979553222656 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2528, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1678, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1655, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1104, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0817, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0702, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0469, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 8/10, Train Loss: 0.035, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Model 3 - Iteration 380: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 99.79103565216064 s\n",
      "Averaged - Iteration 380: Accuracy: 0.966, F1 Micro: 0.9741, F1 Macro: 0.76\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9387881755828857 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.256, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1244, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.0934, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0673, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7673\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8124\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8023\n",
      "Model 1 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 98.42986416816711 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.239, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1493, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.119, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Epoch 5/10, Train Loss: 0.0897, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0643, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0408, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7936\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8301\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.752\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8182\n",
      "Model 2 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.50      0.25      0.33         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.82      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 97.9425048828125 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2433, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1535, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.131, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 5/10, Train Loss: 0.1065, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Epoch 6/10, Train Loss: 0.0717, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0392, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7945\n",
      "Model 3 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 96.70920419692993 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9741, F1 Macro: 0.7617\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3324425220489502 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2526, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1555, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1096, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0726, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0562, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8169\n",
      "Epoch 7/10, Train Loss: 0.0446, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0339, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8058\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8039\n",
      "Epoch 10/10, Train Loss: 0.021, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.786\n",
      "Model 1 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 99.96303200721741 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2376, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1533, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1184, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0739, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Epoch 6/10, Train Loss: 0.0582, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0453, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Model 2 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 101.43976998329163 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2427, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.083, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0652, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Model 3 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 99.71999454498291 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9662, F1 Micro: 0.9742, F1 Macro: 0.7633\n",
      "Total sampling time: 189.27 seconds\n",
      "Total runtime: 5939.852207183838 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335b1a7",
   "metadata": {
    "papermill": {
     "duration": 0.012205,
     "end_time": "2025-04-12T12:34:01.622256",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.610051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b33e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 3\n",
      "Random seed: [14, 7, 33]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5538, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3244, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1984, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1747, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2059, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2186, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.135, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0926, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.298264026641846 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6355, Accuracy: 0.9471, F1 Micro: 0.9589, F1 Macro: 0.6426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2057, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2109, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2266, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1429, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0905, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 37.61404538154602 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5409, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3084, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.268, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1928, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1677, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2093, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2247, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 37.876453161239624 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 16.657130241394043 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4536, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2809, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1799, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.184, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1423, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1384, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1311, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1036, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 1 - Iteration 63: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 42.339507818222046 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5284, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2885, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1846, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1405, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1406, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1373, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1163, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 41.37070608139038 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4388, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1847, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1454, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1468, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1271, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 42.298030376434326 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9586, F1 Micro: 0.9686, F1 Macro: 0.6512\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 17.616461277008057 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3904, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2144, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1598, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1443, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 9/10, Train Loss: 0.0835, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6507\n",
      "Model 1 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.82196354866028 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4347, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2196, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.201, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1645, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.153, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 10/10, Train Loss: 0.0766, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Model 2 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.116942167282104 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3741, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2148, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1982, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1436, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1766, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 9/10, Train Loss: 0.1027, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0849, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Model 3 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.43619704246521 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9605, F1 Micro: 0.9699, F1 Macro: 0.652\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 16.716397762298584 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2049, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1657, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 7/10, Train Loss: 0.1493, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Model 1 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 43.90130114555359 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3998, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2091, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1888, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1679, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 7/10, Train Loss: 0.154, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1153, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.071, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Model 2 - Iteration 128: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.46892213821411 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.351, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2045, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1917, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1825, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1936, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1746, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 7/10, Train Loss: 0.1691, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 8/10, Train Loss: 0.1284, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0833, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0718, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Model 3 - Iteration 128: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 47.13532495498657 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9614, F1 Micro: 0.9706, F1 Macro: 0.6656\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 15.125037431716919 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3282, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2043, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2045, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1785, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1604, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1535, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.1092, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.6502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.693\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7003\n",
      "Model 1 - Iteration 156: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 50.87877154350281 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3554, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2026, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2054, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1538, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Epoch 8/10, Train Loss: 0.0957, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7501\n",
      "Epoch 9/10, Train Loss: 0.0824, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7617\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.761\n",
      "Model 2 - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.70      0.70      0.70       406\n",
      "weighted avg       0.96      0.97      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.276243686676025 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3185, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2046, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2067, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1658, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 7/10, Train Loss: 0.1194, Accuracy: 0.9551, F1 Micro: 0.9658, F1 Macro: 0.6489\n",
      "Epoch 8/10, Train Loss: 0.1058, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Model 3 - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 50.61267614364624 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6761\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 13.556145191192627 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3276, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.174, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "Epoch 6/10, Train Loss: 0.1333, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.0926, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.6509\n",
      "Model 1 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.94      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 50.5399329662323 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3475, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1893, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1769, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9631, F1 Micro: 0.9714, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.081, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "Epoch 8/10, Train Loss: 0.0719, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7623\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7345\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Model 2 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 55.052894592285156 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3116, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1907, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1758, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1808, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 6/10, Train Loss: 0.1402, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7022\n",
      "Epoch 8/10, Train Loss: 0.0785, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7179\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7187\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.7646\n",
      "Model 3 - Iteration 181: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 51.24462103843689 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9624, F1 Micro: 0.9713, F1 Macro: 0.6787\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 12.327219724655151 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3179, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1835, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1637, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7096\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7179\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0496, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Model 1 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 59.75060439109802 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.341, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1645, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.0953, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.751\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0552, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.737\n",
      "Epoch 10/10, Train Loss: 0.0401, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7626\n",
      "Model 2 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.94      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.97      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.3447425365448 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3112, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1837, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.174, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1348, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1056, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8305\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Model 3 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.45501255989075 s\n",
      "Averaged - Iteration 203: Accuracy: 0.963, F1 Micro: 0.9717, F1 Macro: 0.6939\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 11.051703214645386 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.288, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2007, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1329, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6953\n",
      "Epoch 7/10, Train Loss: 0.0897, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 9/10, Train Loss: 0.0394, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0439, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Model 1 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.03907227516174 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3121, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2001, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1928, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7334\n",
      "Epoch 6/10, Train Loss: 0.0774, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7627\n",
      "Epoch 7/10, Train Loss: 0.085, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "Epoch 9/10, Train Loss: 0.0409, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.82\n",
      "Epoch 10/10, Train Loss: 0.0495, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8303\n",
      "Model 2 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 56.63959074020386 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1988, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.0643, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0433, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8023\n",
      "Model 3 - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 61.507479667663574 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9635, F1 Micro: 0.9721, F1 Macro: 0.7053\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 10.107649087905884 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3031, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1521, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1311, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "Epoch 6/10, Train Loss: 0.0985, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7186\n",
      "Epoch 8/10, Train Loss: 0.0395, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7867\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7676\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.494526624679565 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3199, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1803, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1327, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7337\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.099, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0778, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8315\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.8186\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8175\n",
      "Model 2 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.18239092826843 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2918, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.178, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0974, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0884, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8305\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Epoch 10/10, Train Loss: 0.0313, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8304\n",
      "Model 3 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 63.96109962463379 s\n",
      "Averaged - Iteration 241: Accuracy: 0.964, F1 Micro: 0.9725, F1 Macro: 0.7128\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 9.078634262084961 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2823, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1928, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 7/10, Train Loss: 0.0757, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Epoch 9/10, Train Loss: 0.046, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Model 1 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.88027548789978 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2963, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1927, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.155, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0949, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.752\n",
      "Epoch 7/10, Train Loss: 0.0635, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.8275\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.8162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8307\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7505\n",
      "Model 2 - Iteration 250: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 63.908687114715576 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2745, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1723, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7187\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0762, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0506, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Model 3 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 69.58828139305115 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9643, F1 Micro: 0.9727, F1 Macro: 0.7203\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 8.578993558883667 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2857, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1485, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 5/10, Train Loss: 0.1088, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7213\n",
      "Epoch 7/10, Train Loss: 0.0619, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7677\n",
      "Epoch 9/10, Train Loss: 0.0377, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7875\n",
      "Model 1 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 66.22541165351868 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3012, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1764, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1607, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1211, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Epoch 5/10, Train Loss: 0.092, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7418\n",
      "Epoch 6/10, Train Loss: 0.0546, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7945\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8026\n",
      "Model 2 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 67.01874351501465 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1774, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1518, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 5/10, Train Loss: 0.1044, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Epoch 6/10, Train Loss: 0.0653, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0606, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 10/10, Train Loss: 0.0235, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.8026\n",
      "Model 3 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 65.64067268371582 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9646, F1 Micro: 0.973, F1 Macro: 0.7291\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 7.784406423568726 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2812, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1405, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.6546\n",
      "Epoch 6/10, Train Loss: 0.0969, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7011\n",
      "Epoch 7/10, Train Loss: 0.0641, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7217\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.8012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8447\n",
      "Model 1 - Iteration 279: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.94      0.83      0.84       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 68.99143767356873 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3012, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1703, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1383, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1145, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.764\n",
      "Epoch 7/10, Train Loss: 0.0629, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Epoch 8/10, Train Loss: 0.0496, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7529\n",
      "Epoch 9/10, Train Loss: 0.0473, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.7784\n",
      "Epoch 10/10, Train Loss: 0.0353, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8106\n",
      "Model 2 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 65.97532367706299 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2754, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1851, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1763, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1619, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1398, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7637\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7374\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8056\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "Model 3 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 68.26294255256653 s\n",
      "Averaged - Iteration 279: Accuracy: 0.965, F1 Micro: 0.9732, F1 Macro: 0.7343\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.001933574676514 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2805, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1815, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.155, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7242\n",
      "Epoch 7/10, Train Loss: 0.0661, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.771\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7032\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7701\n",
      "Epoch 10/10, Train Loss: 0.0206, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7042\n",
      "Model 1 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 70.86102962493896 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2951, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1804, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1615, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1237, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0978, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0733, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 7/10, Train Loss: 0.0636, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 9/10, Train Loss: 0.0428, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8099\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7344\n",
      "Model 2 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.76       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 69.97422361373901 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2719, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1819, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1543, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 5/10, Train Loss: 0.116, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0808, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0656, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8334\n",
      "Epoch 8/10, Train Loss: 0.0426, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7667\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8041\n",
      "Epoch 10/10, Train Loss: 0.0213, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7399\n",
      "Model 3 - Iteration 292: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.92      0.83      0.83       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 69.97793579101562 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9654, F1 Micro: 0.9736, F1 Macro: 0.7374\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.4457995891571045 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2809, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1556, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7213\n",
      "Epoch 6/10, Train Loss: 0.0827, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.6992\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7891\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7689\n",
      "Epoch 9/10, Train Loss: 0.0369, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.82\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8143\n",
      "Model 1 - Iteration 300: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 71.26656651496887 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1238, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1173, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7268\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0631, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7484\n",
      "Model 2 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.25671935081482 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7004\n",
      "Epoch 6/10, Train Loss: 0.0799, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0588, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 8/10, Train Loss: 0.0567, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7868\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7891\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7154\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 69.28212761878967 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9656, F1 Micro: 0.9737, F1 Macro: 0.7422\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples:10 \n",
      "Sampling duration: 5.9618589878082275 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2749, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1754, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1556, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0854, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0466, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7659\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Model 1 - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 75.54250741004944 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2906, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1753, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1499, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Epoch 5/10, Train Loss: 0.0953, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.743\n",
      "Epoch 6/10, Train Loss: 0.0745, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0698, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "Epoch 9/10, Train Loss: 0.0435, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0324, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "Model 2 - Iteration 310: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 72.07811737060547 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2673, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.086, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0694, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.795\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7945\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7931\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8108\n",
      "Model 3 - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.20536804199219 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9656, F1 Micro: 0.9737, F1 Macro: 0.7453\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.553017616271973 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1442, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1012, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Epoch 6/10, Train Loss: 0.0848, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0617, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8046\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Epoch 9/10, Train Loss: 0.0313, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7791\n",
      "Model 1 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.2574303150177 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2811, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.179, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1646, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1205, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Epoch 5/10, Train Loss: 0.0877, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0627, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8138\n",
      "Epoch 8/10, Train Loss: 0.0375, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7275\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7934\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7192\n",
      "Model 2 - Iteration 320: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.92      0.78      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.28671836853027 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2586, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.18, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0934, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0681, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0372, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0337, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Model 3 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 76.76031517982483 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9657, F1 Micro: 0.9738, F1 Macro: 0.7479\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.170418739318848 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2405, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1549, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Epoch 5/10, Train Loss: 0.0989, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0394, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6937\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.698\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7025\n",
      "Model 1 - Iteration 330: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.01374745368958 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.25, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1544, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1455, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1113, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 6/10, Train Loss: 0.0664, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 7/10, Train Loss: 0.0411, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.785\n",
      "Epoch 8/10, Train Loss: 0.0468, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.8083\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8032\n",
      "Model 2 - Iteration 330: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.24223566055298 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2342, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1555, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1583, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1502, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1048, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7008\n",
      "Epoch 6/10, Train Loss: 0.0795, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0408, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0486, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7948\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "Model 3 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 77.42422652244568 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9657, F1 Micro: 0.9738, F1 Macro: 0.747\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.507641315460205 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1757, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1523, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0546, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "Model 1 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 80.06915831565857 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2736, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1616, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1174, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0929, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0749, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.73\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Model 2 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 76.04425430297852 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2555, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1782, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1772, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 5/10, Train Loss: 0.1182, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0864, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0609, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7954\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7277\n",
      "Epoch 9/10, Train Loss: 0.0279, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7382\n",
      "Epoch 10/10, Train Loss: 0.0241, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7459\n",
      "Model 3 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 77.15586495399475 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7494\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.9554333686828613 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2561, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1593, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1388, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1065, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0656, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Epoch 7/10, Train Loss: 0.0565, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6958\n",
      "Epoch 8/10, Train Loss: 0.0433, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0249, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Model 1 - Iteration 350: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.92848110198975 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.269, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1674, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1423, Accuracy: 0.9503, F1 Micro: 0.9628, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.104, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7193\n",
      "Epoch 5/10, Train Loss: 0.0923, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 6/10, Train Loss: 0.0627, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.727\n",
      "Epoch 7/10, Train Loss: 0.0488, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7626\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Epoch 9/10, Train Loss: 0.0229, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7923\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Model 2 - Iteration 350: Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.93      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.97      0.97       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 73.162602186203 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2496, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1654, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1058, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0704, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0542, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0248, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7639\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.92794108390808 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9658, F1 Micro: 0.9738, F1 Macro: 0.7498\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5457208156585693 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1568, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1401, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1117, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7019\n",
      "Epoch 6/10, Train Loss: 0.0758, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7875\n",
      "Epoch 10/10, Train Loss: 0.0193, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8127\n",
      "Model 1 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 79.41931772232056 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2679, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1531, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1401, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1054, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0876, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0637, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7676\n",
      "Model 2 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.47689318656921 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1362, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0721, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8327\n",
      "Epoch 8/10, Train Loss: 0.0429, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8116\n",
      "Epoch 10/10, Train Loss: 0.0186, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Model 3 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 80.77343106269836 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9659, F1 Micro: 0.974, F1 Macro: 0.7532\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.1756510734558105 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2338, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1692, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1453, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1013, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0727, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7044\n",
      "Epoch 7/10, Train Loss: 0.0407, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0383, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7235\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7892\n",
      "Model 1 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7235\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 83.38616824150085 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2481, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.135, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1116, Accuracy: 0.9487, F1 Micro: 0.9614, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0979, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.069, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0459, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0312, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "Model 2 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.16085314750671 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2304, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1681, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1131, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 6/10, Train Loss: 0.0847, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0478, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8314\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8041\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8123\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8122\n",
      "Model 3 - Iteration 370: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.94      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 81.18884706497192 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9741, F1 Macro: 0.7552\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.476533889770508 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2492, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1497, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1474, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0839, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0764, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7382\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.8304\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7694\n",
      "Model 1 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.93433284759521 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2611, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1481, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 4/10, Train Loss: 0.1072, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0741, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 6/10, Train Loss: 0.069, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.8017\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8308\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.831\n",
      "Model 2 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 82.76002216339111 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2417, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1496, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1798, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0799, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7349\n",
      "Epoch 6/10, Train Loss: 0.0734, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.7828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0283, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7225\n",
      "Model 3 - Iteration 380: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.70      0.75      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 86.53655672073364 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9741, F1 Macro: 0.7561\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.138354539871216 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2432, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1571, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1481, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1284, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Epoch 5/10, Train Loss: 0.0917, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6995\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0677, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0445, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0305, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8117\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8318\n",
      "Model 1 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.64759230613708 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1548, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1342, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7344\n",
      "Epoch 4/10, Train Loss: 0.1006, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0796, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.764\n",
      "Epoch 6/10, Train Loss: 0.0635, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7428\n",
      "Epoch 7/10, Train Loss: 0.0478, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7529\n",
      "Epoch 8/10, Train Loss: 0.0339, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7256\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8182\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8179\n",
      "Model 2 - Iteration 390: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.78      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.145259141922 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2354, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1569, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1479, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1228, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0916, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7374\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7261\n",
      "Epoch 7/10, Train Loss: 0.0454, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0315, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 9/10, Train Loss: 0.0271, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "Model 3 - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 84.74950551986694 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9662, F1 Micro: 0.9741, F1 Macro: 0.7574\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5475375652313232 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2402, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1442, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6549\n",
      "Epoch 5/10, Train Loss: 0.1001, Accuracy: 0.9503, F1 Micro: 0.9611, F1 Macro: 0.6438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0762, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7035\n",
      "Epoch 7/10, Train Loss: 0.0455, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7204\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 9/10, Train Loss: 0.0271, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0233, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.778\n",
      "Model 1 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.75      0.78       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.04636883735657 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2519, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1445, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 3/10, Train Loss: 0.1466, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1075, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Epoch 5/10, Train Loss: 0.083, Accuracy: 0.9535, F1 Micro: 0.9642, F1 Macro: 0.7153\n",
      "Epoch 6/10, Train Loss: 0.0661, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7308\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.9535, F1 Micro: 0.9649, F1 Macro: 0.7332\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9551, F1 Micro: 0.966, F1 Macro: 0.7283\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Model 2 - Iteration 400: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.74      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.40037965774536 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2357, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1435, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1435, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1016, Accuracy: 0.9551, F1 Micro: 0.9651, F1 Macro: 0.7302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0819, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0477, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0313, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "Model 3 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.41895461082458 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9662, F1 Micro: 0.9742, F1 Macro: 0.7583\n",
      "Total sampling time: 190.08 seconds\n",
      "Total runtime: 5260.374185800552 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872ceef",
   "metadata": {
    "papermill": {
     "duration": 0.011108,
     "end_time": "2025-04-12T12:34:01.674355",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.663247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f22a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T12:34:01.697221Z",
     "iopub.status.busy": "2025-04-12T12:34:01.696978Z",
     "iopub.status.idle": "2025-04-12T14:12:22.280217Z",
     "shell.execute_reply": "2025-04-12T14:12:22.279377Z"
    },
    "papermill": {
     "duration": 5900.596441,
     "end_time": "2025-04-12T14:12:22.281695",
     "exception": false,
     "start_time": "2025-04-12T12:34:01.685254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 4\n",
      "Random seed: [3, 44, 85]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2955, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2125, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2292, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0923, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.011518716812134 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6001, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3211, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2749, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2152, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2232, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.014365911483765 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2802, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1102, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1938, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2098, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1334, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.729321002960205 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 23.31420063972473 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4218, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2225, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1014, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1442, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1314, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1094, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1003, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.67842483520508 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4737, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2381, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1458, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1303, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1118, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0929, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.73930644989014 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4198, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1551, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1363, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1231, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1062, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0792, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 45.289193630218506 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 20.427857398986816 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1755, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1575, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1355, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1354, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1401, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1095, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0973, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.1021, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 1 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 49.415900230407715 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3869, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1775, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1333, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.128, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0986, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6504\n",
      "Epoch 10/10, Train Loss: 0.0926, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Model 2 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 47.79937815666199 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3378, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1717, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1405, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1336, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1001, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 50.637758016586304 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 17.827458381652832 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3153, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1572, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1488, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1537, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1269, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1247, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1088, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.0782, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Model 1 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.935975074768066 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3504, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1589, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1505, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1472, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1113, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 9/10, Train Loss: 0.0977, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0694, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Model 2 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.08864784240723 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.307, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1485, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.143, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1174, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1114, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0912, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0688, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 128: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.88499069213867 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9585, F1 Micro: 0.9685, F1 Macro: 0.6511\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 15.92355751991272 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3038, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1514, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1189, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1228, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1117, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0827, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7618\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Model 1 - Iteration 156: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.114342212677 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3221, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1511, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1199, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1444, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1082, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.0973, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Model 2 - Iteration 156: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 57.43804955482483 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2945, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1521, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1568, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1173, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1221, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.1142, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.078, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 156: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 58.36087203025818 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9588, F1 Micro: 0.9687, F1 Macro: 0.6629\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 14.53609561920166 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2921, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1577, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1516, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9535, F1 Micro: 0.9651, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0826, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7939\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 10/10, Train Loss: 0.0415, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Model 1 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7939\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.80      0.79      0.79       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 60.56660556793213 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3086, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1756, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0563, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8286\n",
      "Model 2 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.97      0.79      0.83       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 63.63148355484009 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2823, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1583, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 10/10, Train Loss: 0.0397, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Model 3 - Iteration 181: Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 61.94025111198425 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9594, F1 Micro: 0.9692, F1 Macro: 0.6825\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 12.882067918777466 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1919, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 7/10, Train Loss: 0.0979, Accuracy: 0.9487, F1 Micro: 0.9614, F1 Macro: 0.7132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0533, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7628\n",
      "Epoch 10/10, Train Loss: 0.0357, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7517\n",
      "Model 1 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 66.59856605529785 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2902, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1778, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1174, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0968, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7515\n",
      "Epoch 8/10, Train Loss: 0.0705, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7166\n",
      "Epoch 9/10, Train Loss: 0.0526, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.761\n",
      "Epoch 10/10, Train Loss: 0.0361, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Model 2 - Iteration 203: Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 65.23923754692078 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 7/10, Train Loss: 0.0915, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.7123\n",
      "Epoch 8/10, Train Loss: 0.0655, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0495, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0361, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Model 3 - Iteration 203: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 64.70490503311157 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9598, F1 Micro: 0.9695, F1 Macro: 0.6913\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 11.597718000411987 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2743, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1581, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0874, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0782, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8432\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7945\n",
      "Model 1 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.81      0.79      0.79       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 70.88903856277466 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2925, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1583, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1419, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6505\n",
      "Epoch 6/10, Train Loss: 0.0755, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0776, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8009\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.0421, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.7164\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.734\n",
      "Model 2 - Iteration 223: Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8009\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.95      0.99      0.97       406\n",
      "   macro avg       0.89      0.79      0.80       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 64.32295393943787 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.157, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1443, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0812, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Model 3 - Iteration 223: Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.72      0.75      0.74       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 68.73406338691711 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9601, F1 Micro: 0.9697, F1 Macro: 0.7021\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 10.458566904067993 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1627, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1558, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9503, F1 Micro: 0.9628, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Epoch 7/10, Train Loss: 0.0656, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7625\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7617\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7803\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7608\n",
      "Model 1 - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.74      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 68.53587794303894 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2842, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1636, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1493, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.7174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.098, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Epoch 7/10, Train Loss: 0.068, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Epoch 8/10, Train Loss: 0.0407, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7999\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7913\n",
      "Model 2 - Iteration 241: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.30412530899048 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.267, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.164, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1459, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.108, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0848, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Epoch 8/10, Train Loss: 0.0371, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "Epoch 9/10, Train Loss: 0.0271, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.811\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "Model 3 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.71      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 70.3458309173584 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9606, F1 Micro: 0.9701, F1 Macro: 0.7056\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 9.848633050918579 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2767, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1924, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1779, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1694, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9551, F1 Micro: 0.9663, F1 Macro: 0.7287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0911, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7629\n",
      "Epoch 7/10, Train Loss: 0.0667, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0519, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8433\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7747\n",
      "Model 1 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.93      0.83      0.84       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.54485368728638 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2857, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.089, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0476, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7628\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7924\n",
      "Model 2 - Iteration 250: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.35640048980713 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.192, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1703, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0884, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7842\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0449, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7776\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8144\n",
      "Model 3 - Iteration 250: Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 74.79621315002441 s\n",
      "Averaged - Iteration 250: Accuracy: 0.961, F1 Micro: 0.9703, F1 Macro: 0.7145\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 9.031351089477539 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2676, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.184, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1129, Accuracy: 0.9535, F1 Micro: 0.9649, F1 Macro: 0.723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0928, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.8296\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.801\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8093\n",
      "Epoch 9/10, Train Loss: 0.0337, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7617\n",
      "Epoch 10/10, Train Loss: 0.0259, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7997\n",
      "Model 1 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.8296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.95      0.99      0.97       406\n",
      "   macro avg       0.91      0.83      0.83       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.17724347114563 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2783, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1704, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1092, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7646\n",
      "Epoch 6/10, Train Loss: 0.0845, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8286\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7847\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7486\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 10/10, Train Loss: 0.0296, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8091\n",
      "Model 2 - Iteration 265: Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.74      0.79      0.76       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 72.84190678596497 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2607, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1711, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1625, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0983, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7311\n",
      "Epoch 6/10, Train Loss: 0.0758, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7918\n",
      "Epoch 7/10, Train Loss: 0.0518, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 8/10, Train Loss: 0.0342, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.72\n",
      "Epoch 10/10, Train Loss: 0.0235, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7249\n",
      "Model 3 - Iteration 265: Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.75      0.46         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.95      0.99      0.97       406\n",
      "   macro avg       0.70      0.79      0.73       406\n",
      "weighted avg       0.95      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 73.74431800842285 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9611, F1 Micro: 0.9705, F1 Macro: 0.72\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 8.564074754714966 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2546, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1613, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1638, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7249\n",
      "Epoch 7/10, Train Loss: 0.0568, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.028, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8295\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7626\n",
      "Model 1 - Iteration 279: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      0.99      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.97      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 77.70920014381409 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1639, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 6/10, Train Loss: 0.0803, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.061, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.785\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7929\n",
      "Model 2 - Iteration 279: Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.75      0.73       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 77.14359545707703 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.255, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1624, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1255, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0343, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7668\n",
      "Epoch 9/10, Train Loss: 0.0279, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Model 3 - Iteration 279: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 78.69404339790344 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9613, F1 Micro: 0.9706, F1 Macro: 0.7254\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.533196687698364 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2452, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.125, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1101, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0644, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7626\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9583, F1 Micro: 0.968, F1 Macro: 0.8255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8198\n",
      "Model 1 - Iteration 292: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.03840851783752 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2564, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1713, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1234, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 5/10, Train Loss: 0.1141, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6991\n",
      "Epoch 6/10, Train Loss: 0.0813, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7248\n",
      "Epoch 7/10, Train Loss: 0.0651, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7189\n",
      "Epoch 8/10, Train Loss: 0.0438, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7923\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7248\n",
      "Model 2 - Iteration 292: Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 78.32170820236206 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2357, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1825, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1679, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.114, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0986, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 7/10, Train Loss: 0.0543, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.8015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8017\n",
      "Model 3 - Iteration 292: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.06003952026367 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9614, F1 Micro: 0.9707, F1 Macro: 0.7298\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.9125237464904785 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2502, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1072, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0542, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7864\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7635\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 10/10, Train Loss: 0.021, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7931\n",
      "Model 1 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.74      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.67062759399414 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2651, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1032, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 6/10, Train Loss: 0.0898, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0613, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Epoch 9/10, Train Loss: 0.0419, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7923\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Model 2 - Iteration 300: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.44707107543945 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2485, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1586, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0955, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 6/10, Train Loss: 0.0719, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "Epoch 8/10, Train Loss: 0.037, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8033\n",
      "Epoch 10/10, Train Loss: 0.021, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7533\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.73      0.75      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.66850733757019 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9618, F1 Micro: 0.971, F1 Macro: 0.7323\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.105541944503784 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2486, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1935, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1714, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1039, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.082, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0383, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Epoch 9/10, Train Loss: 0.0307, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7529\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8018\n",
      "Model 1 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 83.73352932929993 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2575, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1671, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0961, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7271\n",
      "Epoch 6/10, Train Loss: 0.0745, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0484, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.8015\n",
      "Model 2 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.11166334152222 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2425, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1914, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1347, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0932, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7024\n",
      "Epoch 6/10, Train Loss: 0.0736, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8217\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "Epoch 9/10, Train Loss: 0.0278, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8215\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8018\n",
      "Model 3 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.8217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 81.94111251831055 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9622, F1 Micro: 0.9713, F1 Macro: 0.7381\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.652893304824829 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2353, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1628, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1428, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.098, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0896, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7364\n",
      "Epoch 7/10, Train Loss: 0.0527, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7618\n",
      "Epoch 8/10, Train Loss: 0.0566, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "Model 1 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.60589814186096 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2468, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1628, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1436, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0953, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7011\n",
      "Epoch 6/10, Train Loss: 0.0792, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Epoch 8/10, Train Loss: 0.0565, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0372, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6991\n",
      "Model 2 - Iteration 320: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.78      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.2949652671814 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2333, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1631, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1323, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0877, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0728, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "Epoch 7/10, Train Loss: 0.0446, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7365\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.795\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7541\n",
      "Model 3 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 83.68658781051636 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9625, F1 Micro: 0.9715, F1 Macro: 0.7427\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.015370607376099 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2243, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.172, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.115, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0725, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0566, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8025\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0204, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "Model 1 - Iteration 330: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.16551160812378 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2347, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1388, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 5/10, Train Loss: 0.108, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0719, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0555, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7852\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7924\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7931\n",
      "Model 2 - Iteration 330: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.97      0.75      0.79       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 86.23287749290466 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2208, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1727, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1306, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 5/10, Train Loss: 0.1038, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0656, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0495, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8325\n",
      "Epoch 8/10, Train Loss: 0.0323, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.8296\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.806\n",
      "Epoch 10/10, Train Loss: 0.0213, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.806\n",
      "Model 3 - Iteration 330: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 86.28963160514832 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9628, F1 Micro: 0.9717, F1 Macro: 0.747\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.579696178436279 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2519, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1757, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1596, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1341, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1187, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "Epoch 7/10, Train Loss: 0.0708, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7928\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7639\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Model 1 - Iteration 340: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 85.87586855888367 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1764, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1365, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9535, F1 Micro: 0.9647, F1 Macro: 0.6914\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6957\n",
      "Epoch 7/10, Train Loss: 0.0785, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7867\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7193\n",
      "Epoch 9/10, Train Loss: 0.0418, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8301\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Model 2 - Iteration 340: Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 84.09142780303955 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1571, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1222, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 5/10, Train Loss: 0.0993, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0733, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "Epoch 7/10, Train Loss: 0.0553, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Epoch 8/10, Train Loss: 0.03, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7347\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7941\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8014\n",
      "Model 3 - Iteration 340: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 85.49040794372559 s\n",
      "Averaged - Iteration 340: Accuracy: 0.963, F1 Micro: 0.9719, F1 Macro: 0.7467\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.008888006210327 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2434, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1432, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1727, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.107, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Epoch 6/10, Train Loss: 0.0819, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0569, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 8/10, Train Loss: 0.0372, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Model 1 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.74      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.69934177398682 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2534, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1452, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7528\n",
      "Epoch 6/10, Train Loss: 0.0744, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7512\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "Epoch 9/10, Train Loss: 0.0243, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7264\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7357\n",
      "Model 2 - Iteration 350: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.25144910812378 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2385, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1446, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1216, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0992, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0478, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0202, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "Epoch 10/10, Train Loss: 0.0206, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.0449070930481 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9632, F1 Micro: 0.972, F1 Macro: 0.7487\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.4735283851623535 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2466, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1644, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1339, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1076, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0822, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0574, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.0441, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7625\n",
      "Epoch 9/10, Train Loss: 0.0312, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8291\n",
      "Epoch 10/10, Train Loss: 0.0184, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7625\n",
      "Model 1 - Iteration 360: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 91.95979905128479 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1657, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1496, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1279, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 5/10, Train Loss: 0.1027, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0741, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7618\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Epoch 8/10, Train Loss: 0.0438, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0316, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7192\n",
      "Model 2 - Iteration 360: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.65044713020325 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2466, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1642, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1488, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1197, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 5/10, Train Loss: 0.0875, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7358\n",
      "Epoch 6/10, Train Loss: 0.0662, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Epoch 7/10, Train Loss: 0.0468, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 8/10, Train Loss: 0.0406, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7349\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Model 3 - Iteration 360: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.8799340724945 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9632, F1 Micro: 0.972, F1 Macro: 0.7498\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.954667568206787 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2279, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1534, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0967, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7172\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0579, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.8182\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "Model 1 - Iteration 370: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 95.6333360671997 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2385, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1558, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1476, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0986, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Epoch 6/10, Train Loss: 0.0761, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7251\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7999\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.8007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7931\n",
      "Model 2 - Iteration 370: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.30172538757324 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.225, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1552, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1362, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0899, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7891\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7868\n",
      "Model 3 - Iteration 370: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.50      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.79      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 97.26582431793213 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9633, F1 Micro: 0.9721, F1 Macro: 0.7514\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: Sampling duration: 2.481437921524048 seconds10\n",
      "\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1501, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1627, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1328, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1115, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 6/10, Train Loss: 0.0806, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.8631\n",
      "Epoch 8/10, Train Loss: 0.0358, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7951\n",
      "Model 1 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.8631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.94      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.82      0.86       406\n",
      "weighted avg       0.98      0.98      0.98       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 95.29463362693787 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2264, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1518, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1616, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 5/10, Train Loss: 0.1045, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.0706, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7626\n",
      "Epoch 7/10, Train Loss: 0.0495, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8112\n",
      "Epoch 8/10, Train Loss: 0.0321, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7631\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7267\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6954\n",
      "Model 2 - Iteration 380: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 90.3743827342987 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2139, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1581, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Epoch 4/10, Train Loss: 0.1248, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.7427\n",
      "Epoch 5/10, Train Loss: 0.091, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7621\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.744\n",
      "Epoch 7/10, Train Loss: 0.0456, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0308, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8126\n",
      "Epoch 10/10, Train Loss: 0.0196, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "Model 3 - Iteration 380: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.88      0.83      0.81       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 92.80482697486877 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9635, F1 Micro: 0.9722, F1 Macro: 0.7525\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.900940179824829 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2246, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1402, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0943, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0653, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7538\n",
      "Epoch 7/10, Train Loss: 0.0439, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0345, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7793\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7659\n",
      "Model 1 - Iteration 390: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 98.5123360157013 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2326, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.157, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1396, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1407, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.6927\n",
      "Epoch 5/10, Train Loss: 0.0926, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Epoch 6/10, Train Loss: 0.0627, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0442, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7015\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 9/10, Train Loss: 0.0272, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.8005\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6993\n",
      "Model 2 - Iteration 390: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 95.23309421539307 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2236, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1563, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1356, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1271, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7344\n",
      "Epoch 5/10, Train Loss: 0.0799, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6994\n",
      "Epoch 6/10, Train Loss: 0.0542, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0425, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0312, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7355\n",
      "Epoch 9/10, Train Loss: 0.0243, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "Model 3 - Iteration 390: Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.8022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.89      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 98.2999861240387 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9636, F1 Micro: 0.9723, F1 Macro: 0.7532\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.374504566192627 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2165, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1601, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1437, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1222, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0858, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0602, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7522\n",
      "Epoch 7/10, Train Loss: 0.047, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0291, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8634\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7973\n",
      "Epoch 10/10, Train Loss: 0.0223, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7309\n",
      "Model 1 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.83      0.86       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 99.71586561203003 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2242, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.16, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1413, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1377, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0892, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7371\n",
      "Epoch 6/10, Train Loss: 0.0658, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8023\n",
      "Epoch 8/10, Train Loss: 0.0308, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7921\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7128\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.745\n",
      "Model 2 - Iteration 400: Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.38      0.75      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.71      0.78      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 96.62481164932251 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2134, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1598, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1365, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.6986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0777, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "Epoch 6/10, Train Loss: 0.0547, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.0458, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.804\n",
      "Epoch 8/10, Train Loss: 0.0308, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7858\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7858\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7941\n",
      "Model 3 - Iteration 400: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.89      0.83      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 94.91427159309387 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9637, F1 Micro: 0.9724, F1 Macro: 0.7553\n",
      "Total sampling time: 206.4 seconds\n",
      "Total runtime: 5899.69521355629 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ccd9a",
   "metadata": {
    "papermill": {
     "duration": 0.15149,
     "end_time": "2025-04-12T14:12:22.587979",
     "exception": false,
     "start_time": "2025-04-12T14:12:22.436489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e37b8d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T14:12:22.899343Z",
     "iopub.status.busy": "2025-04-12T14:12:22.899005Z",
     "iopub.status.idle": "2025-04-12T15:51:09.518410Z",
     "shell.execute_reply": "2025-04-12T15:51:09.517663Z"
    },
    "papermill": {
     "duration": 5926.776138,
     "end_time": "2025-04-12T15:51:09.519770",
     "exception": false,
     "start_time": "2025-04-12T14:12:22.743632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 5\n",
      "Random seed: [94, 21, 5]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5613, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3141, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2349, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.212, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2173, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1608, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1909, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1611, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1423, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 1 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.90741801261902 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5537, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3132, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2322, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.213, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.218, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.163, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1988, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1598, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1621, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1501, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 2 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 39.307820081710815 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3226, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2502, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2242, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2301, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2076, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.17, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1708, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1648, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Model 3 - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 38.40505576133728 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 23.33908462524414 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4424, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2374, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1876, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1396, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1283, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1151, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1352, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 10/10, Train Loss: 0.0974, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 1 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 40.98114275932312 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4386, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2358, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1851, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1558, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.131, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1448, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1403, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1179, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1515, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1035, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Model 2 - Iteration 63: Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.428327322006226 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2025, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1442, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1491, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1449, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1185, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.15, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.1076, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Model 3 - Iteration 63: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 44.307143211364746 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9586, F1 Micro: 0.9686, F1 Macro: 0.6512\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 20.599688053131104 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1462, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1538, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.121, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1048, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.096, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Epoch 10/10, Train Loss: 0.0696, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Model 1 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.620224952697754 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3539, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.163, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1439, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.0921, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 10/10, Train Loss: 0.0691, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Model 2 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.566680908203125 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.128, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 9/10, Train Loss: 0.1062, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Epoch 10/10, Train Loss: 0.0788, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Model 3 - Iteration 97: Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.84      1.00      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.65       406\n",
      "weighted avg       0.94      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 48.28384256362915 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9585, F1 Micro: 0.9685, F1 Macro: 0.6511\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 17.863227605819702 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3388, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1866, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1544, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1357, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0723, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Model 1 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 53.654656648635864 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3402, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.187, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1426, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1484, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1397, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Model 2 - Iteration 128: Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.95      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.97      0.97       406\n",
      "\n",
      "Training completed in 54.23943853378296 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3548, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1944, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1454, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1402, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1189, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.0957, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6507\n",
      "Model 3 - Iteration 128: Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.98      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.96      0.98      0.97       406\n",
      "\n",
      "Training completed in 52.04997229576111 s\n",
      "Averaged - Iteration 128: Accuracy: 0.959, F1 Micro: 0.9688, F1 Macro: 0.6513\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 16.283318281173706 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3235, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.163, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1444, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 60.04888105392456 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3147, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1635, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1766, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1588, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1503, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 8/10, Train Loss: 0.0851, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6505\n",
      "Epoch 10/10, Train Loss: 0.0404, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Model 2 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 56.15668487548828 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3292, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1696, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1801, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.173, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1596, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1574, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.651\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.6507\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.7243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.651\n",
      "Model 3 - Iteration 156: Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.94      0.91        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.97      0.97       406\n",
      "\n",
      "Training completed in 56.432049036026 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9598, F1 Micro: 0.9694, F1 Macro: 0.656\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 14.324517011642456 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3144, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1916, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.163, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7206\n",
      "Model 1 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.37790322303772 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3149, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1926, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.168, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1628, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1483, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6515\n",
      "Epoch 7/10, Train Loss: 0.0903, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0596, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0483, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7857\n",
      "Epoch 10/10, Train Loss: 0.0345, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.8138\n",
      "Model 2 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 62.560712575912476 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3274, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1963, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1683, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 8/10, Train Loss: 0.0832, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7012\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0403, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7739\n",
      "Model 3 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.95      0.97      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 59.515145778656006 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9606, F1 Micro: 0.9699, F1 Macro: 0.6629\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 12.786142349243164 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2947, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1584, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1513, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Epoch 6/10, Train Loss: 0.1234, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0546, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0402, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Model 1 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.74      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.85476398468018 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2862, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1902, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1439, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7628\n",
      "Epoch 8/10, Train Loss: 0.0671, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.761\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "Model 2 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 65.43227648735046 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3039, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1631, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.145, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1245, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 7/10, Train Loss: 0.1027, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7071\n",
      "Epoch 8/10, Train Loss: 0.0769, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.7069\n",
      "Epoch 9/10, Train Loss: 0.0562, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0395, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7658\n",
      "Model 3 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.65      0.66      0.65       406\n",
      "weighted avg       0.96      0.97      0.96       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 63.449737548828125 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9613, F1 Micro: 0.9705, F1 Macro: 0.6753\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 11.8356773853302 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2821, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1609, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1988, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1298, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 7/10, Train Loss: 0.089, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7064\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.7162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7194\n",
      "Epoch 10/10, Train Loss: 0.0382, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.652\n",
      "Model 1 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.97      0.97       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 68.46047854423523 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2814, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1602, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1994, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 6/10, Train Loss: 0.1175, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Epoch 8/10, Train Loss: 0.0819, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.718\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7468\n",
      "Epoch 10/10, Train Loss: 0.0378, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Model 2 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.73      0.74      0.74       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 66.65538692474365 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2925, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1574, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2046, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 6/10, Train Loss: 0.1126, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9439, F1 Micro: 0.9578, F1 Macro: 0.695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7194\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7921\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7192\n",
      "Model 3 - Iteration 223: Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.97      0.97       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 66.33715581893921 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9617, F1 Micro: 0.9708, F1 Macro: 0.6815\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 10.474359035491943 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2667, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1703, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1548, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1544, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0542, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.0381, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "Model 1 - Iteration 241: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.65      0.66      0.66       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.66471409797668 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2599, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1697, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1535, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1599, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.055, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7637\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7183\n",
      "Model 2 - Iteration 241: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.85      1.00      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.81      0.75      0.76       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 74.23223900794983 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2739, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1735, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1919, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.158, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1648, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1375, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.06, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "Epoch 9/10, Train Loss: 0.0548, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7082\n",
      "Epoch 10/10, Train Loss: 0.0431, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8026\n",
      "Model 3 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 74.04171776771545 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9623, F1 Micro: 0.9712, F1 Macro: 0.6851\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 9.567418575286865 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2791, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1307, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.13, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1137, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7218\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Model 1 - Iteration 250: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 74.98195004463196 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2727, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1701, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1068, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7201\n",
      "Epoch 7/10, Train Loss: 0.0682, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "Epoch 9/10, Train Loss: 0.0476, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7626\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7864\n",
      "Model 2 - Iteration 250: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.74      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 71.75294661521912 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2847, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1794, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1691, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1333, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Epoch 7/10, Train Loss: 0.0791, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Epoch 8/10, Train Loss: 0.058, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Epoch 9/10, Train Loss: 0.0509, Accuracy: 0.9551, F1 Micro: 0.9659, F1 Macro: 0.6922\n",
      "Epoch 10/10, Train Loss: 0.0315, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.761\n",
      "Model 3 - Iteration 250: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 70.33161616325378 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9627, F1 Micro: 0.9715, F1 Macro: 0.6893\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 8.847877502441406 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2683, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1639, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1551, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0939, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0531, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0353, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7791\n",
      "Model 1 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 78.3790545463562 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2636, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1642, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1825, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1652, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7944\n",
      "Epoch 7/10, Train Loss: 0.0617, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0526, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 10/10, Train Loss: 0.0338, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8151\n",
      "Model 2 - Iteration 265: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.76      0.75      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 76.44482946395874 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2771, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1693, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1836, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 6/10, Train Loss: 0.0975, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.6499\n",
      "Epoch 7/10, Train Loss: 0.0651, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7618\n",
      "Epoch 8/10, Train Loss: 0.0534, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7839\n",
      "Epoch 9/10, Train Loss: 0.0502, Accuracy: 0.9567, F1 Micro: 0.967, F1 Macro: 0.7053\n",
      "Epoch 10/10, Train Loss: 0.0373, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.784\n",
      "Model 3 - Iteration 265: Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.66      0.65       406\n",
      "weighted avg       0.95      0.98      0.96       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 73.4426097869873 s\n",
      "Averaged - Iteration 265: Accuracy: 0.963, F1 Micro: 0.9717, F1 Macro: 0.6928\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 8.325211763381958 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.257, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.08, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0475, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7978\n",
      "Model 1 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 83.33439922332764 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2521, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1813, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1827, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1334, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0827, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0504, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "Epoch 9/10, Train Loss: 0.0492, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7643\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.831\n",
      "Model 2 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.70      0.72       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.98       406\n",
      "\n",
      "Training completed in 79.7212781906128 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2652, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1826, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1856, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.6514\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0842, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0475, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7754\n",
      "Model 3 - Iteration 279: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.89      0.75      0.78       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 79.75271916389465 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9635, F1 Micro: 0.9721, F1 Macro: 0.6988\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 7.352176189422607 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2538, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.656\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6543\n",
      "Epoch 7/10, Train Loss: 0.0672, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7187\n",
      "Epoch 8/10, Train Loss: 0.0591, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7955\n",
      "Epoch 9/10, Train Loss: 0.0391, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7769\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8437\n",
      "Model 1 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.65      0.67      0.66       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 77.52120208740234 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2512, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1868, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1329, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0639, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "Epoch 9/10, Train Loss: 0.0413, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0311, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Model 2 - Iteration 292: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.48945045471191 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1909, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Epoch 5/10, Train Loss: 0.146, Accuracy: 0.9535, F1 Micro: 0.9648, F1 Macro: 0.685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Epoch 8/10, Train Loss: 0.0641, Accuracy: 0.9567, F1 Micro: 0.9673, F1 Macro: 0.7602\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.8091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8301\n",
      "Model 3 - Iteration 292: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 80.80862188339233 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9638, F1 Micro: 0.9723, F1 Macro: 0.7034\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 6.865772247314453 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2542, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1738, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1489, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1175, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0819, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0586, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0481, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "Model 1 - Iteration 300: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.87      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.84698724746704 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2514, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1781, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1786, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1551, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1248, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0856, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Epoch 7/10, Train Loss: 0.0622, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0516, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7952\n",
      "Model 2 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.79      0.80       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.8236436843872 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2648, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1852, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1794, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1601, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Epoch 7/10, Train Loss: 0.0641, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.052, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7094\n",
      "Epoch 9/10, Train Loss: 0.0329, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0316, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7753\n",
      "Model 3 - Iteration 300: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.90      0.74      0.78       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 84.52218985557556 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9639, F1 Micro: 0.9724, F1 Macro: 0.7088\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 6.2291436195373535 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.24, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1765, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1566, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1104, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7301\n",
      "Epoch 6/10, Train Loss: 0.0951, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7311\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Epoch 8/10, Train Loss: 0.0536, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.8026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7458\n",
      "Model 1 - Iteration 310: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 82.66937518119812 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2349, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1733, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1106, Accuracy: 0.9519, F1 Micro: 0.9639, F1 Macro: 0.7185\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6983\n",
      "Epoch 7/10, Train Loss: 0.068, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.7248\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8465\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7799\n",
      "Model 2 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 80.46045517921448 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.177, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1617, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.112, Accuracy: 0.9535, F1 Micro: 0.965, F1 Macro: 0.713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7371\n",
      "Epoch 8/10, Train Loss: 0.0569, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.8028\n",
      "Model 3 - Iteration 310: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 82.52294516563416 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9642, F1 Micro: 0.9726, F1 Macro: 0.7149\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.547078371047974 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2586, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1743, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1755, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 6/10, Train Loss: 0.0873, Accuracy: 0.9583, F1 Micro: 0.9685, F1 Macro: 0.7259\n",
      "Epoch 7/10, Train Loss: 0.0637, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0573, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Epoch 9/10, Train Loss: 0.0314, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7941\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7281\n",
      "Model 1 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 82.45826411247253 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2553, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1751, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1369, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.0835, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7419\n",
      "Epoch 7/10, Train Loss: 0.0626, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.7486\n",
      "Epoch 8/10, Train Loss: 0.0688, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 9/10, Train Loss: 0.0374, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.8093\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7442\n",
      "Model 2 - Iteration 320: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.64      0.67      0.66       406\n",
      "weighted avg       0.95      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 80.35402703285217 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2666, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1777, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.176, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1469, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6528\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7066\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7201\n",
      "Epoch 8/10, Train Loss: 0.065, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8159\n",
      "Model 3 - Iteration 320: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.92      0.79      0.82       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 85.62750101089478 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9644, F1 Micro: 0.9728, F1 Macro: 0.7168\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.145713806152344 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2397, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1594, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0991, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0748, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "Epoch 8/10, Train Loss: 0.037, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7392\n",
      "Epoch 9/10, Train Loss: 0.0272, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8124\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Model 1 - Iteration 330: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 88.56109285354614 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2355, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1809, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1472, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0913, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7309\n",
      "Epoch 6/10, Train Loss: 0.0782, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7684\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7548\n",
      "Model 2 - Iteration 330: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.90      0.79      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 88.502512216568 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2486, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1827, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1636, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1567, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Epoch 6/10, Train Loss: 0.0889, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7186\n",
      "Epoch 8/10, Train Loss: 0.0395, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7179\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7862\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9551, F1 Micro: 0.9662, F1 Macro: 0.7999\n",
      "Model 3 - Iteration 330: Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.94      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       406\n",
      "   macro avg       0.81      0.70      0.72       406\n",
      "weighted avg       0.96      0.97      0.97       406\n",
      " samples avg       0.97      0.97      0.97       406\n",
      "\n",
      "Training completed in 87.06673765182495 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9646, F1 Micro: 0.9729, F1 Macro: 0.7195\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.926551342010498 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2437, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1443, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1405, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7653\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7367\n",
      "Epoch 6/10, Train Loss: 0.0996, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0625, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8315\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.8311\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "Epoch 10/10, Train Loss: 0.0186, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7494\n",
      "Model 1 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.98      0.78      0.83       406\n",
      "weighted avg       0.98      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.4686439037323 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2444, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1676, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1433, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.14, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.1071, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Epoch 6/10, Train Loss: 0.1009, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7001\n",
      "Epoch 7/10, Train Loss: 0.0696, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.0364, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7676\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.735\n",
      "Model 2 - Iteration 340: Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.97      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.75      0.79      0.76       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 86.23475933074951 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.252, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1686, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1487, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1049, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0708, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7871\n",
      "Epoch 8/10, Train Loss: 0.0373, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.728\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Model 3 - Iteration 340: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 89.80269837379456 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7235\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.988312244415283 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2576, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1865, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1661, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7196\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7529\n",
      "Epoch 7/10, Train Loss: 0.0517, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7254\n",
      "Epoch 8/10, Train Loss: 0.0412, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7772\n",
      "Model 1 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.77      0.79      0.78       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.59562349319458 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2549, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1867, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1664, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1455, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.0995, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0781, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0468, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "Epoch 10/10, Train Loss: 0.0322, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7104\n",
      "Model 2 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.75      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 92.52228331565857 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2637, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1904, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6519\n",
      "Epoch 6/10, Train Loss: 0.0835, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.8005\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7483\n",
      "Model 3 - Iteration 350: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.98      0.74      0.79       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 87.6173198223114 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9649, F1 Micro: 0.9732, F1 Macro: 0.7267\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.6526341438293457 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2427, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1753, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1632, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.142, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.738\n",
      "Epoch 6/10, Train Loss: 0.0765, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7479\n",
      "Epoch 7/10, Train Loss: 0.0646, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7283\n",
      "Model 1 - Iteration 360: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.96      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.9103536605835 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2402, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1763, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.138, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 5/10, Train Loss: 0.1033, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7007\n",
      "Epoch 6/10, Train Loss: 0.0777, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.6991\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.7256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.049, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 10/10, Train Loss: 0.0263, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7636\n",
      "Model 2 - Iteration 360: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.8207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.90      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 89.18989491462708 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2478, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1788, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.123, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.72\n",
      "Epoch 6/10, Train Loss: 0.0861, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7189\n",
      "Epoch 7/10, Train Loss: 0.0712, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8319\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7865\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7633\n",
      "Model 3 - Iteration 360: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 90.93619012832642 s\n",
      "Averaged - Iteration 360: Accuracy: 0.965, F1 Micro: 0.9733, F1 Macro: 0.7307\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.9680843353271484 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2427, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1733, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1339, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0934, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0467, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.754\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7533\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7451\n",
      "Model 1 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.76       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 95.30745100975037 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2403, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1729, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1379, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1371, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 5/10, Train Loss: 0.0937, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.6948\n",
      "Epoch 6/10, Train Loss: 0.0735, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.6998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.051, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7287\n",
      "Epoch 8/10, Train Loss: 0.0411, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7018\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8336\n",
      "Model 2 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.98      0.79      0.83       406\n",
      "weighted avg       0.98      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 93.66497468948364 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2481, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1763, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1378, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1007, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7448\n",
      "Epoch 6/10, Train Loss: 0.0752, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0477, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0346, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7964\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7923\n",
      "Model 3 - Iteration 370: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 97.27170467376709 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9653, F1 Micro: 0.9735, F1 Macro: 0.7339\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.0799593925476074 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2517, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1667, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.654\n",
      "Epoch 4/10, Train Loss: 0.1255, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7177\n",
      "Epoch 5/10, Train Loss: 0.083, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0686, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8458\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Epoch 9/10, Train Loss: 0.0225, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 10/10, Train Loss: 0.0188, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8126\n",
      "Model 1 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       406\n",
      "   macro avg       0.94      0.83      0.85       406\n",
      "weighted avg       0.97      0.99      0.98       406\n",
      " samples avg       0.97      0.99      0.98       406\n",
      "\n",
      "Training completed in 93.2769923210144 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2496, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1669, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1282, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Epoch 5/10, Train Loss: 0.0856, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0742, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7444\n",
      "Epoch 7/10, Train Loss: 0.061, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.6983\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8143\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7418\n",
      "Model 2 - Iteration 380: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.8143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.98      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       406\n",
      "   macro avg       0.92      0.79      0.81       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.1916663646698 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2619, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1699, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1633, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1395, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1061, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.7182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0817, Accuracy: 0.9679, F1 Micro: 0.9752, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0633, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0288, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8324\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7864\n",
      "Model 3 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.95      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.92      0.83      0.83       406\n",
      "weighted avg       0.97      0.98      0.98       406\n",
      " samples avg       0.97      0.98      0.97       406\n",
      "\n",
      "Training completed in 100.29295134544373 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9654, F1 Micro: 0.9736, F1 Macro: 0.7383\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9548923969268799 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2109, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1429, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1572, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1204, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6538\n",
      "Epoch 5/10, Train Loss: 0.0926, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7946\n",
      "Epoch 8/10, Train Loss: 0.0269, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7633\n",
      "Epoch 9/10, Train Loss: 0.0259, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0161, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "Model 1 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.8208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.89      0.83      0.82       406\n",
      "weighted avg       0.97      0.99      0.97       406\n",
      " samples avg       0.96      0.99      0.97       406\n",
      "\n",
      "Training completed in 96.27931809425354 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2085, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.145, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1623, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1192, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.6539\n",
      "Epoch 5/10, Train Loss: 0.0899, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7182\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9583, F1 Micro: 0.9686, F1 Macro: 0.751\n",
      "Epoch 7/10, Train Loss: 0.0562, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7658\n",
      "Epoch 8/10, Train Loss: 0.032, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0323, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7441\n",
      "Model 2 - Iteration 390: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.40      0.50      0.44         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       1.00      0.25      0.40         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       406\n",
      "   macro avg       0.88      0.79      0.80       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 95.19728255271912 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.218, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1463, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1658, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1247, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6548\n",
      "Epoch 5/10, Train Loss: 0.0982, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7198\n",
      "Epoch 6/10, Train Loss: 0.0658, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0576, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.8308\n",
      "Epoch 8/10, Train Loss: 0.0336, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7847\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.8291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0207, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "Model 3 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       406\n",
      "   macro avg       0.81      0.75      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.97      0.98      0.98       406\n",
      "\n",
      "Training completed in 96.70686936378479 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9655, F1 Micro: 0.9736, F1 Macro: 0.7407\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8184704780578613 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2442, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1748, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1483, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.655\n",
      "Epoch 4/10, Train Loss: 0.1268, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6495\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.7597\n",
      "Epoch 6/10, Train Loss: 0.078, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7939\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7628\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7375\n",
      "Model 1 - Iteration 400: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       406\n",
      "   macro avg       0.72      0.79      0.75       406\n",
      "weighted avg       0.96      0.99      0.97       406\n",
      " samples avg       0.97      0.99      0.97       406\n",
      "\n",
      "Training completed in 94.90472364425659 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.244, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1721, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1224, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0878, Accuracy: 0.9647, F1 Micro: 0.9727, F1 Macro: 0.7191\n",
      "Epoch 6/10, Train Loss: 0.0717, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 7/10, Train Loss: 0.0485, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7009\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7016\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7668\n",
      "Model 2 - Iteration 400: Accuracy: 0.9647, F1 Micro: 0.9727, F1 Macro: 0.7191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.92      0.92        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       406\n",
      "   macro avg       0.82      0.69      0.72       406\n",
      "weighted avg       0.97      0.97      0.97       406\n",
      " samples avg       0.98      0.97      0.97       406\n",
      "\n",
      "Training completed in 96.62453985214233 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2524, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1768, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1506, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1309, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1168, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0855, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.8204\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.8422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "Epoch 10/10, Train Loss: 0.0281, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7628\n",
      "Model 3 - Iteration 400: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7659\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        87\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       406\n",
      "   macro avg       0.82      0.74      0.77       406\n",
      "weighted avg       0.97      0.98      0.97       406\n",
      " samples avg       0.98      0.98      0.97       406\n",
      "\n",
      "Training completed in 101.543781042099 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9655, F1 Micro: 0.9737, F1 Macro: 0.7409\n",
      "Total sampling time: 207.78 seconds\n",
      "Total runtime: 5925.907134056091 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6862554,
     "sourceId": 11020795,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11860.39301,
   "end_time": "2025-04-12T15:51:12.772138",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T12:33:32.379128",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03a561ebf79142209a62e9d9e7753fb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2e93303a2f7044819e821f6f5d812ec3",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_30827413e90a4994aa02e87fd2dc5fea",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡112/112â€‡[00:00&lt;00:00,â€‡11.2kB/s]"
      }
     },
     "0b535fd14a9944e8b1ee249bbc2838e0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e73be03a2754ab4b2edce0e721a0fb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "246137f266a04730abfb07f31e9885ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ae4b37ede3c47c9ba30f967c97df16f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8db427beb5b647acbf747594cb7e6e71",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9f9c2f5268514953bef88341d54ef6c8",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:â€‡100%"
      }
     },
     "2e93303a2f7044819e821f6f5d812ec3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30827413e90a4994aa02e87fd2dc5fea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3374c447b0be4c5dbc86e4074eb2d2f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36c44998a00949268d0faa0f57b18224": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6c5288708b5c4f7480e41161db54ea2c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8f426a25a7a64a3ca08783c499aed01d",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡2.00/2.00â€‡[00:00&lt;00:00,â€‡163B/s]"
      }
     },
     "3ebeb2fc52e54abdbac9d3542412b629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc6146c2fa5f4961a975181aff8e4bd4",
        "IPY_MODEL_ef13a1c27a5b40fca77046efbb709998",
        "IPY_MODEL_36c44998a00949268d0faa0f57b18224"
       ],
       "layout": "IPY_MODEL_90fc00c91cc547519740e601def8d810",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4a5807a7c23d43ae9ab3f42e4b1754fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3374c447b0be4c5dbc86e4074eb2d2f8",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a8185b62a8ff4970963b466915e7a336",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "512043c9735846709fcef8439acd0026": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "54bd26fc15e44428816c6bb70f8fbe91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5706ccb92e8743f2acc0c39ef5de6d2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "58b21df153f84053bbe85b426a0bf183": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a27a1c320954af3b276e9db8e69d0ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "630f224b26024fd691976b10a9532a7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2ae4b37ede3c47c9ba30f967c97df16f",
        "IPY_MODEL_4a5807a7c23d43ae9ab3f42e4b1754fe",
        "IPY_MODEL_825e2f2a02594306b41179c56204859f"
       ],
       "layout": "IPY_MODEL_882b81198658451d9faceee57a56a670",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6587645b97414c1c83a80ae0bad04881": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6890e8d57f694004a4a66542fe579fb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58b21df153f84053bbe85b426a0bf183",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_512043c9735846709fcef8439acd0026",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "6c5288708b5c4f7480e41161db54ea2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7377ddae34e3456895e095ab3408ec40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "825e2f2a02594306b41179c56204859f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_246137f266a04730abfb07f31e9885ed",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7377ddae34e3456895e095ab3408ec40",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡229k/229kâ€‡[00:00&lt;00:00,â€‡5.56MB/s]"
      }
     },
     "8633ba8d274746c9af6606d8926cf79a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "882b81198658451d9faceee57a56a670": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89fea51bfe114984bef2ee2717909d96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8db427beb5b647acbf747594cb7e6e71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f426a25a7a64a3ca08783c499aed01d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8f74db37213243d8bf4e7c3876a8ff63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b6432897b4e9444a8c2e99d01907eb70",
        "IPY_MODEL_e329169666204ce18b092c653df26df9",
        "IPY_MODEL_c317333bb02a472ba2ae0f165df5995f"
       ],
       "layout": "IPY_MODEL_b499fe51a56b4cedbad3705e799f69bb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "90fc00c91cc547519740e601def8d810": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f9c2f5268514953bef88341d54ef6c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a5a650cc169a4a01b5968b1503d99614": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a8185b62a8ff4970963b466915e7a336": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "addbbe044d28408e84e198741562a5a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b9cabf24c5eb4e8f9c0c0789215eab4f",
        "IPY_MODEL_6890e8d57f694004a4a66542fe579fb6",
        "IPY_MODEL_03a561ebf79142209a62e9d9e7753fb4"
       ],
       "layout": "IPY_MODEL_89fea51bfe114984bef2ee2717909d96",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b499fe51a56b4cedbad3705e799f69bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6432897b4e9444a8c2e99d01907eb70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_54bd26fc15e44428816c6bb70f8fbe91",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d6c6fd0f4a5b46c6aa305bd7deccddcd",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "b9cabf24c5eb4e8f9c0c0789215eab4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8633ba8d274746c9af6606d8926cf79a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c8f880e50d0a49f794e9052407495757",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:â€‡100%"
      }
     },
     "c317333bb02a472ba2ae0f165df5995f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a27a1c320954af3b276e9db8e69d0ed",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c35214ccac934c1fabb3aa91e8ee247a",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡141kB/s]"
      }
     },
     "c35214ccac934c1fabb3aa91e8ee247a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c8f880e50d0a49f794e9052407495757": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc6146c2fa5f4961a975181aff8e4bd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0e73be03a2754ab4b2edce0e721a0fb0",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a5a650cc169a4a01b5968b1503d99614",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "d6c6fd0f4a5b46c6aa305bd7deccddcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e329169666204ce18b092c653df26df9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6587645b97414c1c83a80ae0bad04881",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e84dd765799c463581dbbbb123f5e6e9",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "e84dd765799c463581dbbbb123f5e6e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ef13a1c27a5b40fca77046efbb709998": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b535fd14a9944e8b1ee249bbc2838e0",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5706ccb92e8743f2acc0c39ef5de6d2f",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
